{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eezzeldin/POC/blob/RandomSearch_PP_Models/Profit_ML_V5_run0ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX8OulqEKx-0"
      },
      "outputs": [],
      "source": [
        "#pip install gplearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install tqdm"
      ],
      "metadata": {
        "id": "PXIHsEuiaXK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "wwvBMqzQcNu7",
        "outputId": "6c3947cf-d543-4426-bc90-2a01866515e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom gplearn.genetic import SymbolicRegressor, SymbolicTransformer\\n\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_squared_error\\nimport numpy as np\\n\\n# Generating some synthetic data for demonstration\\n# For example, let\\'s try to discover the relationship y = x^2 - x + 1\\nX = np.linspace(-1, 1, 100).reshape(-1, 1)\\ny = X**2 - X + 1 + np.random.randn(*X.shape) * 0.1\\n\\n# Splitting data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\\n\\n# Creating and training the symbolic regressor\\nest_gp = SymbolicRegressor(population_size=5000,\\n                           generations=3, stopping_criteria=0.01,\\n                           p_crossover=0.7, p_subtree_mutation=0.1,\\n                           p_hoist_mutation=0.05, p_point_mutation=0.1,\\n                           max_samples=0.9, verbose=1,\\n                           parsimony_coefficient=0.01, random_state=0 ,n_jobs=-1)\\nest_gp.fit(X_train, y_train)\\n\\n# Making predictions\\ny_pred = est_gp.predict(X_test)\\n\\n# Evaluating the model\\nprint(\"Model expression:\", est_gp._program)\\nprint(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "'''\n",
        "from gplearn.genetic import SymbolicRegressor, SymbolicTransformer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Generating some synthetic data for demonstration\n",
        "# For example, let's try to discover the relationship y = x^2 - x + 1\n",
        "X = np.linspace(-1, 1, 100).reshape(-1, 1)\n",
        "y = X**2 - X + 1 + np.random.randn(*X.shape) * 0.1\n",
        "\n",
        "# Splitting data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Creating and training the symbolic regressor\n",
        "est_gp = SymbolicRegressor(population_size=5000,\n",
        "                           generations=3, stopping_criteria=0.01,\n",
        "                           p_crossover=0.7, p_subtree_mutation=0.1,\n",
        "                           p_hoist_mutation=0.05, p_point_mutation=0.1,\n",
        "                           max_samples=0.9, verbose=1,\n",
        "                           parsimony_coefficient=0.01, random_state=0 ,n_jobs=-1)\n",
        "est_gp.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = est_gp.predict(X_test)\n",
        "\n",
        "# Evaluating the model\n",
        "print(\"Model expression:\", est_gp._program)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiXIBMXCcFJE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "\n",
        "from gplearn.genetic import SymbolicRegressor, SymbolicTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "m2Lh21mHNpQL",
        "outputId": "ab038e35-f7c1-4c0f-bc0b-f0440dba9cf1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n+The reason an MMC  has the Profit it does is :\\n- price, TIV decay\\n- R2 TIV , R2 Price\\n\\n- Confidence measure : number of points.\\n\\n- Year of Release (candidate for removal)\\n\\n+missing from analysis :\\nTIV Launch price\\n\\n+grouping variable    : Launch Price Bins.\\n+granularity variable : MMC\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "'''\n",
        "+The reason an MMC  has the Profit it does is :\n",
        "- price, TIV decay\n",
        "- R2 TIV , R2 Price\n",
        "\n",
        "- Confidence measure : number of points.\n",
        "\n",
        "- Year of Release (candidate for removal)\n",
        "\n",
        "+missing from analysis :\n",
        "TIV Launch price\n",
        "\n",
        "+grouping variable    : Launch Price Bins.\n",
        "+granularity variable : MMC\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDFnEZjNK6qV"
      },
      "outputs": [],
      "source": [
        "input_file_path    = \"/content/profit_pred_3.csv\"\n",
        "\n",
        "col_rename_dict = {\n",
        "    \"Launch Price (bin)\"   : \"LPB\" ,\n",
        "    'Avg. Launch Price'    : \"LP\"  ,\n",
        "    \"Avg. Launch TIV\"      : \"LTIV\",\n",
        "    \"Model Memory Carrier\" : \"MMC\" ,\n",
        "    \"Year of Release Date\" : \"Year\",\n",
        "    \"Avg. Point Count 1000\": \"PC\"  ,\n",
        "    \"Avg. Price decay\"     : \"Price_Decay\",\n",
        "    \"Avg. Price rsquared\"  : \"Price_R2\"  ,\n",
        "    \"Avg. TIV decay\"       : \"TIV_Decay\" ,\n",
        "    \"Avg. TIV rsquared\"    : \"TIV_R2\",\n",
        "}\n",
        "\n",
        "not_Features           = [\"Profit\" , \"MMC\" ,\"PC\"]\n",
        "Target                 = \"Profit\"\n",
        "pred_col_name          = \"Profit_Pred\"\n",
        "\n",
        "scaler_dict            = {}\n",
        "interaction_1_name     = \"Price_Decay_R2\"\n",
        "interaction_1_terms    = [\"Price_R2\" , \"Price_Decay\"]\n",
        "\n",
        "grouping_col           = \"LPB\" # .astype(\"category\")\n",
        "\n",
        "number_of_test_per_fold = 1\n",
        "fold_y_pred             = \"fold_y_pred\"\n",
        "fold_test_index         = \"fold_test_index\"\n",
        "fold_num                = 'fold_num'\n",
        "fold_y_g_pred           = \"fold_y_g_pred\"\n",
        "\n",
        "interaction       = True\n",
        "one_hot           = True\n",
        "scale_features    = True\n",
        "drop_grouping_var = True\n",
        "Kfold_symbolic    = True\n",
        "\n",
        "\n",
        "#winner\n",
        "generations=100\n",
        "population_size=4000\n",
        "hall_of_fame=200\n",
        "n_components=10\n",
        "\n",
        "#winner\n",
        "generations=200 # * 2\n",
        "population_size=8000 # * 2\n",
        "hall_of_fame=100\n",
        "n_components = 30\n",
        "function_set_trans = ['add', 'sub', 'mul', 'div',\n",
        "'sqrt', 'log', 'abs', 'neg', 'inv',\n",
        "'max', 'min']\n",
        "parsimony_coefficient_trans = 0.0005\n",
        "\n",
        "#winner\n",
        "generations=10 # * 2\n",
        "population_size=800 # * 2\n",
        "hall_of_fame = 200\n",
        "n_components = 50\n",
        "function_set_trans = ['add', 'sub', 'mul', 'div',\n",
        "'sqrt', 'log', 'abs', 'neg', 'inv',\n",
        "'max', 'min']\n",
        "parsimony_coefficient_trans = 0.0005\n",
        "\n",
        "\n",
        "#competitor\n",
        "generations=10 # * 2\n",
        "population_size=800 # * 2\n",
        "hall_of_fame = 200\n",
        "n_components = 50\n",
        "function_set_trans = ['add', 'sub', 'mul', 'div',\n",
        "'sqrt', 'log', 'abs', 'neg', 'inv',\n",
        "'max', 'min']\n",
        "parsimony_coefficient_trans = 0.0005\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "9jP5YV0hLAH1",
        "outputId": "b3e2b8f8-b8e3-4b67-c752-6b5daa135dbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Launch Price (bin)          Model Memory Carrier  Year of Release Date  \\\n",
              "0                1000   iPhone XS Max_512GB_Verizon                  2018   \n",
              "1                1000  iPhone XS Max_512GB_Unlocked                  2018   \n",
              "2                1000  iPhone XS Max_256GB_Unlocked                  2018   \n",
              "3                1000        iPhone X_256GB_Verizon                  2017   \n",
              "4                 900   iPhone XS Max_256GB_Verizon                  2018   \n",
              "\n",
              "   Avg. Launch Price  Avg. Launch TIV  Avg. Point Count 1000  \\\n",
              "0            1029.35          656.816                     19   \n",
              "1            1014.39          634.388                     20   \n",
              "2            1008.15          602.997                     20   \n",
              "3            1011.38          602.270                     19   \n",
              "4             982.38          562.836                     20   \n",
              "\n",
              "   Avg. Price decay  Avg. Price rsquared  Avg. TIV decay  Avg. TIV rsquared  \\\n",
              "0         -0.001192             0.894662       -0.001335           0.879887   \n",
              "1         -0.001009             0.911918       -0.001326           0.918513   \n",
              "2         -0.001031             0.915380       -0.001333           0.932912   \n",
              "3         -0.001220             0.958448       -0.001388           0.895701   \n",
              "4         -0.001070             0.891031       -0.001114           0.860168   \n",
              "\n",
              "    Profit  \n",
              "0    41381  \n",
              "1   227473  \n",
              "2  1514777  \n",
              "3   126462  \n",
              "4   199737  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed923d78-cd61-4342-9a33-91314c5c933a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Launch Price (bin)</th>\n",
              "      <th>Model Memory Carrier</th>\n",
              "      <th>Year of Release Date</th>\n",
              "      <th>Avg. Launch Price</th>\n",
              "      <th>Avg. Launch TIV</th>\n",
              "      <th>Avg. Point Count 1000</th>\n",
              "      <th>Avg. Price decay</th>\n",
              "      <th>Avg. Price rsquared</th>\n",
              "      <th>Avg. TIV decay</th>\n",
              "      <th>Avg. TIV rsquared</th>\n",
              "      <th>Profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone XS Max_512GB_Verizon</td>\n",
              "      <td>2018</td>\n",
              "      <td>1029.35</td>\n",
              "      <td>656.816</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.001192</td>\n",
              "      <td>0.894662</td>\n",
              "      <td>-0.001335</td>\n",
              "      <td>0.879887</td>\n",
              "      <td>41381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone XS Max_512GB_Unlocked</td>\n",
              "      <td>2018</td>\n",
              "      <td>1014.39</td>\n",
              "      <td>634.388</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.001009</td>\n",
              "      <td>0.911918</td>\n",
              "      <td>-0.001326</td>\n",
              "      <td>0.918513</td>\n",
              "      <td>227473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone XS Max_256GB_Unlocked</td>\n",
              "      <td>2018</td>\n",
              "      <td>1008.15</td>\n",
              "      <td>602.997</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.001031</td>\n",
              "      <td>0.915380</td>\n",
              "      <td>-0.001333</td>\n",
              "      <td>0.932912</td>\n",
              "      <td>1514777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone X_256GB_Verizon</td>\n",
              "      <td>2017</td>\n",
              "      <td>1011.38</td>\n",
              "      <td>602.270</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.001220</td>\n",
              "      <td>0.958448</td>\n",
              "      <td>-0.001388</td>\n",
              "      <td>0.895701</td>\n",
              "      <td>126462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>900</td>\n",
              "      <td>iPhone XS Max_256GB_Verizon</td>\n",
              "      <td>2018</td>\n",
              "      <td>982.38</td>\n",
              "      <td>562.836</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.001070</td>\n",
              "      <td>0.891031</td>\n",
              "      <td>-0.001114</td>\n",
              "      <td>0.860168</td>\n",
              "      <td>199737</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed923d78-cd61-4342-9a33-91314c5c933a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed923d78-cd61-4342-9a33-91314c5c933a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed923d78-cd61-4342-9a33-91314c5c933a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b4759935-d6dc-4486-b494-5794955e8da4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4759935-d6dc-4486-b494-5794955e8da4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b4759935-d6dc-4486-b494-5794955e8da4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data_input\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Launch Price (bin)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 44,\n        \"min\": 900,\n        \"max\": 1000,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          900,\n          1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model Memory Carrier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"iPhone XS Max_512GB_Unlocked\",\n          \"iPhone XS Max_256GB_Verizon\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year of Release Date\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2017,\n        \"max\": 2018,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2017,\n          2018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg. Launch Price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.015444454965,\n        \"min\": 982.38,\n        \"max\": 1029.35,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1014.39,\n          982.38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg. Launch TIV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35.715634374878476,\n        \"min\": 562.836,\n        \"max\": 656.816,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          634.388,\n          562.836\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg. Point Count 1000\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 19,\n        \"max\": 20,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          20,\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg. Price decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.593760092997943e-05,\n        \"min\": -0.001219558,\n        \"max\": -0.001008523,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.001008523,\n          -0.001070336\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg. Price rsquared\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.026846707846587065,\n        \"min\": 0.891031,\n        \"max\": 0.958448,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.911918,\n          0.891031\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg. TIV decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00010664962719109716,\n        \"min\": -0.00138764,\n        \"max\": -0.00111357,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.00132644,\n          -0.00111357\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg. TIV rsquared\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.029166195992964168,\n        \"min\": 0.860168,\n        \"max\": 0.932912,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.918513,\n          0.860168\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Profit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 615145,\n        \"min\": 41381,\n        \"max\": 1514777,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          227473,\n          199737\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data_input  = pd.read_csv (input_file_path)\n",
        "data_input.head ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WtRWhkuLNAV",
        "outputId": "7c7292de-112c-4444-a82d-67b22aef0f4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(114, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data_input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhQBisyiLJXL",
        "outputId": "fa2c1946-74c8-48a1-e7bf-f05cfa2b33bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 114 entries, 0 to 113\n",
            "Data columns (total 11 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   Launch Price (bin)     114 non-null    int64  \n",
            " 1   Model Memory Carrier   114 non-null    object \n",
            " 2   Year of Release Date   114 non-null    int64  \n",
            " 3   Avg. Launch Price      114 non-null    float64\n",
            " 4   Avg. Launch TIV        114 non-null    float64\n",
            " 5   Avg. Point Count 1000  114 non-null    int64  \n",
            " 6   Avg. Price decay       114 non-null    float64\n",
            " 7   Avg. Price rsquared    114 non-null    float64\n",
            " 8   Avg. TIV decay         114 non-null    float64\n",
            " 9   Avg. TIV rsquared      114 non-null    float64\n",
            " 10  Profit                 114 non-null    int64  \n",
            "dtypes: float64(6), int64(4), object(1)\n",
            "memory usage: 9.9+ KB\n"
          ]
        }
      ],
      "source": [
        "data_input.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giTDaAT8LYu3",
        "outputId": "3bf30061-7108-48c2-d7dc-76bc342eaec7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Launch Price (bin)', 'Model Memory Carrier', 'Year of Release Date',\n",
              "       'Avg. Launch Price', 'Avg. Launch TIV', 'Avg. Point Count 1000',\n",
              "       'Avg. Price decay', 'Avg. Price rsquared', 'Avg. TIV decay',\n",
              "       'Avg. TIV rsquared', 'Profit'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data_input.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Mj7pKpctLLjk",
        "outputId": "6928cd26-061a-47e7-f5bb-13ba4e4b45c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    LPB                           MMC  Year       LP     LTIV  PC  \\\n",
              "0  1000   iPhone XS Max_512GB_Verizon  2018  1029.35  656.816  19   \n",
              "1  1000  iPhone XS Max_512GB_Unlocked  2018  1014.39  634.388  20   \n",
              "2  1000  iPhone XS Max_256GB_Unlocked  2018  1008.15  602.997  20   \n",
              "3  1000        iPhone X_256GB_Verizon  2017  1011.38  602.270  19   \n",
              "4   900   iPhone XS Max_256GB_Verizon  2018   982.38  562.836  20   \n",
              "\n",
              "   Price_Decay  Price_R2  TIV_Decay    TIV_R2   Profit  \n",
              "0    -0.001192  0.894662  -0.001335  0.879887    41381  \n",
              "1    -0.001009  0.911918  -0.001326  0.918513   227473  \n",
              "2    -0.001031  0.915380  -0.001333  0.932912  1514777  \n",
              "3    -0.001220  0.958448  -0.001388  0.895701   126462  \n",
              "4    -0.001070  0.891031  -0.001114  0.860168   199737  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21988283-d048-4312-b1e1-7e27cfb2a4db\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LPB</th>\n",
              "      <th>MMC</th>\n",
              "      <th>Year</th>\n",
              "      <th>LP</th>\n",
              "      <th>LTIV</th>\n",
              "      <th>PC</th>\n",
              "      <th>Price_Decay</th>\n",
              "      <th>Price_R2</th>\n",
              "      <th>TIV_Decay</th>\n",
              "      <th>TIV_R2</th>\n",
              "      <th>Profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone XS Max_512GB_Verizon</td>\n",
              "      <td>2018</td>\n",
              "      <td>1029.35</td>\n",
              "      <td>656.816</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.001192</td>\n",
              "      <td>0.894662</td>\n",
              "      <td>-0.001335</td>\n",
              "      <td>0.879887</td>\n",
              "      <td>41381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone XS Max_512GB_Unlocked</td>\n",
              "      <td>2018</td>\n",
              "      <td>1014.39</td>\n",
              "      <td>634.388</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.001009</td>\n",
              "      <td>0.911918</td>\n",
              "      <td>-0.001326</td>\n",
              "      <td>0.918513</td>\n",
              "      <td>227473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone XS Max_256GB_Unlocked</td>\n",
              "      <td>2018</td>\n",
              "      <td>1008.15</td>\n",
              "      <td>602.997</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.001031</td>\n",
              "      <td>0.915380</td>\n",
              "      <td>-0.001333</td>\n",
              "      <td>0.932912</td>\n",
              "      <td>1514777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone X_256GB_Verizon</td>\n",
              "      <td>2017</td>\n",
              "      <td>1011.38</td>\n",
              "      <td>602.270</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.001220</td>\n",
              "      <td>0.958448</td>\n",
              "      <td>-0.001388</td>\n",
              "      <td>0.895701</td>\n",
              "      <td>126462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>900</td>\n",
              "      <td>iPhone XS Max_256GB_Verizon</td>\n",
              "      <td>2018</td>\n",
              "      <td>982.38</td>\n",
              "      <td>562.836</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.001070</td>\n",
              "      <td>0.891031</td>\n",
              "      <td>-0.001114</td>\n",
              "      <td>0.860168</td>\n",
              "      <td>199737</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21988283-d048-4312-b1e1-7e27cfb2a4db')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21988283-d048-4312-b1e1-7e27cfb2a4db button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21988283-d048-4312-b1e1-7e27cfb2a4db');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3de68e23-6482-4cf5-b478-9fa9acb639a0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3de68e23-6482-4cf5-b478-9fa9acb639a0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3de68e23-6482-4cf5-b478-9fa9acb639a0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_input",
              "summary": "{\n  \"name\": \"data_input\",\n  \"rows\": 114,\n  \"fields\": [\n    {\n      \"column\": \"LPB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 155,\n        \"min\": 300,\n        \"max\": 1000,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          900,\n          500,\n          1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MMC\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 114,\n        \"samples\": [\n          \"iPhone 11_128GB_T-Mobile\",\n          \"iPhone XS Max_256GB_Verizon\",\n          \"iPhone 8 Plus_256GB_Verizon\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2016,\n        \"max\": 2019,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2017,\n          2016,\n          2018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 159.75913399110536,\n        \"min\": 398.66,\n        \"max\": 1029.35,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          535.16,\n          982.38,\n          767.27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LTIV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105.31749580441497,\n        \"min\": 207.186,\n        \"max\": 656.816,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          239.438,\n          562.836,\n          409.377\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 16,\n        \"max\": 21,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          19,\n          20,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price_Decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00023556628349597262,\n        \"min\": -0.001411932,\n        \"max\": -0.00044894,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          -0.000637359,\n          -0.001070336,\n          -0.001031244\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price_R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08766141185476332,\n        \"min\": 0.512654,\n        \"max\": 0.980328,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          0.763261,\n          0.891031,\n          0.938773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TIV_Decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0002520634633665147,\n        \"min\": -0.00158934,\n        \"max\": -0.00050391,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          -0.00050391,\n          -0.00111357,\n          -0.00108685\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TIV_R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09797161857413617,\n        \"min\": 0.466594,\n        \"max\": 0.958327,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          0.643396,\n          0.860168,\n          0.838461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Profit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1063143,\n        \"min\": 4932,\n        \"max\": 5747639,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          276864,\n          199737,\n          110921\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data_input.rename (col_rename_dict,axis =1 ,inplace=True)\n",
        "data_input.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWetqzxhSRcd"
      },
      "outputs": [],
      "source": [
        "data_input [grouping_col] = data_input [grouping_col].astype(\"category\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BCYSWDYNkot"
      },
      "outputs": [],
      "source": [
        "#data_input [interaction_1_name] = data_input [interaction_1_terms [0]]  * data_input [interaction_1_terms [1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6uqrdMvNYCo"
      },
      "outputs": [],
      "source": [
        "X = data_input.drop (not_Features , axis=1)\n",
        "y =  data_input [Target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EP1z7yHzOOdO",
        "outputId": "91f74f48-98a2-4155-b0c1-ce538cddf9fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    LPB  Year       LP     LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
              "0  1000  2018  1029.35  656.816    -0.001192  0.894662  -0.001335  0.879887\n",
              "1  1000  2018  1014.39  634.388    -0.001009  0.911918  -0.001326  0.918513\n",
              "2  1000  2018  1008.15  602.997    -0.001031  0.915380  -0.001333  0.932912\n",
              "3  1000  2017  1011.38  602.270    -0.001220  0.958448  -0.001388  0.895701\n",
              "4   900  2018   982.38  562.836    -0.001070  0.891031  -0.001114  0.860168"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97c960c3-9bd6-4fbf-8534-ff6565cc0185\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LPB</th>\n",
              "      <th>Year</th>\n",
              "      <th>LP</th>\n",
              "      <th>LTIV</th>\n",
              "      <th>Price_Decay</th>\n",
              "      <th>Price_R2</th>\n",
              "      <th>TIV_Decay</th>\n",
              "      <th>TIV_R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000</td>\n",
              "      <td>2018</td>\n",
              "      <td>1029.35</td>\n",
              "      <td>656.816</td>\n",
              "      <td>-0.001192</td>\n",
              "      <td>0.894662</td>\n",
              "      <td>-0.001335</td>\n",
              "      <td>0.879887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000</td>\n",
              "      <td>2018</td>\n",
              "      <td>1014.39</td>\n",
              "      <td>634.388</td>\n",
              "      <td>-0.001009</td>\n",
              "      <td>0.911918</td>\n",
              "      <td>-0.001326</td>\n",
              "      <td>0.918513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000</td>\n",
              "      <td>2018</td>\n",
              "      <td>1008.15</td>\n",
              "      <td>602.997</td>\n",
              "      <td>-0.001031</td>\n",
              "      <td>0.915380</td>\n",
              "      <td>-0.001333</td>\n",
              "      <td>0.932912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>2017</td>\n",
              "      <td>1011.38</td>\n",
              "      <td>602.270</td>\n",
              "      <td>-0.001220</td>\n",
              "      <td>0.958448</td>\n",
              "      <td>-0.001388</td>\n",
              "      <td>0.895701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>900</td>\n",
              "      <td>2018</td>\n",
              "      <td>982.38</td>\n",
              "      <td>562.836</td>\n",
              "      <td>-0.001070</td>\n",
              "      <td>0.891031</td>\n",
              "      <td>-0.001114</td>\n",
              "      <td>0.860168</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97c960c3-9bd6-4fbf-8534-ff6565cc0185')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97c960c3-9bd6-4fbf-8534-ff6565cc0185 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97c960c3-9bd6-4fbf-8534-ff6565cc0185');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9132b68c-3e11-429f-84b1-4181129b907d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9132b68c-3e11-429f-84b1-4181129b907d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9132b68c-3e11-429f-84b1-4181129b907d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"LPB\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          900,\n          1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2017,\n        \"max\": 2018,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2017,\n          2018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.015444454965,\n        \"min\": 982.38,\n        \"max\": 1029.35,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1014.39,\n          982.38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LTIV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35.715634374878476,\n        \"min\": 562.836,\n        \"max\": 656.816,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          634.388,\n          562.836\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price_Decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.593760092997943e-05,\n        \"min\": -0.001219558,\n        \"max\": -0.001008523,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.001008523,\n          -0.001070336\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price_R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.026846707846587065,\n        \"min\": 0.891031,\n        \"max\": 0.958448,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.911918,\n          0.891031\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TIV_Decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00010664962719109716,\n        \"min\": -0.00138764,\n        \"max\": -0.00111357,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.00132644,\n          -0.00111357\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TIV_R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.029166195992964168,\n        \"min\": 0.860168,\n        \"max\": 0.932912,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.918513,\n          0.860168\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X.head ( )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXZpTQUhOoKQ",
        "outputId": "769e7d4e-ad71-45ba-a351-f51be404e828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 114 entries, 0 to 113\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype   \n",
            "---  ------       --------------  -----   \n",
            " 0   LPB          114 non-null    category\n",
            " 1   Year         114 non-null    int64   \n",
            " 2   LP           114 non-null    float64 \n",
            " 3   LTIV         114 non-null    float64 \n",
            " 4   Price_Decay  114 non-null    float64 \n",
            " 5   Price_R2     114 non-null    float64 \n",
            " 6   TIV_Decay    114 non-null    float64 \n",
            " 7   TIV_R2       114 non-null    float64 \n",
            "dtypes: category(1), float64(6), int64(1)\n",
            "memory usage: 6.8 KB\n"
          ]
        }
      ],
      "source": [
        "X.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_size      = int  (X.shape [0] * 0.3)\n",
        "\n",
        "test_indicies  = X.sample (test_size).index.values\n",
        "train_indicies = [i for i in X.index if i not in test_indicies]\n",
        "\n",
        "X_train       = X.loc [train_indicies]\n",
        "X_test        = X.loc [test_indicies]\n",
        "y_train       = y.loc [train_indicies]\n",
        "y_test        = y.loc [test_indicies]"
      ],
      "metadata": {
        "id": "E1KZnZVceCZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_dict  [Target] = StandardScaler().fit (y_train.values.reshape (-1,1))\n",
        "y_train_scaled = scaler_dict  [Target].transform (y_train.values.reshape (-1,1))"
      ],
      "metadata": {
        "id": "HPWqmjVXKYia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame (y_train_scaled).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "b88ZRYApAY71",
        "outputId": "e185c633-8f78-43f1-be9a-aa4a09409e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  0\n",
              "count  8.000000e+01\n",
              "mean  -1.110223e-17\n",
              "std    1.006309e+00\n",
              "min   -6.861549e-01\n",
              "25%   -6.347016e-01\n",
              "50%   -4.299079e-01\n",
              "75%    1.745080e-01\n",
              "max    3.781622e+00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a24ecf00-0bb7-4dbd-ae1f-35ceca6bb602\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8.000000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-1.110223e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.006309e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-6.861549e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-6.347016e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-4.299079e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.745080e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.781622e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a24ecf00-0bb7-4dbd-ae1f-35ceca6bb602')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a24ecf00-0bb7-4dbd-ae1f-35ceca6bb602 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a24ecf00-0bb7-4dbd-ae1f-35ceca6bb602');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8a656806-15d7-4dd0-828e-a0263bdf86bb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a656806-15d7-4dd0-828e-a0263bdf86bb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8a656806-15d7-4dd0-828e-a0263bdf86bb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.159949765805578,\n        \"min\": -0.6861549155885165,\n        \"max\": 80.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -1.1102230246251566e-17,\n          -0.4299079059176762,\n          80.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from gplearn.genetic import SymbolicTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "\n",
        "# Define the polynomial features followed by MinMax scaling part of the pipeline\n",
        "poly_minmax_pipeline = Pipeline([\n",
        "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    ('minmax_scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "# FeatureUnion to combine PolynomialFeatures + MinMaxScaler and SymbolicTransformer\n",
        "combined_features = FeatureUnion([\n",
        "    (\"poly_minmax\", poly_minmax_pipeline),\n",
        "    (\"symbolic_transform\", SymbolicTransformer(generations=20, population_size=2000,\n",
        "                                                 hall_of_fame=100, n_components=10,\n",
        "                                                 function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'inv', 'max', 'min'),\n",
        "                                                 parsimony_coefficient=0.0005, max_samples=0.9, verbose=0,n_jobs=-1)),\n",
        "])\n",
        "\n",
        "\n",
        "# Define a placeholder pipeline with a generic 'regressor' step\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('features', combined_features),\n",
        "    ('regressor', RandomForestRegressor())  # Placeholder, will be replaced by RandomizedSearchCV\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Define the parameter space for RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    'features__poly_minmax__poly__degree': [randint (1,10).rvs() for _ in range (10)],\n",
        "    'features__symbolic_transform__population_size': [randint (100,1000).rvs () for _ in range (10)],\n",
        "    'features__symbolic_transform__generations': [randint (1,10).rvs() for _ in range (10)],\n",
        "    'features__symbolic_transform__n_components': [randint (1,30).rvs () for _ in range (10)],\n",
        "    #'regressor': np.random.choice ([LinearRegression()]),\n",
        "    'regressor__n_estimators': [randint (10,100).rvs () for _ in range (10)],\n",
        "}\n",
        "\n",
        "cv     = 5\n",
        "n_iter = 100\n",
        "random_search = RandomizedSearchCV(pipeline, param_distributions=param_distributions,\n",
        "                                   n_iter=n_iter, verbose=50,cv = cv)\n",
        "\n",
        "random_search.fit (X_train,y_train_scaled.ravel())\n",
        "print (random_search.best_score_)\n",
        "print (random_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGVW8KQTzrMO",
        "outputId": "565fe2eb-9954-46d1-cb6b-9b690fd08566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "[CV 1/5; 1/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66\n",
            "[CV 1/5; 1/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66;, score=-0.305 total time=   3.3s\n",
            "[CV 2/5; 1/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66\n",
            "[CV 2/5; 1/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66;, score=-1.759 total time=   2.1s\n",
            "[CV 3/5; 1/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66\n",
            "[CV 3/5; 1/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66;, score=0.259 total time=   3.1s\n",
            "[CV 4/5; 1/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66\n",
            "[CV 4/5; 1/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66;, score=-0.141 total time=   3.2s\n",
            "[CV 5/5; 1/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66\n",
            "[CV 5/5; 1/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66;, score=-0.599 total time=   2.1s\n",
            "[CV 1/5; 2/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=86\n",
            "[CV 1/5; 2/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=86;, score=-1.095 total time=   7.3s\n",
            "[CV 2/5; 2/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=86\n",
            "[CV 2/5; 2/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=86;, score=-1.367 total time=   8.2s\n",
            "[CV 3/5; 2/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=86\n",
            "[CV 3/5; 2/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=86;, score=-0.136 total time=   8.4s\n",
            "[CV 4/5; 2/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=86\n",
            "[CV 4/5; 2/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=86;, score=0.325 total time=   7.0s\n",
            "[CV 5/5; 2/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=86\n",
            "[CV 5/5; 2/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=86;, score=-1.507 total time=   8.4s\n",
            "[CV 1/5; 3/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 1/5; 3/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-0.254 total time=   0.9s\n",
            "[CV 2/5; 3/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 2/5; 3/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-0.825 total time=   0.9s\n",
            "[CV 3/5; 3/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 3/5; 3/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=0.072 total time=   0.9s\n",
            "[CV 4/5; 3/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 4/5; 3/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=0.132 total time=   0.8s\n",
            "[CV 5/5; 3/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 5/5; 3/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-0.852 total time=   0.9s\n",
            "[CV 1/5; 4/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=18\n",
            "[CV 1/5; 4/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=18;, score=-0.172 total time=   0.7s\n",
            "[CV 2/5; 4/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=18\n",
            "[CV 2/5; 4/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=18;, score=-1.537 total time=   0.7s\n",
            "[CV 3/5; 4/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=18\n",
            "[CV 3/5; 4/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=18;, score=0.075 total time=   0.7s\n",
            "[CV 4/5; 4/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=18\n",
            "[CV 4/5; 4/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=18;, score=-0.068 total time=   0.8s\n",
            "[CV 5/5; 4/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=18\n",
            "[CV 5/5; 4/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=18;, score=-0.553 total time=   1.2s\n",
            "[CV 1/5; 5/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 1/5; 5/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=0.059 total time=   2.7s\n",
            "[CV 2/5; 5/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 2/5; 5/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=-0.499 total time=   2.4s\n",
            "[CV 3/5; 5/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 3/5; 5/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=-0.203 total time=   2.7s\n",
            "[CV 4/5; 5/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 4/5; 5/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=0.012 total time=   2.2s\n",
            "[CV 5/5; 5/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 5/5; 5/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=-0.940 total time=   2.4s\n",
            "[CV 1/5; 6/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=86\n",
            "[CV 1/5; 6/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=86;, score=0.105 total time=   5.4s\n",
            "[CV 2/5; 6/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=86\n",
            "[CV 2/5; 6/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=86;, score=-0.075 total time=   5.2s\n",
            "[CV 3/5; 6/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=86\n",
            "[CV 3/5; 6/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=86;, score=0.184 total time=   5.7s\n",
            "[CV 4/5; 6/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=86\n",
            "[CV 4/5; 6/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=86;, score=0.010 total time=   5.6s\n",
            "[CV 5/5; 6/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=86\n",
            "[CV 5/5; 6/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=86;, score=-1.054 total time=   6.5s\n",
            "[CV 1/5; 7/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18\n",
            "[CV 1/5; 7/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18;, score=-0.362 total time=   2.1s\n",
            "[CV 2/5; 7/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18\n",
            "[CV 2/5; 7/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18;, score=-0.712 total time=   2.1s\n",
            "[CV 3/5; 7/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18\n",
            "[CV 3/5; 7/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18;, score=0.148 total time=   2.1s\n",
            "[CV 4/5; 7/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18\n",
            "[CV 4/5; 7/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18;, score=0.039 total time=   2.0s\n",
            "[CV 5/5; 7/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18\n",
            "[CV 5/5; 7/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18;, score=-0.908 total time=   2.7s\n",
            "[CV 1/5; 8/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 1/5; 8/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-0.073 total time=   4.0s\n",
            "[CV 2/5; 8/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 2/5; 8/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-0.567 total time=   3.6s\n",
            "[CV 3/5; 8/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 3/5; 8/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=0.072 total time=   3.5s\n",
            "[CV 4/5; 8/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 4/5; 8/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=0.089 total time=   4.2s\n",
            "[CV 5/5; 8/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 5/5; 8/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-0.747 total time=   3.7s\n",
            "[CV 1/5; 9/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=12\n",
            "[CV 1/5; 9/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=12;, score=-0.928 total time=   9.5s\n",
            "[CV 2/5; 9/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=12\n",
            "[CV 2/5; 9/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=12;, score=-0.592 total time=   8.5s\n",
            "[CV 3/5; 9/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=12\n",
            "[CV 3/5; 9/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=12;, score=0.185 total time=   8.9s\n",
            "[CV 4/5; 9/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=12\n",
            "[CV 4/5; 9/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=12;, score=-0.029 total time=  10.3s\n",
            "[CV 5/5; 9/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=12\n",
            "[CV 5/5; 9/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=12;, score=-1.265 total time=   7.5s\n",
            "[CV 1/5; 10/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=18\n",
            "[CV 1/5; 10/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=18;, score=-0.177 total time=   5.0s\n",
            "[CV 2/5; 10/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=18\n",
            "[CV 2/5; 10/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=18;, score=-0.452 total time=   4.1s\n",
            "[CV 3/5; 10/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=18\n",
            "[CV 3/5; 10/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=18;, score=-0.117 total time=   4.5s\n",
            "[CV 4/5; 10/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=18\n",
            "[CV 4/5; 10/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=18;, score=0.133 total time=   5.3s\n",
            "[CV 5/5; 10/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=18\n",
            "[CV 5/5; 10/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=18;, score=-0.860 total time=   3.9s\n",
            "[CV 1/5; 11/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=12\n",
            "[CV 1/5; 11/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=12;, score=-0.331 total time=   8.4s\n",
            "[CV 2/5; 11/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=12\n",
            "[CV 2/5; 11/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=12;, score=-0.673 total time=   5.6s\n",
            "[CV 3/5; 11/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=12\n",
            "[CV 3/5; 11/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=12;, score=0.117 total time=   7.9s\n",
            "[CV 4/5; 11/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=12\n",
            "[CV 4/5; 11/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=12;, score=-0.146 total time=   6.6s\n",
            "[CV 5/5; 11/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=12\n",
            "[CV 5/5; 11/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=12;, score=-2.604 total time=   7.5s\n",
            "[CV 1/5; 12/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=762, regressor__n_estimators=86\n",
            "[CV 1/5; 12/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=762, regressor__n_estimators=86;, score=0.256 total time=   3.2s\n",
            "[CV 2/5; 12/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=762, regressor__n_estimators=86\n",
            "[CV 2/5; 12/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=762, regressor__n_estimators=86;, score=-0.597 total time=   3.7s\n",
            "[CV 3/5; 12/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=762, regressor__n_estimators=86\n",
            "[CV 3/5; 12/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=762, regressor__n_estimators=86;, score=0.112 total time=   3.7s\n",
            "[CV 4/5; 12/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=762, regressor__n_estimators=86\n",
            "[CV 4/5; 12/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=762, regressor__n_estimators=86;, score=0.187 total time=   3.4s\n",
            "[CV 5/5; 12/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=762, regressor__n_estimators=86\n",
            "[CV 5/5; 12/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=762, regressor__n_estimators=86;, score=-1.144 total time=   3.1s\n",
            "[CV 1/5; 13/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66\n",
            "[CV 1/5; 13/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66;, score=-0.314 total time=   3.3s\n",
            "[CV 2/5; 13/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66\n",
            "[CV 2/5; 13/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66;, score=-1.737 total time=   2.7s\n",
            "[CV 3/5; 13/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66\n",
            "[CV 3/5; 13/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66;, score=0.382 total time=   2.4s\n",
            "[CV 4/5; 13/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66\n",
            "[CV 4/5; 13/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66;, score=0.055 total time=   2.3s\n",
            "[CV 5/5; 13/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66\n",
            "[CV 5/5; 13/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66;, score=-1.105 total time=   2.3s\n",
            "[CV 1/5; 14/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=18\n",
            "[CV 1/5; 14/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=18;, score=-0.212 total time=  15.2s\n",
            "[CV 2/5; 14/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=18\n",
            "[CV 2/5; 14/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=18;, score=-0.739 total time=  15.6s\n",
            "[CV 3/5; 14/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=18\n",
            "[CV 3/5; 14/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=18;, score=0.134 total time=  14.0s\n",
            "[CV 4/5; 14/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=18\n",
            "[CV 4/5; 14/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=18;, score=-0.116 total time=  14.7s\n",
            "[CV 5/5; 14/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=18\n",
            "[CV 5/5; 14/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=18;, score=-1.248 total time=  13.7s\n",
            "[CV 1/5; 15/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=66\n",
            "[CV 1/5; 15/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=66;, score=-0.030 total time=   1.4s\n",
            "[CV 2/5; 15/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=66\n",
            "[CV 2/5; 15/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=66;, score=-0.568 total time=   1.5s\n",
            "[CV 3/5; 15/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=66\n",
            "[CV 3/5; 15/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=66;, score=0.101 total time=   1.7s\n",
            "[CV 4/5; 15/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=66\n",
            "[CV 4/5; 15/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=66;, score=0.209 total time=   2.0s\n",
            "[CV 5/5; 15/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=66\n",
            "[CV 5/5; 15/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=66;, score=-0.389 total time=   1.5s\n",
            "[CV 1/5; 16/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=79\n",
            "[CV 1/5; 16/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=79;, score=-0.235 total time=   3.5s\n",
            "[CV 2/5; 16/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=79\n",
            "[CV 2/5; 16/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=79;, score=0.488 total time=   3.7s\n",
            "[CV 3/5; 16/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=79\n",
            "[CV 3/5; 16/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=79;, score=0.118 total time=   4.8s\n",
            "[CV 4/5; 16/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=79\n",
            "[CV 4/5; 16/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=79;, score=0.132 total time=   3.6s\n",
            "[CV 5/5; 16/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=79\n",
            "[CV 5/5; 16/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=79;, score=-0.383 total time=   3.4s\n",
            "[CV 1/5; 17/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=85\n",
            "[CV 1/5; 17/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=85;, score=0.032 total time=  11.5s\n",
            "[CV 2/5; 17/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=85\n",
            "[CV 2/5; 17/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=85;, score=-0.672 total time=  10.4s\n",
            "[CV 3/5; 17/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=85\n",
            "[CV 3/5; 17/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=85;, score=0.463 total time=  10.9s\n",
            "[CV 4/5; 17/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=85\n",
            "[CV 4/5; 17/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=85;, score=0.052 total time=   9.2s\n",
            "[CV 5/5; 17/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=85\n",
            "[CV 5/5; 17/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=85;, score=-1.546 total time=   9.8s\n",
            "[CV 1/5; 18/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 1/5; 18/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=-0.768 total time=   3.1s\n",
            "[CV 2/5; 18/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 2/5; 18/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=-1.467 total time=   3.4s\n",
            "[CV 3/5; 18/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 3/5; 18/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=-0.185 total time=   3.0s\n",
            "[CV 4/5; 18/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 4/5; 18/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=0.104 total time=   2.8s\n",
            "[CV 5/5; 18/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 5/5; 18/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=-1.671 total time=   2.9s\n",
            "[CV 1/5; 19/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=45\n",
            "[CV 1/5; 19/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=45;, score=-0.118 total time=   6.4s\n",
            "[CV 2/5; 19/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=45\n",
            "[CV 2/5; 19/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=45;, score=-1.153 total time=   5.6s\n",
            "[CV 3/5; 19/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=45\n",
            "[CV 3/5; 19/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=45;, score=0.145 total time=   6.2s\n",
            "[CV 4/5; 19/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=45\n",
            "[CV 4/5; 19/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=45;, score=-0.002 total time=   5.2s\n",
            "[CV 5/5; 19/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=45\n",
            "[CV 5/5; 19/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=45;, score=-1.319 total time=   6.3s\n",
            "[CV 1/5; 20/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=874, regressor__n_estimators=86\n",
            "[CV 1/5; 20/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=874, regressor__n_estimators=86;, score=-0.461 total time=   7.7s\n",
            "[CV 2/5; 20/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=874, regressor__n_estimators=86\n",
            "[CV 2/5; 20/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=874, regressor__n_estimators=86;, score=-1.040 total time=   9.3s\n",
            "[CV 3/5; 20/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=874, regressor__n_estimators=86\n",
            "[CV 3/5; 20/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=874, regressor__n_estimators=86;, score=0.072 total time=   9.1s\n",
            "[CV 4/5; 20/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=874, regressor__n_estimators=86\n",
            "[CV 4/5; 20/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=874, regressor__n_estimators=86;, score=0.121 total time=   7.5s\n",
            "[CV 5/5; 20/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=874, regressor__n_estimators=86\n",
            "[CV 5/5; 20/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=874, regressor__n_estimators=86;, score=-0.324 total time=   9.7s\n",
            "[CV 1/5; 21/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 1/5; 21/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=-0.251 total time=   7.6s\n",
            "[CV 2/5; 21/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 2/5; 21/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=-1.321 total time=   7.3s\n",
            "[CV 3/5; 21/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 3/5; 21/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=0.464 total time=   7.7s\n",
            "[CV 4/5; 21/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 4/5; 21/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=0.093 total time=   7.0s\n",
            "[CV 5/5; 21/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 5/5; 21/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=-1.191 total time=   7.5s\n",
            "[CV 1/5; 22/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=37\n",
            "[CV 1/5; 22/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=37;, score=-0.194 total time=   3.1s\n",
            "[CV 2/5; 22/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=37\n",
            "[CV 2/5; 22/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=37;, score=-0.315 total time=   4.1s\n",
            "[CV 3/5; 22/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=37\n",
            "[CV 3/5; 22/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=37;, score=-0.045 total time=   3.3s\n",
            "[CV 4/5; 22/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=37\n",
            "[CV 4/5; 22/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=37;, score=0.143 total time=   4.2s\n",
            "[CV 5/5; 22/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=37\n",
            "[CV 5/5; 22/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=37;, score=-1.997 total time=   2.9s\n",
            "[CV 1/5; 23/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=887, regressor__n_estimators=66\n",
            "[CV 1/5; 23/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=887, regressor__n_estimators=66;, score=-0.179 total time=   8.6s\n",
            "[CV 2/5; 23/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=887, regressor__n_estimators=66\n",
            "[CV 2/5; 23/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=887, regressor__n_estimators=66;, score=0.044 total time=   8.2s\n",
            "[CV 3/5; 23/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=887, regressor__n_estimators=66\n",
            "[CV 3/5; 23/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=887, regressor__n_estimators=66;, score=0.235 total time=   6.9s\n",
            "[CV 4/5; 23/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=887, regressor__n_estimators=66\n",
            "[CV 4/5; 23/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=887, regressor__n_estimators=66;, score=0.092 total time=   8.0s\n",
            "[CV 5/5; 23/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=887, regressor__n_estimators=66\n",
            "[CV 5/5; 23/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=887, regressor__n_estimators=66;, score=-1.022 total time=   7.3s\n",
            "[CV 1/5; 24/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=926, regressor__n_estimators=37\n",
            "[CV 1/5; 24/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=926, regressor__n_estimators=37;, score=-0.342 total time=   7.4s\n",
            "[CV 2/5; 24/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=926, regressor__n_estimators=37\n",
            "[CV 2/5; 24/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=926, regressor__n_estimators=37;, score=-1.095 total time=   7.5s\n",
            "[CV 3/5; 24/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=926, regressor__n_estimators=37\n",
            "[CV 3/5; 24/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=926, regressor__n_estimators=37;, score=-0.525 total time=   7.0s\n",
            "[CV 4/5; 24/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=926, regressor__n_estimators=37\n",
            "[CV 4/5; 24/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=926, regressor__n_estimators=37;, score=0.281 total time=   8.0s\n",
            "[CV 5/5; 24/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=926, regressor__n_estimators=37\n",
            "[CV 5/5; 24/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=926, regressor__n_estimators=37;, score=-0.696 total time=   6.8s\n",
            "[CV 1/5; 25/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=621, regressor__n_estimators=85\n",
            "[CV 1/5; 25/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=621, regressor__n_estimators=85;, score=-0.157 total time=  47.0s\n",
            "[CV 2/5; 25/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=621, regressor__n_estimators=85\n",
            "[CV 2/5; 25/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=621, regressor__n_estimators=85;, score=-1.100 total time=  46.1s\n",
            "[CV 3/5; 25/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=621, regressor__n_estimators=85\n",
            "[CV 3/5; 25/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=621, regressor__n_estimators=85;, score=0.179 total time=  45.2s\n",
            "[CV 4/5; 25/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=621, regressor__n_estimators=85\n",
            "[CV 4/5; 25/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=621, regressor__n_estimators=85;, score=0.138 total time=  44.2s\n",
            "[CV 5/5; 25/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=621, regressor__n_estimators=85\n",
            "[CV 5/5; 25/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=621, regressor__n_estimators=85;, score=-1.222 total time=  55.2s\n",
            "[CV 1/5; 26/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=86\n",
            "[CV 1/5; 26/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=86;, score=-0.303 total time=   7.3s\n",
            "[CV 2/5; 26/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=86\n",
            "[CV 2/5; 26/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=86;, score=-0.880 total time=   5.8s\n",
            "[CV 3/5; 26/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=86\n",
            "[CV 3/5; 26/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=86;, score=0.430 total time=   7.0s\n",
            "[CV 4/5; 26/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=86\n",
            "[CV 4/5; 26/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=86;, score=0.072 total time=   5.3s\n",
            "[CV 5/5; 26/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=86\n",
            "[CV 5/5; 26/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=86;, score=-0.492 total time=   6.2s\n",
            "[CV 1/5; 27/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=37\n",
            "[CV 1/5; 27/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=37;, score=-0.510 total time=  29.4s\n",
            "[CV 2/5; 27/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=37\n",
            "[CV 2/5; 27/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=37;, score=-1.285 total time=  26.0s\n",
            "[CV 3/5; 27/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=37\n",
            "[CV 3/5; 27/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=37;, score=0.146 total time=  26.2s\n",
            "[CV 4/5; 27/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=37\n",
            "[CV 4/5; 27/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=37;, score=0.234 total time=  24.6s\n",
            "[CV 5/5; 27/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=37\n",
            "[CV 5/5; 27/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=37;, score=-1.258 total time=  25.6s\n",
            "[CV 1/5; 28/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13\n",
            "[CV 1/5; 28/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13;, score=-0.761 total time=   6.2s\n",
            "[CV 2/5; 28/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13\n",
            "[CV 2/5; 28/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13;, score=-1.895 total time=   6.0s\n",
            "[CV 3/5; 28/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13\n",
            "[CV 3/5; 28/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13;, score=0.019 total time=   6.0s\n",
            "[CV 4/5; 28/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13\n",
            "[CV 4/5; 28/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13;, score=0.436 total time=   6.1s\n",
            "[CV 5/5; 28/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13\n",
            "[CV 5/5; 28/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13;, score=-1.232 total time=   6.3s\n",
            "[CV 1/5; 29/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66\n",
            "[CV 1/5; 29/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66;, score=-0.056 total time=   2.9s\n",
            "[CV 2/5; 29/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66\n",
            "[CV 2/5; 29/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66;, score=-0.812 total time=   2.2s\n",
            "[CV 3/5; 29/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66\n",
            "[CV 3/5; 29/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66;, score=-0.010 total time=   2.2s\n",
            "[CV 4/5; 29/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66\n",
            "[CV 4/5; 29/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66;, score=0.044 total time=   2.1s\n",
            "[CV 5/5; 29/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66\n",
            "[CV 5/5; 29/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=66;, score=-0.823 total time=   2.0s\n",
            "[CV 1/5; 30/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=37\n",
            "[CV 1/5; 30/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=37;, score=-0.419 total time=  20.4s\n",
            "[CV 2/5; 30/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=37\n",
            "[CV 2/5; 30/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=37;, score=-1.314 total time=  20.6s\n",
            "[CV 3/5; 30/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=37\n",
            "[CV 3/5; 30/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=37;, score=0.071 total time=  19.8s\n",
            "[CV 4/5; 30/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=37\n",
            "[CV 4/5; 30/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=37;, score=-0.009 total time=  18.9s\n",
            "[CV 5/5; 30/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=37\n",
            "[CV 5/5; 30/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=37;, score=-1.315 total time=  19.9s\n",
            "[CV 1/5; 31/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=85\n",
            "[CV 1/5; 31/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=85;, score=-0.269 total time=   2.2s\n",
            "[CV 2/5; 31/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=85\n",
            "[CV 2/5; 31/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=85;, score=-1.552 total time=   3.0s\n",
            "[CV 3/5; 31/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=85\n",
            "[CV 3/5; 31/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=85;, score=0.119 total time=   2.1s\n",
            "[CV 4/5; 31/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=85\n",
            "[CV 4/5; 31/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=85;, score=0.025 total time=   2.0s\n",
            "[CV 5/5; 31/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=85\n",
            "[CV 5/5; 31/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=85;, score=-0.867 total time=   2.0s\n",
            "[CV 1/5; 32/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=18\n",
            "[CV 1/5; 32/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=18;, score=-0.073 total time=   4.8s\n",
            "[CV 2/5; 32/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=18\n",
            "[CV 2/5; 32/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=18;, score=-0.740 total time=   5.1s\n",
            "[CV 3/5; 32/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=18\n",
            "[CV 3/5; 32/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=18;, score=0.207 total time=   4.6s\n",
            "[CV 4/5; 32/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=18\n",
            "[CV 4/5; 32/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=18;, score=0.073 total time=   5.5s\n",
            "[CV 5/5; 32/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=18\n",
            "[CV 5/5; 32/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=18;, score=-1.098 total time=   4.4s\n",
            "[CV 1/5; 33/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=85\n",
            "[CV 1/5; 33/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=85;, score=-0.109 total time=   1.4s\n",
            "[CV 2/5; 33/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=85\n",
            "[CV 2/5; 33/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=85;, score=-0.710 total time=   1.3s\n",
            "[CV 3/5; 33/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=85\n",
            "[CV 3/5; 33/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=85;, score=-0.017 total time=   1.3s\n",
            "[CV 4/5; 33/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=85\n",
            "[CV 4/5; 33/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=85;, score=0.107 total time=   1.7s\n",
            "[CV 5/5; 33/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=85\n",
            "[CV 5/5; 33/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=85;, score=-1.380 total time=   2.1s\n",
            "[CV 1/5; 34/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=66\n",
            "[CV 1/5; 34/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=66;, score=-0.136 total time=   1.3s\n",
            "[CV 2/5; 34/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=66\n",
            "[CV 2/5; 34/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=66;, score=-0.309 total time=   1.3s\n",
            "[CV 3/5; 34/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=66\n",
            "[CV 3/5; 34/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=66;, score=0.214 total time=   1.3s\n",
            "[CV 4/5; 34/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=66\n",
            "[CV 4/5; 34/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=66;, score=0.238 total time=   1.3s\n",
            "[CV 5/5; 34/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=66\n",
            "[CV 5/5; 34/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=654, regressor__n_estimators=66;, score=-0.450 total time=   1.3s\n",
            "[CV 1/5; 35/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 1/5; 35/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-0.176 total time=  41.2s\n",
            "[CV 2/5; 35/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 2/5; 35/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-1.211 total time=  44.1s\n",
            "[CV 3/5; 35/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 3/5; 35/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=0.032 total time=  42.2s\n",
            "[CV 4/5; 35/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 4/5; 35/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=0.027 total time=  41.5s\n",
            "[CV 5/5; 35/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 5/5; 35/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-1.425 total time=  41.7s\n",
            "[CV 1/5; 36/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=621, regressor__n_estimators=66\n",
            "[CV 1/5; 36/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=621, regressor__n_estimators=66;, score=0.004 total time=   1.3s\n",
            "[CV 2/5; 36/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=621, regressor__n_estimators=66\n",
            "[CV 2/5; 36/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=621, regressor__n_estimators=66;, score=0.013 total time=   1.4s\n",
            "[CV 3/5; 36/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=621, regressor__n_estimators=66\n",
            "[CV 3/5; 36/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=621, regressor__n_estimators=66;, score=0.311 total time=   1.3s\n",
            "[CV 4/5; 36/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=621, regressor__n_estimators=66\n",
            "[CV 4/5; 36/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=621, regressor__n_estimators=66;, score=0.036 total time=   1.3s\n",
            "[CV 5/5; 36/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=621, regressor__n_estimators=66\n",
            "[CV 5/5; 36/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=621, regressor__n_estimators=66;, score=-0.953 total time=   2.0s\n",
            "[CV 1/5; 37/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=79\n",
            "[CV 1/5; 37/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=79;, score=-0.556 total time=   4.2s\n",
            "[CV 2/5; 37/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=79\n",
            "[CV 2/5; 37/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=79;, score=-1.425 total time=   4.2s\n",
            "[CV 3/5; 37/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=79\n",
            "[CV 3/5; 37/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=79;, score=0.067 total time=   4.8s\n",
            "[CV 4/5; 37/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=79\n",
            "[CV 4/5; 37/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=79;, score=0.014 total time=   4.3s\n",
            "[CV 5/5; 37/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=79\n",
            "[CV 5/5; 37/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=79;, score=-0.925 total time=   4.1s\n",
            "[CV 1/5; 38/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=53\n",
            "[CV 1/5; 38/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=53;, score=-0.524 total time=   1.8s\n",
            "[CV 2/5; 38/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=53\n",
            "[CV 2/5; 38/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=53;, score=-0.696 total time=   2.2s\n",
            "[CV 3/5; 38/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=53\n",
            "[CV 3/5; 38/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=53;, score=0.187 total time=   2.5s\n",
            "[CV 4/5; 38/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=53\n",
            "[CV 4/5; 38/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=53;, score=0.278 total time=   1.6s\n",
            "[CV 5/5; 38/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=53\n",
            "[CV 5/5; 38/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=53;, score=-0.816 total time=   1.4s\n",
            "[CV 1/5; 39/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=13\n",
            "[CV 1/5; 39/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=13;, score=-0.168 total time=   8.1s\n",
            "[CV 2/5; 39/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=13\n",
            "[CV 2/5; 39/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=13;, score=-1.413 total time=   6.2s\n",
            "[CV 3/5; 39/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=13\n",
            "[CV 3/5; 39/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=13;, score=0.156 total time=   7.8s\n",
            "[CV 4/5; 39/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=13\n",
            "[CV 4/5; 39/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=13;, score=0.159 total time=   6.8s\n",
            "[CV 5/5; 39/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=13\n",
            "[CV 5/5; 39/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=13;, score=-0.667 total time=   8.1s\n",
            "[CV 1/5; 40/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=79\n",
            "[CV 1/5; 40/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=79;, score=-0.586 total time=  10.2s\n",
            "[CV 2/5; 40/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=79\n",
            "[CV 2/5; 40/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=79;, score=-1.240 total time=   8.3s\n",
            "[CV 3/5; 40/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=79\n",
            "[CV 3/5; 40/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=79;, score=0.286 total time=   9.5s\n",
            "[CV 4/5; 40/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=79\n",
            "[CV 4/5; 40/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=79;, score=-0.045 total time=   9.9s\n",
            "[CV 5/5; 40/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=79\n",
            "[CV 5/5; 40/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=79;, score=-0.861 total time=   9.0s\n",
            "[CV 1/5; 41/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=66\n",
            "[CV 1/5; 41/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=66;, score=0.184 total time=   5.4s\n",
            "[CV 2/5; 41/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=66\n",
            "[CV 2/5; 41/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=66;, score=-0.608 total time=   4.8s\n",
            "[CV 3/5; 41/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=66\n",
            "[CV 3/5; 41/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=66;, score=0.215 total time=   6.6s\n",
            "[CV 4/5; 41/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=66\n",
            "[CV 4/5; 41/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=66;, score=0.217 total time=   4.9s\n",
            "[CV 5/5; 41/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=66\n",
            "[CV 5/5; 41/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=66;, score=-1.027 total time=   6.1s\n",
            "[CV 1/5; 42/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=18\n",
            "[CV 1/5; 42/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=18;, score=0.018 total time=   2.6s\n",
            "[CV 2/5; 42/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=18\n",
            "[CV 2/5; 42/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=18;, score=0.283 total time=   2.8s\n",
            "[CV 3/5; 42/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=18\n",
            "[CV 3/5; 42/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=18;, score=-0.003 total time=   2.6s\n",
            "[CV 4/5; 42/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=18\n",
            "[CV 4/5; 42/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=18;, score=0.239 total time=   3.6s\n",
            "[CV 5/5; 42/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=18\n",
            "[CV 5/5; 42/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=18;, score=-1.093 total time=   2.7s\n",
            "[CV 1/5; 43/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=79\n",
            "[CV 1/5; 43/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=79;, score=-0.003 total time=   6.0s\n",
            "[CV 2/5; 43/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=79\n",
            "[CV 2/5; 43/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=79;, score=-0.335 total time=   7.2s\n",
            "[CV 3/5; 43/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=79\n",
            "[CV 3/5; 43/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=79;, score=0.074 total time=   6.4s\n",
            "[CV 4/5; 43/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=79\n",
            "[CV 4/5; 43/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=79;, score=0.208 total time=   7.2s\n",
            "[CV 5/5; 43/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=79\n",
            "[CV 5/5; 43/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=79;, score=-1.087 total time=   7.1s\n",
            "[CV 1/5; 44/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=13\n",
            "[CV 1/5; 44/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=13;, score=-0.814 total time=   4.9s\n",
            "[CV 2/5; 44/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=13\n",
            "[CV 2/5; 44/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=13;, score=-2.500 total time=   4.2s\n",
            "[CV 3/5; 44/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=13\n",
            "[CV 3/5; 44/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=13;, score=0.115 total time=   5.1s\n",
            "[CV 4/5; 44/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=13\n",
            "[CV 4/5; 44/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=13;, score=0.057 total time=   3.8s\n",
            "[CV 5/5; 44/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=13\n",
            "[CV 5/5; 44/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=13;, score=-1.436 total time=   4.9s\n",
            "[CV 1/5; 45/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=53\n",
            "[CV 1/5; 45/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=53;, score=-0.155 total time=   2.6s\n",
            "[CV 2/5; 45/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=53\n",
            "[CV 2/5; 45/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=53;, score=-0.152 total time=   2.0s\n",
            "[CV 3/5; 45/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=53\n",
            "[CV 3/5; 45/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=53;, score=-0.049 total time=   1.9s\n",
            "[CV 4/5; 45/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=53\n",
            "[CV 4/5; 45/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=53;, score=0.200 total time=   1.8s\n",
            "[CV 5/5; 45/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=53\n",
            "[CV 5/5; 45/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=53;, score=-0.870 total time=   1.8s\n",
            "[CV 1/5; 46/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=85\n",
            "[CV 1/5; 46/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=85;, score=-0.177 total time=   2.5s\n",
            "[CV 2/5; 46/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=85\n",
            "[CV 2/5; 46/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=85;, score=-1.067 total time=   3.4s\n",
            "[CV 3/5; 46/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=85\n",
            "[CV 3/5; 46/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=85;, score=0.156 total time=   2.5s\n",
            "[CV 4/5; 46/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=85\n",
            "[CV 4/5; 46/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=85;, score=0.124 total time=   2.5s\n",
            "[CV 5/5; 46/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=85\n",
            "[CV 5/5; 46/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=85;, score=-1.142 total time=   2.5s\n",
            "[CV 1/5; 47/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=45\n",
            "[CV 1/5; 47/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=45;, score=-0.647 total time=  25.3s\n",
            "[CV 2/5; 47/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=45\n",
            "[CV 2/5; 47/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=45;, score=-1.200 total time=  25.1s\n",
            "[CV 3/5; 47/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=45\n",
            "[CV 3/5; 47/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=45;, score=0.086 total time=  23.3s\n",
            "[CV 4/5; 47/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=45\n",
            "[CV 4/5; 47/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=45;, score=0.014 total time=  23.3s\n",
            "[CV 5/5; 47/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=45\n",
            "[CV 5/5; 47/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=887, regressor__n_estimators=45;, score=-0.906 total time=  24.5s\n",
            "[CV 1/5; 48/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86\n",
            "[CV 1/5; 48/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86;, score=-0.085 total time=   5.5s\n",
            "[CV 2/5; 48/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86\n",
            "[CV 2/5; 48/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86;, score=-1.145 total time=   7.2s\n",
            "[CV 3/5; 48/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86\n",
            "[CV 3/5; 48/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86;, score=0.235 total time=   5.4s\n",
            "[CV 4/5; 48/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86\n",
            "[CV 4/5; 48/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86;, score=0.282 total time=   6.3s\n",
            "[CV 5/5; 48/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86\n",
            "[CV 5/5; 48/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86;, score=-1.080 total time=   5.2s\n",
            "[CV 1/5; 49/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13\n",
            "[CV 1/5; 49/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13;, score=-0.081 total time=   1.7s\n",
            "[CV 2/5; 49/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13\n",
            "[CV 2/5; 49/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13;, score=-0.732 total time=   2.2s\n",
            "[CV 3/5; 49/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13\n",
            "[CV 3/5; 49/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13;, score=-0.093 total time=   2.2s\n",
            "[CV 4/5; 49/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13\n",
            "[CV 4/5; 49/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13;, score=0.152 total time=   1.8s\n",
            "[CV 5/5; 49/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13\n",
            "[CV 5/5; 49/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=13;, score=-2.414 total time=   1.4s\n",
            "[CV 1/5; 50/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=762, regressor__n_estimators=13\n",
            "[CV 1/5; 50/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=762, regressor__n_estimators=13;, score=0.029 total time=   5.5s\n",
            "[CV 2/5; 50/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=762, regressor__n_estimators=13\n",
            "[CV 2/5; 50/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=762, regressor__n_estimators=13;, score=-0.699 total time=   6.3s\n",
            "[CV 3/5; 50/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=762, regressor__n_estimators=13\n",
            "[CV 3/5; 50/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=762, regressor__n_estimators=13;, score=-0.020 total time=   6.5s\n",
            "[CV 4/5; 50/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=762, regressor__n_estimators=13\n",
            "[CV 4/5; 50/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=762, regressor__n_estimators=13;, score=-0.118 total time=   6.8s\n",
            "[CV 5/5; 50/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=762, regressor__n_estimators=13\n",
            "[CV 5/5; 50/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=762, regressor__n_estimators=13;, score=-3.490 total time=   5.3s\n",
            "[CV 1/5; 51/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66\n",
            "[CV 1/5; 51/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66;, score=-0.031 total time=   3.2s\n",
            "[CV 2/5; 51/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66\n",
            "[CV 2/5; 51/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66;, score=-0.993 total time=   2.2s\n",
            "[CV 3/5; 51/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66\n",
            "[CV 3/5; 51/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66;, score=0.112 total time=   2.0s\n",
            "[CV 4/5; 51/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66\n",
            "[CV 4/5; 51/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66;, score=-0.080 total time=   2.1s\n",
            "[CV 5/5; 51/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66\n",
            "[CV 5/5; 51/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=764, regressor__n_estimators=66;, score=-0.376 total time=   2.1s\n",
            "[CV 1/5; 52/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 1/5; 52/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-0.082 total time=   0.9s\n",
            "[CV 2/5; 52/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 2/5; 52/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-0.419 total time=   1.1s\n",
            "[CV 3/5; 52/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 3/5; 52/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=0.300 total time=   1.4s\n",
            "[CV 4/5; 52/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 4/5; 52/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=0.057 total time=   1.2s\n",
            "[CV 5/5; 52/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 5/5; 52/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-1.153 total time=   0.9s\n",
            "[CV 1/5; 53/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 1/5; 53/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=0.211 total time=   2.9s\n",
            "[CV 2/5; 53/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 2/5; 53/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=-0.423 total time=   3.1s\n",
            "[CV 3/5; 53/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 3/5; 53/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=0.206 total time=   2.5s\n",
            "[CV 4/5; 53/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 4/5; 53/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=-0.016 total time=   3.7s\n",
            "[CV 5/5; 53/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 5/5; 53/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=-0.706 total time=   2.9s\n",
            "[CV 1/5; 54/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=53\n",
            "[CV 1/5; 54/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=53;, score=-0.099 total time=   4.1s\n",
            "[CV 2/5; 54/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=53\n",
            "[CV 2/5; 54/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=53;, score=-2.335 total time=   5.0s\n",
            "[CV 3/5; 54/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=53\n",
            "[CV 3/5; 54/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=53;, score=0.601 total time=   3.8s\n",
            "[CV 4/5; 54/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=53\n",
            "[CV 4/5; 54/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=53;, score=0.151 total time=   3.8s\n",
            "[CV 5/5; 54/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=53\n",
            "[CV 5/5; 54/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=53;, score=-1.569 total time=   4.9s\n",
            "[CV 1/5; 55/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86\n",
            "[CV 1/5; 55/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86;, score=-0.277 total time=   4.7s\n",
            "[CV 2/5; 55/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86\n",
            "[CV 2/5; 55/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86;, score=-0.485 total time=   4.7s\n",
            "[CV 3/5; 55/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86\n",
            "[CV 3/5; 55/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86;, score=-0.067 total time=   5.9s\n",
            "[CV 4/5; 55/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86\n",
            "[CV 4/5; 55/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86;, score=0.016 total time=   4.6s\n",
            "[CV 5/5; 55/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86\n",
            "[CV 5/5; 55/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86;, score=-1.103 total time=   5.3s\n",
            "[CV 1/5; 56/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=13\n",
            "[CV 1/5; 56/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=13;, score=-0.050 total time=   5.8s\n",
            "[CV 2/5; 56/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=13\n",
            "[CV 2/5; 56/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=13;, score=-0.202 total time=   6.5s\n",
            "[CV 3/5; 56/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=13\n",
            "[CV 3/5; 56/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=13;, score=0.190 total time=   5.6s\n",
            "[CV 4/5; 56/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=13\n",
            "[CV 4/5; 56/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=13;, score=0.107 total time=   5.2s\n",
            "[CV 5/5; 56/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=13\n",
            "[CV 5/5; 56/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=13;, score=-1.409 total time=   6.1s\n",
            "[CV 1/5; 57/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=86\n",
            "[CV 1/5; 57/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=86;, score=-0.129 total time=   4.3s\n",
            "[CV 2/5; 57/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=86\n",
            "[CV 2/5; 57/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=86;, score=-0.721 total time=   4.5s\n",
            "[CV 3/5; 57/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=86\n",
            "[CV 3/5; 57/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=86;, score=-0.053 total time=   4.3s\n",
            "[CV 4/5; 57/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=86\n",
            "[CV 4/5; 57/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=86;, score=0.008 total time=   3.8s\n",
            "[CV 5/5; 57/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=86\n",
            "[CV 5/5; 57/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=86;, score=-1.893 total time=   4.9s\n",
            "[CV 1/5; 58/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=172, regressor__n_estimators=37\n",
            "[CV 1/5; 58/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=172, regressor__n_estimators=37;, score=0.036 total time=   1.9s\n",
            "[CV 2/5; 58/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=172, regressor__n_estimators=37\n",
            "[CV 2/5; 58/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=172, regressor__n_estimators=37;, score=-0.397 total time=   1.8s\n",
            "[CV 3/5; 58/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=172, regressor__n_estimators=37\n",
            "[CV 3/5; 58/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=172, regressor__n_estimators=37;, score=0.034 total time=   1.7s\n",
            "[CV 4/5; 58/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=172, regressor__n_estimators=37\n",
            "[CV 4/5; 58/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=172, regressor__n_estimators=37;, score=-0.015 total time=   1.6s\n",
            "[CV 5/5; 58/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=172, regressor__n_estimators=37\n",
            "[CV 5/5; 58/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=172, regressor__n_estimators=37;, score=-0.800 total time=   1.6s\n",
            "[CV 1/5; 59/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=66\n",
            "[CV 1/5; 59/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=66;, score=0.069 total time=   1.5s\n",
            "[CV 2/5; 59/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=66\n",
            "[CV 2/5; 59/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=66;, score=0.082 total time=   2.3s\n",
            "[CV 3/5; 59/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=66\n",
            "[CV 3/5; 59/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=66;, score=0.161 total time=   2.0s\n",
            "[CV 4/5; 59/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=66\n",
            "[CV 4/5; 59/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=66;, score=0.215 total time=   1.5s\n",
            "[CV 5/5; 59/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=66\n",
            "[CV 5/5; 59/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=762, regressor__n_estimators=66;, score=-0.878 total time=   1.6s\n",
            "[CV 1/5; 60/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=874, regressor__n_estimators=66\n",
            "[CV 1/5; 60/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=874, regressor__n_estimators=66;, score=-0.108 total time=   7.3s\n",
            "[CV 2/5; 60/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=874, regressor__n_estimators=66\n",
            "[CV 2/5; 60/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=874, regressor__n_estimators=66;, score=-0.477 total time=   6.0s\n",
            "[CV 3/5; 60/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=874, regressor__n_estimators=66\n",
            "[CV 3/5; 60/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=874, regressor__n_estimators=66;, score=0.620 total time=   6.2s\n",
            "[CV 4/5; 60/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=874, regressor__n_estimators=66\n",
            "[CV 4/5; 60/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=874, regressor__n_estimators=66;, score=0.166 total time=   6.6s\n",
            "[CV 5/5; 60/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=874, regressor__n_estimators=66\n",
            "[CV 5/5; 60/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=874, regressor__n_estimators=66;, score=-2.384 total time=   6.6s\n",
            "[CV 1/5; 61/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=53\n",
            "[CV 1/5; 61/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=53;, score=-0.040 total time=   7.6s\n",
            "[CV 2/5; 61/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=53\n",
            "[CV 2/5; 61/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=53;, score=0.003 total time=   7.5s\n",
            "[CV 3/5; 61/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=53\n",
            "[CV 3/5; 61/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=53;, score=0.090 total time=   7.5s\n",
            "[CV 4/5; 61/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=53\n",
            "[CV 4/5; 61/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=53;, score=0.410 total time=   7.1s\n",
            "[CV 5/5; 61/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=53\n",
            "[CV 5/5; 61/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=654, regressor__n_estimators=53;, score=-2.317 total time=   7.2s\n",
            "[CV 1/5; 62/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 1/5; 62/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=-0.472 total time=   1.3s\n",
            "[CV 2/5; 62/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 2/5; 62/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=-2.163 total time=   1.0s\n",
            "[CV 3/5; 62/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 3/5; 62/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=0.091 total time=   0.9s\n",
            "[CV 4/5; 62/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 4/5; 62/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=0.055 total time=   0.8s\n",
            "[CV 5/5; 62/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13\n",
            "[CV 5/5; 62/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=356, regressor__n_estimators=13;, score=-0.646 total time=   0.8s\n",
            "[CV 1/5; 63/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=79\n",
            "[CV 1/5; 63/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=79;, score=0.236 total time=   1.6s\n",
            "[CV 2/5; 63/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=79\n",
            "[CV 2/5; 63/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=79;, score=-1.261 total time=   1.6s\n",
            "[CV 3/5; 63/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=79\n",
            "[CV 3/5; 63/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=79;, score=0.176 total time=   1.6s\n",
            "[CV 4/5; 63/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=79\n",
            "[CV 4/5; 63/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=79;, score=0.108 total time=   1.7s\n",
            "[CV 5/5; 63/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=79\n",
            "[CV 5/5; 63/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=79;, score=-1.364 total time=   2.7s\n",
            "[CV 1/5; 64/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=874, regressor__n_estimators=18\n",
            "[CV 1/5; 64/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=874, regressor__n_estimators=18;, score=-0.583 total time=   7.2s\n",
            "[CV 2/5; 64/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=874, regressor__n_estimators=18\n",
            "[CV 2/5; 64/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=874, regressor__n_estimators=18;, score=-1.173 total time=   7.4s\n",
            "[CV 3/5; 64/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=874, regressor__n_estimators=18\n",
            "[CV 3/5; 64/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=874, regressor__n_estimators=18;, score=0.451 total time=   6.8s\n",
            "[CV 4/5; 64/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=874, regressor__n_estimators=18\n",
            "[CV 4/5; 64/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=874, regressor__n_estimators=18;, score=0.384 total time=   7.6s\n",
            "[CV 5/5; 64/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=874, regressor__n_estimators=18\n",
            "[CV 5/5; 64/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=874, regressor__n_estimators=18;, score=-0.798 total time=   6.2s\n",
            "[CV 1/5; 65/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=887, regressor__n_estimators=53\n",
            "[CV 1/5; 65/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=887, regressor__n_estimators=53;, score=0.090 total time=   2.7s\n",
            "[CV 2/5; 65/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=887, regressor__n_estimators=53\n",
            "[CV 2/5; 65/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=887, regressor__n_estimators=53;, score=0.095 total time=   1.7s\n",
            "[CV 3/5; 65/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=887, regressor__n_estimators=53\n",
            "[CV 3/5; 65/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=887, regressor__n_estimators=53;, score=0.123 total time=   1.7s\n",
            "[CV 4/5; 65/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=887, regressor__n_estimators=53\n",
            "[CV 4/5; 65/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=887, regressor__n_estimators=53;, score=0.173 total time=   1.7s\n",
            "[CV 5/5; 65/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=887, regressor__n_estimators=53\n",
            "[CV 5/5; 65/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=887, regressor__n_estimators=53;, score=-1.122 total time=   1.7s\n",
            "[CV 1/5; 66/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=18\n",
            "[CV 1/5; 66/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=18;, score=-0.028 total time=   0.4s\n",
            "[CV 2/5; 66/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=18\n",
            "[CV 2/5; 66/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=18;, score=-1.106 total time=   0.4s\n",
            "[CV 3/5; 66/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=18\n",
            "[CV 3/5; 66/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=18;, score=0.010 total time=   0.4s\n",
            "[CV 4/5; 66/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=18\n",
            "[CV 4/5; 66/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=18;, score=-0.124 total time=   0.4s\n",
            "[CV 5/5; 66/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=18\n",
            "[CV 5/5; 66/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=172, regressor__n_estimators=18;, score=-0.857 total time=   0.4s\n",
            "[CV 1/5; 67/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 1/5; 67/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=0.126 total time=   6.4s\n",
            "[CV 2/5; 67/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 2/5; 67/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=-0.356 total time=   4.8s\n",
            "[CV 3/5; 67/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 3/5; 67/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=0.369 total time=   5.4s\n",
            "[CV 4/5; 67/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 4/5; 67/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=0.086 total time=   4.7s\n",
            "[CV 5/5; 67/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 5/5; 67/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=-1.046 total time=   4.6s\n",
            "[CV 1/5; 68/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=86\n",
            "[CV 1/5; 68/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=86;, score=-0.280 total time=  43.7s\n",
            "[CV 2/5; 68/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=86\n",
            "[CV 2/5; 68/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=86;, score=-1.434 total time=  44.2s\n",
            "[CV 3/5; 68/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=86\n",
            "[CV 3/5; 68/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=86;, score=0.070 total time=  42.6s\n",
            "[CV 4/5; 68/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=86\n",
            "[CV 4/5; 68/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=86;, score=0.024 total time=  40.3s\n",
            "[CV 5/5; 68/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=86\n",
            "[CV 5/5; 68/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=356, regressor__n_estimators=86;, score=-1.197 total time=  45.1s\n",
            "[CV 1/5; 69/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 1/5; 69/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=-0.626 total time=  41.2s\n",
            "[CV 2/5; 69/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 2/5; 69/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=-1.204 total time=  43.1s\n",
            "[CV 3/5; 69/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 3/5; 69/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=0.081 total time=  45.2s\n",
            "[CV 4/5; 69/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 4/5; 69/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=0.077 total time=  39.9s\n",
            "[CV 5/5; 69/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 5/5; 69/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=-1.264 total time=  44.5s\n",
            "[CV 1/5; 70/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=37\n",
            "[CV 1/5; 70/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=37;, score=-0.206 total time=  20.2s\n",
            "[CV 2/5; 70/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=37\n",
            "[CV 2/5; 70/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=37;, score=-1.056 total time=  20.8s\n",
            "[CV 3/5; 70/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=37\n",
            "[CV 3/5; 70/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=37;, score=0.181 total time=  20.2s\n",
            "[CV 4/5; 70/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=37\n",
            "[CV 4/5; 70/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=37;, score=0.116 total time=  18.8s\n",
            "[CV 5/5; 70/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=37\n",
            "[CV 5/5; 70/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=277, regressor__n_estimators=37;, score=-1.190 total time=  20.9s\n",
            "[CV 1/5; 71/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=13\n",
            "[CV 1/5; 71/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=13;, score=-0.261 total time=   1.7s\n",
            "[CV 2/5; 71/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=13\n",
            "[CV 2/5; 71/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=13;, score=-0.263 total time=   1.6s\n",
            "[CV 3/5; 71/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=13\n",
            "[CV 3/5; 71/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=13;, score=0.161 total time=   1.6s\n",
            "[CV 4/5; 71/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=13\n",
            "[CV 4/5; 71/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=13;, score=0.167 total time=   1.7s\n",
            "[CV 5/5; 71/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=13\n",
            "[CV 5/5; 71/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=13;, score=-0.111 total time=   2.4s\n",
            "[CV 1/5; 72/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18\n",
            "[CV 1/5; 72/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18;, score=-0.790 total time=  14.8s\n",
            "[CV 2/5; 72/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18\n",
            "[CV 2/5; 72/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18;, score=-1.634 total time=  15.0s\n",
            "[CV 3/5; 72/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18\n",
            "[CV 3/5; 72/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18;, score=0.171 total time=  13.9s\n",
            "[CV 4/5; 72/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18\n",
            "[CV 4/5; 72/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18;, score=-0.092 total time=  15.3s\n",
            "[CV 5/5; 72/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18\n",
            "[CV 5/5; 72/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=874, regressor__n_estimators=18;, score=-1.159 total time=  14.4s\n",
            "[CV 1/5; 73/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=85\n",
            "[CV 1/5; 73/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=85;, score=-0.075 total time=   0.9s\n",
            "[CV 2/5; 73/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=85\n",
            "[CV 2/5; 73/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=85;, score=-0.188 total time=   0.8s\n",
            "[CV 3/5; 73/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=85\n",
            "[CV 3/5; 73/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=85;, score=0.179 total time=   0.7s\n",
            "[CV 4/5; 73/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=85\n",
            "[CV 4/5; 73/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=85;, score=-0.144 total time=   0.6s\n",
            "[CV 5/5; 73/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=85\n",
            "[CV 5/5; 73/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=172, regressor__n_estimators=85;, score=-0.012 total time=   0.5s\n",
            "[CV 1/5; 74/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=86\n",
            "[CV 1/5; 74/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=86;, score=-0.723 total time=   2.5s\n",
            "[CV 2/5; 74/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=86\n",
            "[CV 2/5; 74/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=86;, score=-1.705 total time=   2.5s\n",
            "[CV 3/5; 74/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=86\n",
            "[CV 3/5; 74/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=86;, score=0.076 total time=   2.3s\n",
            "[CV 4/5; 74/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=86\n",
            "[CV 4/5; 74/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=86;, score=-0.117 total time=   2.7s\n",
            "[CV 5/5; 74/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=86\n",
            "[CV 5/5; 74/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=86;, score=-0.759 total time=   2.6s\n",
            "[CV 1/5; 75/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=621, regressor__n_estimators=45\n",
            "[CV 1/5; 75/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=621, regressor__n_estimators=45;, score=-2.280 total time=   4.6s\n",
            "[CV 2/5; 75/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=621, regressor__n_estimators=45\n",
            "[CV 2/5; 75/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=621, regressor__n_estimators=45;, score=-0.403 total time=   4.3s\n",
            "[CV 3/5; 75/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=621, regressor__n_estimators=45\n",
            "[CV 3/5; 75/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=621, regressor__n_estimators=45;, score=-0.177 total time=   6.2s\n",
            "[CV 4/5; 75/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=621, regressor__n_estimators=45\n",
            "[CV 4/5; 75/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=621, regressor__n_estimators=45;, score=-0.019 total time=   4.4s\n",
            "[CV 5/5; 75/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=621, regressor__n_estimators=45\n",
            "[CV 5/5; 75/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=621, regressor__n_estimators=45;, score=-0.644 total time=   5.3s\n",
            "[CV 1/5; 76/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 1/5; 76/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=-0.085 total time=   4.7s\n",
            "[CV 2/5; 76/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 2/5; 76/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=-0.795 total time=   4.8s\n",
            "[CV 3/5; 76/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 3/5; 76/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=-0.118 total time=   5.3s\n",
            "[CV 4/5; 76/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 4/5; 76/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=-0.148 total time=   4.6s\n",
            "[CV 5/5; 76/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85\n",
            "[CV 5/5; 76/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=654, regressor__n_estimators=85;, score=-0.837 total time=   5.7s\n",
            "[CV 1/5; 77/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86\n",
            "[CV 1/5; 77/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86;, score=-1.553 total time=   5.9s\n",
            "[CV 2/5; 77/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86\n",
            "[CV 2/5; 77/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86;, score=-1.103 total time=   8.0s\n",
            "[CV 3/5; 77/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86\n",
            "[CV 3/5; 77/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86;, score=0.350 total time=   5.6s\n",
            "[CV 4/5; 77/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86\n",
            "[CV 4/5; 77/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86;, score=0.229 total time=   7.2s\n",
            "[CV 5/5; 77/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86\n",
            "[CV 5/5; 77/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=86;, score=-0.639 total time=   6.3s\n",
            "[CV 1/5; 78/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=53\n",
            "[CV 1/5; 78/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=53;, score=-0.428 total time=   4.3s\n",
            "[CV 2/5; 78/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=53\n",
            "[CV 2/5; 78/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=53;, score=-0.761 total time=   2.9s\n",
            "[CV 3/5; 78/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=53\n",
            "[CV 3/5; 78/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=53;, score=0.045 total time=   3.0s\n",
            "[CV 4/5; 78/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=53\n",
            "[CV 4/5; 78/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=53;, score=-0.222 total time=   3.0s\n",
            "[CV 5/5; 78/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=53\n",
            "[CV 5/5; 78/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=764, regressor__n_estimators=53;, score=-1.027 total time=   4.0s\n",
            "[CV 1/5; 79/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=79\n",
            "[CV 1/5; 79/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=79;, score=-0.217 total time=   2.0s\n",
            "[CV 2/5; 79/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=79\n",
            "[CV 2/5; 79/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=79;, score=-1.291 total time=   2.1s\n",
            "[CV 3/5; 79/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=79\n",
            "[CV 3/5; 79/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=79;, score=0.190 total time=   2.1s\n",
            "[CV 4/5; 79/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=79\n",
            "[CV 4/5; 79/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=79;, score=-0.071 total time=   2.0s\n",
            "[CV 5/5; 79/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=79\n",
            "[CV 5/5; 79/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=621, regressor__n_estimators=79;, score=-0.525 total time=   2.8s\n",
            "[CV 1/5; 80/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=79\n",
            "[CV 1/5; 80/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=79;, score=-0.588 total time=   6.6s\n",
            "[CV 2/5; 80/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=79\n",
            "[CV 2/5; 80/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=79;, score=-1.125 total time=   7.3s\n",
            "[CV 3/5; 80/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=79\n",
            "[CV 3/5; 80/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=79;, score=-0.165 total time=   6.5s\n",
            "[CV 4/5; 80/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=79\n",
            "[CV 4/5; 80/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=79;, score=-0.159 total time=   7.9s\n",
            "[CV 5/5; 80/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=79\n",
            "[CV 5/5; 80/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=926, regressor__n_estimators=79;, score=-0.361 total time=   7.2s\n",
            "[CV 1/5; 81/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=762, regressor__n_estimators=12\n",
            "[CV 1/5; 81/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=762, regressor__n_estimators=12;, score=0.247 total time=   5.3s\n",
            "[CV 2/5; 81/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=762, regressor__n_estimators=12\n",
            "[CV 2/5; 81/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=762, regressor__n_estimators=12;, score=-0.456 total time=   4.4s\n",
            "[CV 3/5; 81/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=762, regressor__n_estimators=12\n",
            "[CV 3/5; 81/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=762, regressor__n_estimators=12;, score=0.078 total time=   6.4s\n",
            "[CV 4/5; 81/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=762, regressor__n_estimators=12\n",
            "[CV 4/5; 81/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=762, regressor__n_estimators=12;, score=0.062 total time=   4.6s\n",
            "[CV 5/5; 81/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=762, regressor__n_estimators=12\n",
            "[CV 5/5; 81/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=762, regressor__n_estimators=12;, score=-1.381 total time=   4.4s\n",
            "[CV 1/5; 82/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=37\n",
            "[CV 1/5; 82/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=37;, score=-0.362 total time=   3.2s\n",
            "[CV 2/5; 82/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=37\n",
            "[CV 2/5; 82/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=37;, score=-1.020 total time=   2.3s\n",
            "[CV 3/5; 82/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=37\n",
            "[CV 3/5; 82/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=37;, score=-0.039 total time=   2.5s\n",
            "[CV 4/5; 82/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=37\n",
            "[CV 4/5; 82/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=37;, score=0.079 total time=   2.3s\n",
            "[CV 5/5; 82/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=37\n",
            "[CV 5/5; 82/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=621, regressor__n_estimators=37;, score=-1.563 total time=   2.8s\n",
            "[CV 1/5; 83/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=277, regressor__n_estimators=12\n",
            "[CV 1/5; 83/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=277, regressor__n_estimators=12;, score=0.293 total time=   2.5s\n",
            "[CV 2/5; 83/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=277, regressor__n_estimators=12\n",
            "[CV 2/5; 83/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=277, regressor__n_estimators=12;, score=-0.176 total time=   2.0s\n",
            "[CV 3/5; 83/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=277, regressor__n_estimators=12\n",
            "[CV 3/5; 83/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=277, regressor__n_estimators=12;, score=0.446 total time=   1.9s\n",
            "[CV 4/5; 83/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=277, regressor__n_estimators=12\n",
            "[CV 4/5; 83/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=277, regressor__n_estimators=12;, score=0.187 total time=   2.2s\n",
            "[CV 5/5; 83/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=277, regressor__n_estimators=12\n",
            "[CV 5/5; 83/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=277, regressor__n_estimators=12;, score=-1.006 total time=   1.9s\n",
            "[CV 1/5; 84/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=66\n",
            "[CV 1/5; 84/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=66;, score=0.096 total time=   8.5s\n",
            "[CV 2/5; 84/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=66\n",
            "[CV 2/5; 84/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=66;, score=-1.548 total time=   8.1s\n",
            "[CV 3/5; 84/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=66\n",
            "[CV 3/5; 84/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=66;, score=-0.121 total time=   7.9s\n",
            "[CV 4/5; 84/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=66\n",
            "[CV 4/5; 84/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=66;, score=0.286 total time=   7.9s\n",
            "[CV 5/5; 84/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=66\n",
            "[CV 5/5; 84/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=66;, score=-0.678 total time=   7.1s\n",
            "[CV 1/5; 85/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=45\n",
            "[CV 1/5; 85/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=45;, score=-0.177 total time=   5.0s\n",
            "[CV 2/5; 85/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=45\n",
            "[CV 2/5; 85/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=45;, score=-0.472 total time=   4.4s\n",
            "[CV 3/5; 85/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=45\n",
            "[CV 3/5; 85/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=45;, score=0.045 total time=   5.8s\n",
            "[CV 4/5; 85/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=45\n",
            "[CV 4/5; 85/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=45;, score=-0.174 total time=   4.7s\n",
            "[CV 5/5; 85/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=45\n",
            "[CV 5/5; 85/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=654, regressor__n_estimators=45;, score=-0.293 total time=   5.1s\n",
            "[CV 1/5; 86/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 1/5; 86/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-0.715 total time=  39.5s\n",
            "[CV 2/5; 86/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 2/5; 86/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-1.191 total time=  42.8s\n",
            "[CV 3/5; 86/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 3/5; 86/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-0.004 total time=  37.9s\n",
            "[CV 4/5; 86/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 4/5; 86/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=0.088 total time=  36.8s\n",
            "[CV 5/5; 86/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 5/5; 86/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-1.078 total time=  41.7s\n",
            "[CV 1/5; 87/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86\n",
            "[CV 1/5; 87/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86;, score=-0.428 total time=   7.1s\n",
            "[CV 2/5; 87/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86\n",
            "[CV 2/5; 87/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86;, score=-1.087 total time=   7.2s\n",
            "[CV 3/5; 87/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86\n",
            "[CV 3/5; 87/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86;, score=0.213 total time=   6.2s\n",
            "[CV 4/5; 87/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86\n",
            "[CV 4/5; 87/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86;, score=0.115 total time=   6.9s\n",
            "[CV 5/5; 87/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86\n",
            "[CV 5/5; 87/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=762, regressor__n_estimators=86;, score=-1.095 total time=   6.9s\n",
            "[CV 1/5; 88/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=45\n",
            "[CV 1/5; 88/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=45;, score=0.005 total time=   8.5s\n",
            "[CV 2/5; 88/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=45\n",
            "[CV 2/5; 88/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=45;, score=-0.359 total time=   8.6s\n",
            "[CV 3/5; 88/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=45\n",
            "[CV 3/5; 88/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=45;, score=0.169 total time=  10.3s\n",
            "[CV 4/5; 88/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=45\n",
            "[CV 4/5; 88/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=45;, score=0.283 total time=   7.2s\n",
            "[CV 5/5; 88/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=45\n",
            "[CV 5/5; 88/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=8, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=926, regressor__n_estimators=45;, score=-0.558 total time=   8.7s\n",
            "[CV 1/5; 89/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=277, regressor__n_estimators=53\n",
            "[CV 1/5; 89/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=277, regressor__n_estimators=53;, score=-0.367 total time=   2.2s\n",
            "[CV 2/5; 89/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=277, regressor__n_estimators=53\n",
            "[CV 2/5; 89/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=277, regressor__n_estimators=53;, score=-0.112 total time=   2.3s\n",
            "[CV 3/5; 89/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=277, regressor__n_estimators=53\n",
            "[CV 3/5; 89/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=277, regressor__n_estimators=53;, score=0.191 total time=   2.0s\n",
            "[CV 4/5; 89/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=277, regressor__n_estimators=53\n",
            "[CV 4/5; 89/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=277, regressor__n_estimators=53;, score=0.173 total time=   3.1s\n",
            "[CV 5/5; 89/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=277, regressor__n_estimators=53\n",
            "[CV 5/5; 89/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=277, regressor__n_estimators=53;, score=-1.081 total time=   2.2s\n",
            "[CV 1/5; 90/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=53\n",
            "[CV 1/5; 90/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=53;, score=-0.128 total time=   1.4s\n",
            "[CV 2/5; 90/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=53\n",
            "[CV 2/5; 90/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=53;, score=-0.935 total time=   1.3s\n",
            "[CV 3/5; 90/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=53\n",
            "[CV 3/5; 90/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=53;, score=0.142 total time=   1.3s\n",
            "[CV 4/5; 90/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=53\n",
            "[CV 4/5; 90/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=53;, score=-0.198 total time=   1.3s\n",
            "[CV 5/5; 90/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=53\n",
            "[CV 5/5; 90/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=277, regressor__n_estimators=53;, score=-0.264 total time=   1.3s\n",
            "[CV 1/5; 91/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=85\n",
            "[CV 1/5; 91/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=85;, score=-0.342 total time=   7.4s\n",
            "[CV 2/5; 91/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=85\n",
            "[CV 2/5; 91/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=85;, score=-1.377 total time=   6.6s\n",
            "[CV 3/5; 91/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=85\n",
            "[CV 3/5; 91/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=85;, score=-0.119 total time=   7.3s\n",
            "[CV 4/5; 91/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=85\n",
            "[CV 4/5; 91/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=85;, score=0.063 total time=   7.0s\n",
            "[CV 5/5; 91/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=85\n",
            "[CV 5/5; 91/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=6, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=85;, score=-1.203 total time=   6.2s\n",
            "[CV 1/5; 92/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=37\n",
            "[CV 1/5; 92/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=37;, score=-0.415 total time=   8.2s\n",
            "[CV 2/5; 92/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=37\n",
            "[CV 2/5; 92/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=37;, score=-0.117 total time=   7.7s\n",
            "[CV 3/5; 92/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=37\n",
            "[CV 3/5; 92/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=37;, score=0.090 total time=   8.1s\n",
            "[CV 4/5; 92/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=37\n",
            "[CV 4/5; 92/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=37;, score=0.014 total time=   8.4s\n",
            "[CV 5/5; 92/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=37\n",
            "[CV 5/5; 92/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=926, regressor__n_estimators=37;, score=-1.890 total time=   7.7s\n",
            "[CV 1/5; 93/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=66\n",
            "[CV 1/5; 93/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=66;, score=-0.242 total time=   7.1s\n",
            "[CV 2/5; 93/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=66\n",
            "[CV 2/5; 93/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=66;, score=-0.643 total time=   5.3s\n",
            "[CV 3/5; 93/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=66\n",
            "[CV 3/5; 93/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=66;, score=0.125 total time=   6.4s\n",
            "[CV 4/5; 93/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=66\n",
            "[CV 4/5; 93/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=66;, score=0.361 total time=   6.4s\n",
            "[CV 5/5; 93/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=66\n",
            "[CV 5/5; 93/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=762, regressor__n_estimators=66;, score=-0.558 total time=   6.6s\n",
            "[CV 1/5; 94/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=12\n",
            "[CV 1/5; 94/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=12;, score=-0.056 total time=   0.7s\n",
            "[CV 2/5; 94/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=12\n",
            "[CV 2/5; 94/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=12;, score=-0.500 total time=   0.7s\n",
            "[CV 3/5; 94/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=12\n",
            "[CV 3/5; 94/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=12;, score=0.092 total time=   0.7s\n",
            "[CV 4/5; 94/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=12\n",
            "[CV 4/5; 94/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=12;, score=0.206 total time=   0.7s\n",
            "[CV 5/5; 94/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=12\n",
            "[CV 5/5; 94/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=2, features__symbolic_transform__n_components=23, features__symbolic_transform__population_size=356, regressor__n_estimators=12;, score=-0.632 total time=   0.8s\n",
            "[CV 1/5; 95/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=85\n",
            "[CV 1/5; 95/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=85;, score=0.033 total time=  46.3s\n",
            "[CV 2/5; 95/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=85\n",
            "[CV 2/5; 95/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=85;, score=-0.927 total time=  45.2s\n",
            "[CV 3/5; 95/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=85\n",
            "[CV 3/5; 95/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=85;, score=-0.152 total time=  42.9s\n",
            "[CV 4/5; 95/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=85\n",
            "[CV 4/5; 95/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=85;, score=0.175 total time=  43.6s\n",
            "[CV 5/5; 95/100] START features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=85\n",
            "[CV 5/5; 95/100] END features__poly_minmax__poly__degree=9, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=887, regressor__n_estimators=85;, score=-1.431 total time=  44.5s\n",
            "[CV 1/5; 96/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=66\n",
            "[CV 1/5; 96/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=66;, score=-0.038 total time=   5.0s\n",
            "[CV 2/5; 96/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=66\n",
            "[CV 2/5; 96/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=66;, score=-0.658 total time=   4.3s\n",
            "[CV 3/5; 96/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=66\n",
            "[CV 3/5; 96/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=66;, score=-0.353 total time=   4.9s\n",
            "[CV 4/5; 96/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=66\n",
            "[CV 4/5; 96/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=66;, score=0.274 total time=   4.8s\n",
            "[CV 5/5; 96/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=66\n",
            "[CV 5/5; 96/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=12, features__symbolic_transform__population_size=356, regressor__n_estimators=66;, score=-0.268 total time=   4.6s\n",
            "[CV 1/5; 97/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=12\n",
            "[CV 1/5; 97/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=12;, score=-1.154 total time=   5.8s\n",
            "[CV 2/5; 97/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=12\n",
            "[CV 2/5; 97/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=12;, score=-2.130 total time=   3.5s\n",
            "[CV 3/5; 97/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=12\n",
            "[CV 3/5; 97/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=12;, score=0.067 total time=   4.0s\n",
            "[CV 4/5; 97/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=12\n",
            "[CV 4/5; 97/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=12;, score=0.060 total time=   4.5s\n",
            "[CV 5/5; 97/100] START features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=12\n",
            "[CV 5/5; 97/100] END features__poly_minmax__poly__degree=5, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=4, features__symbolic_transform__population_size=356, regressor__n_estimators=12;, score=-1.009 total time=   3.4s\n",
            "[CV 1/5; 98/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=66\n",
            "[CV 1/5; 98/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=66;, score=-0.231 total time=  12.2s\n",
            "[CV 2/5; 98/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=66\n",
            "[CV 2/5; 98/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=66;, score=-0.306 total time=  10.5s\n",
            "[CV 3/5; 98/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=66\n",
            "[CV 3/5; 98/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=66;, score=0.361 total time=   9.6s\n",
            "[CV 4/5; 98/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=66\n",
            "[CV 4/5; 98/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=66;, score=0.243 total time=  10.2s\n",
            "[CV 5/5; 98/100] START features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=66\n",
            "[CV 5/5; 98/100] END features__poly_minmax__poly__degree=4, features__symbolic_transform__generations=9, features__symbolic_transform__n_components=22, features__symbolic_transform__population_size=926, regressor__n_estimators=66;, score=-1.152 total time=   9.7s\n",
            "[CV 1/5; 99/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 1/5; 99/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=0.043 total time=   1.5s\n",
            "[CV 2/5; 99/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 2/5; 99/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-0.677 total time=   1.5s\n",
            "[CV 3/5; 99/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 3/5; 99/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=0.299 total time=   2.0s\n",
            "[CV 4/5; 99/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 4/5; 99/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=0.036 total time=   2.1s\n",
            "[CV 5/5; 99/100] START features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=79\n",
            "[CV 5/5; 99/100] END features__poly_minmax__poly__degree=1, features__symbolic_transform__generations=4, features__symbolic_transform__n_components=6, features__symbolic_transform__population_size=356, regressor__n_estimators=79;, score=-0.408 total time=   1.5s\n",
            "[CV 1/5; 100/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=79\n",
            "[CV 1/5; 100/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=79;, score=0.443 total time=   6.7s\n",
            "[CV 2/5; 100/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=79\n",
            "[CV 2/5; 100/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=79;, score=-0.070 total time=   7.5s\n",
            "[CV 3/5; 100/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=79\n",
            "[CV 3/5; 100/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=79;, score=0.256 total time=   6.3s\n",
            "[CV 4/5; 100/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=79\n",
            "[CV 4/5; 100/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=79;, score=0.142 total time=   7.0s\n",
            "[CV 5/5; 100/100] START features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=79\n",
            "[CV 5/5; 100/100] END features__poly_minmax__poly__degree=2, features__symbolic_transform__generations=7, features__symbolic_transform__n_components=13, features__symbolic_transform__population_size=887, regressor__n_estimators=79;, score=-2.883 total time=   7.7s\n",
            "0.023893667348430302\n",
            "{'regressor__n_estimators': 79, 'features__symbolic_transform__population_size': 887, 'features__symbolic_transform__n_components': 22, 'features__symbolic_transform__generations': 4, 'features__poly_minmax__poly__degree': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_col_list  = [\"param_\" +i for i in list (param_distributions.keys()) ]\n",
        "performance_list = [\"mean_fit_time\"  ,\"rank_test_score\" ]\n",
        "cv_cols = np.concatenate ([param_col_list ,  performance_list ]).tolist()\n",
        "\n",
        "cv_df = pd.DataFrame (random_search.cv_results_) [cv_cols]\n",
        "\n",
        "X_cv = cv_df.iloc [:,:-1]\n",
        "y_cv = cv_df.iloc [:,-1]\n",
        "\n",
        "X_cv_scaler = MinMaxScaler ()\n",
        "y_cv_scaler = MinMaxScaler ()\n",
        "\n",
        "X_cv_scaled = X_cv_scaler.fit_transform (X_cv)\n",
        "y_cv_scaled = y_cv_scaler.fit_transform (y_cv.values.reshape (-1,1))\n",
        "\n",
        "reg_cv = LinearRegression ()\n",
        "reg_cv.fit (X_cv_scaled , y_cv_scaled)\n",
        "\n",
        "y_pred_cv = reg_cv.predict (X_cv_scaled)\n",
        "\n",
        "print ('reg_cv.score (X_cv,y_cv)' , reg_cv.score (X_cv_scaled,y_cv_scaled))\n",
        "\n",
        "cv_df [\"y\"]         = y_cv_scaled\n",
        "cv_df [\"y_pred\"]    = y_pred_cv\n",
        "\n",
        "cv_df [(cv_df [\"y_pred\" ] < cv_df [\"y\"].max() ) *\n",
        "            (cv_df [\"y_pred\" ] > cv_df [\"y\"].min() )\n",
        "             ].plot.scatter (\"y\" , \"y_pred\" )\n",
        "\n",
        "print ('param_col_list' ,X_cv.columns )\n",
        "print (\"reg_cv.coef_\",reg_cv.coef_)\n",
        "print (\"reg_cv.intercept\",reg_cv.intercept_)\n",
        "\n",
        "\n",
        "'''\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.scatter(y_cv,y_pred_cv)\n",
        "#ax.plot([i for i in range (y.shape [0]) ],  ,color =\"green\")\n",
        "plt.show()\n",
        "\n",
        "print (\"reg_cv.coef_\",reg_cv.coef_)\n",
        "'''\n",
        "\n",
        "'''\n",
        "data_input [(data_input [fold_y_g_pred ] < data_input [Target].max() ) *\n",
        "            (data_input [fold_y_g_pred ] > data_input [Target].min() )\n",
        "             ].plot.scatter (Target , fold_y_g_pred )\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "t56p9t9s4FGh",
        "outputId": "fc0d1bc9-ae24-431f-8b6b-b1adefa0806f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reg_cv.score (X_cv,y_cv) 0.264656018248821\n",
            "param_col_list Index(['param_features__poly_minmax__poly__degree',\n",
            "       'param_features__symbolic_transform__population_size',\n",
            "       'param_features__symbolic_transform__generations',\n",
            "       'param_features__symbolic_transform__n_components',\n",
            "       'param_regressor__n_estimators', 'mean_fit_time'],\n",
            "      dtype='object')\n",
            "reg_cv.coef_ [[ 0.4279618   0.02823763  0.12081735 -0.18356369 -0.08709983  0.04643671]]\n",
            "reg_cv.intercept [0.39764525]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndata_input [(data_input [fold_y_g_pred ] < data_input [Target].max() ) *\\n            (data_input [fold_y_g_pred ] > data_input [Target].min() )\\n             ].plot.scatter (Target , fold_y_g_pred )\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZvdfpIbB7Jro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bhXPFMlf7J-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AS_TaCh-637u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4WXbj6K0zrcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import randint\n",
        "randint(10, 200).rvs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opMUXcwEuALA",
        "outputId": "9a8c5a9f-07b3-4070-a988-b684e7aa69bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from gplearn.genetic import SymbolicTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from scipy.stats import randint\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the polynomial features followed by MinMax scaling part of the pipeline\n",
        "poly_minmax_pipeline = Pipeline([\n",
        "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    ('minmax_scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "# FeatureUnion to combine PolynomialFeatures + MinMaxScaler and SymbolicTransformer\n",
        "combined_features = FeatureUnion([\n",
        "    (\"poly_minmax\", poly_minmax_pipeline),\n",
        "    (\"symbolic_transform\", SymbolicTransformer(generations=20, population_size=2000,\n",
        "                                                 hall_of_fame=100, n_components=10,\n",
        "                                                 function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'inv', 'max', 'min'),\n",
        "                                                 parsimony_coefficient=0.0005, max_samples=0.9, verbose=0,n_jobs=-1)),\n",
        "])\n",
        "\n",
        "'''\n",
        "# Final pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('features', combined_features),\n",
        "    ('linear_regression', LinearRegression())\n",
        "])\n",
        "'''\n",
        "\n",
        "# Define a placeholder pipeline with a generic 'regressor' step\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('features', combined_features),\n",
        "    ('regressor', LinearRegression())  # Placeholder, will be replaced by RandomizedSearchCV\n",
        "])\n",
        "\n",
        "\n",
        "# Define the parameter space for RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    'features__poly_minmax__poly__degree': randint (1,3),\n",
        "    'features__symbolic_transform__population_size': randint (1000,10000),\n",
        "    'features__symbolic_transform__generations': randint (1,5),\n",
        "    'features__symbolic_transform__n_components': randint (1,10),\n",
        "    #'regressor': np.random.choice ([LinearRegression()]),\n",
        "    'regressor__fit_intercept': [True, False],\n",
        "}\n",
        "\n",
        "# Number of iterations for randomized search\n",
        "n_iter = 100\n",
        "\n",
        "# Prepare for cross-validation\n",
        "cv = KFold(n_splits=2, shuffle=True, random_state=42)\n",
        "\n",
        "# Sample parameters and track progress with tqdm\n",
        "best_score  = -10000000000\n",
        "best_params = None\n",
        "params_list = []\n",
        "scores_list = []\n",
        "\n",
        "for _ in tqdm(range(n_iter), desc='Randomized Search Progress'):\n",
        "    # Sample a set of parameters\n",
        "    #sampled_params = {param: dist.rvs() for param, dist in param_distributions.items()}\n",
        "    sampled_params = {param: dist.rvs() if hasattr(dist, 'rvs') else random.choice(dist) for param, dist in param_distributions.items()}\n",
        "    params_list.append (sampled_params)\n",
        "\n",
        "    # Set model parameters\n",
        "    pipeline.set_params(**sampled_params)\n",
        "\n",
        "    # Evaluate the model using cross-validation\n",
        "    scores = cross_val_score(pipeline, X_train, y_train_scaled.ravel(), cv=cv,n_jobs=-1)\n",
        "    mean_score = np.mean(scores)\n",
        "    scores_list.append (mean_score)\n",
        "\n",
        "    # Update best score and parameters if current model is better\n",
        "    if mean_score > best_score:\n",
        "        best_score = mean_score\n",
        "        best_params = sampled_params\n",
        "\n",
        "# Display the best parameters and score\n",
        "print(f\"Best Score: {best_score}\")\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "ywLeq8xdc6vb",
        "outputId": "0e3173b2-c1bc-4b18-f095-8668e0c13127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Randomized Search Progress:  17%|        | 17/100 [07:27<36:23, 26.31s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-ea064acf91fc>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# Evaluate the model using cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mmean_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mscores_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1706\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pipeline.predict (X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRgsOak1_u53",
        "outputId": "c4053bb7-3602-487b-c401-5dda00ce843f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  591439.08229131,   752530.9228889 , -2685583.91928316,\n",
              "         -15949.37247386,  1386020.36586994,  2072085.01477079,\n",
              "        -582067.61219902,   958334.72112473,  -282400.49041108,\n",
              "        -100129.63709688,  -850413.03179482,  1756504.74515103,\n",
              "         728158.70727665,   164461.59477663,   121538.97280892,\n",
              "         495743.64308018,  1559183.32853212,   689948.69526136,\n",
              "         452811.9186288 ,  -445194.60458677, -1264937.35765752,\n",
              "         553769.69960764,  2570068.84127389,  1299666.55151188,\n",
              "         831721.32820484,   627386.86654907,   502997.28455903,\n",
              "         620596.42004627,   440017.92440524,  1102738.32040988,\n",
              "       -1741952.23913559,   263106.96055655,    46857.16924342,\n",
              "         992946.46955271])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.score (X_test , y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQAu0TUw_r0W",
        "outputId": "1e0b616a-8976-4d3a-e359-ecc082419776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.1292929381334582"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6fwiF-wUFPyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9MMAqmR2FaZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQ1HyYFZFami"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9BAe4WZVFauJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RN6b9t9E_sCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "poly_scaler_dict = {}\n",
        "poly           = PolynomialFeatures(3,interaction_only=True)\n",
        "poly_fit       = poly.fit (X_train)\n",
        "\n",
        "interaction_df = pd.DataFrame ( poly_fit.transform(X) )\n",
        "interaction_df_rename_dict = {}\n",
        "for col in interaction_df.columns : interaction_df_rename_dict [col] = str (col) + \"_poly\"\n",
        "interaction_df.rename (interaction_df_rename_dict,axis =1, inplace=True)\n",
        "sel_col_indicies        = list ( set ( [ random.randint (0,int (interaction_df.shape [1] * 0.3) - X.shape [1] ) for _ in range (int (interaction_df.shape [1] * 1))] ) )\n",
        "print (interaction_df.shape)\n",
        "interaction_df  = interaction_df.T.drop_duplicates().T\n",
        "print (max (sel_col_indicies) , interaction_df.shape [1] , sel_col_indicies  )\n",
        "interaction_df = interaction_df.iloc [:,sel_col_indicies]\n",
        "print (interaction_df.shape)\n",
        "\n",
        "interaction_df_train = interaction_df.loc [train_indicies]\n",
        "for col in interaction_df.columns :\n",
        "  try :\n",
        "    #c1 = type (X [col])   == type (X [\"PC\"])\n",
        "    #c2 = type (X [col])   == type (X [\"Price_Decay\"])\n",
        "    #c  = c1 | c2\n",
        "    #if c:\n",
        "    #if col != grouping_col :\n",
        "      poly_scaler_dict [col] = MinMaxScaler().fit (interaction_df_train [col].values.reshape (-1,1))\n",
        "  except :\n",
        "    continue\n",
        "print (poly_scaler_dict)\n",
        "for col in interaction_df.columns :\n",
        "    if col in poly_scaler_dict.keys() :\n",
        "      interaction_df [col]                      =  poly_scaler_dict [col].transform (interaction_df [col].values.reshape (-1,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-Esvs-8eK7k",
        "outputId": "0b1e90d4-87b4-4bff-9cf0-a43138b8f5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(114, 93)\n",
            "19 93 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "(114, 20)\n",
            "{'0_poly': MinMaxScaler(), '1_poly': MinMaxScaler(), '2_poly': MinMaxScaler(), '3_poly': MinMaxScaler(), '4_poly': MinMaxScaler(), '5_poly': MinMaxScaler(), '6_poly': MinMaxScaler(), '7_poly': MinMaxScaler(), '8_poly': MinMaxScaler(), '9_poly': MinMaxScaler(), '10_poly': MinMaxScaler(), '11_poly': MinMaxScaler(), '12_poly': MinMaxScaler(), '13_poly': MinMaxScaler(), '14_poly': MinMaxScaler(), '15_poly': MinMaxScaler(), '16_poly': MinMaxScaler(), '17_poly': MinMaxScaler(), '18_poly': MinMaxScaler(), '19_poly': MinMaxScaler()}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGRgG8mHm9_Z",
        "outputId": "5eaf031d-0efe-4936-fc2d-e5ff34b21c15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'LPB': StandardScaler(), 'Year': StandardScaler(), 'LP': StandardScaler(), 'LTIV': StandardScaler(), 'Price_Decay': StandardScaler(), 'Price_R2': StandardScaler(), 'TIV_Decay': StandardScaler(), 'TIV_R2': StandardScaler()}\n",
            "{'LPB': StandardScaler(), 'Year': StandardScaler(), 'LP': StandardScaler(), 'LTIV': StandardScaler(), 'Price_Decay': StandardScaler(), 'Price_R2': StandardScaler(), 'TIV_Decay': StandardScaler(), 'TIV_R2': StandardScaler(), 'Profit': StandardScaler()}\n"
          ]
        }
      ],
      "source": [
        "for col in X.columns :\n",
        "  try :\n",
        "    #c1 = type (X [col])   == type (X [\"PC\"])\n",
        "    #c2 = type (X [col])   == type (X [\"Price_Decay\"])\n",
        "    #c  = c1 | c2\n",
        "    #if c:\n",
        "    #if col != grouping_col :\n",
        "      scaler_dict [col] = StandardScaler().fit (X_train [col].values.reshape (-1,1))\n",
        "  except :\n",
        "    continue\n",
        "print (scaler_dict)\n",
        "\n",
        "scaler_dict  [Target] = StandardScaler().fit (y_train.values.reshape (-1,1))\n",
        "\n",
        "print (scaler_dict)\n",
        "\n",
        "#print ( col , scaler_dict [col].transform (X [col].values.reshape (-1,1)) )\n",
        "if scale_features :\n",
        "  for col in X.columns :\n",
        "    if col in scaler_dict.keys() :\n",
        "      X [col]                      =  scaler_dict [col].transform (X [col].values.reshape (-1,1))\n",
        "  y                                =  scaler_dict [Target].transform (y.values.reshape (-1,1))\n",
        "  y = pd.Series ( y.reshape (-1) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R45fgEYTwMdw",
        "outputId": "7387c475-ceeb-41c6-b155-2cfc189c9afe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     -0.701497\n",
              "1     -0.517761\n",
              "2      0.753245\n",
              "3     -0.617494\n",
              "4     -0.545146\n",
              "         ...   \n",
              "109   -0.732612\n",
              "110   -0.659082\n",
              "111   -0.349535\n",
              "112    0.074627\n",
              "113   -0.334164\n",
              "Length: 114, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "1hgmjutjSlFK",
        "outputId": "61649df5-c301-4799-8976-03d061390a80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     -1.8364285000041605_  -1.2191416092464593_  -0.6018547184887585_  \\\n",
              "0                       0                     0                     0   \n",
              "1                       0                     0                     0   \n",
              "2                       0                     0                     0   \n",
              "3                       0                     0                     0   \n",
              "4                       0                     0                     0   \n",
              "..                    ...                   ...                   ...   \n",
              "109                     0                     1                     0   \n",
              "110                     0                     1                     0   \n",
              "111                     0                     1                     0   \n",
              "112                     0                     1                     0   \n",
              "113                     1                     0                     0   \n",
              "\n",
              "     0.015432172268942524_  0.6327190630266435_  1.2500059537843444_  \\\n",
              "0                        0                    0                    0   \n",
              "1                        0                    0                    0   \n",
              "2                        0                    0                    0   \n",
              "3                        0                    0                    0   \n",
              "4                        0                    0                    0   \n",
              "..                     ...                  ...                  ...   \n",
              "109                      0                    0                    0   \n",
              "110                      0                    0                    0   \n",
              "111                      0                    0                    0   \n",
              "112                      0                    0                    0   \n",
              "113                      0                    0                    0   \n",
              "\n",
              "     1.8672928445420454_  2.4845797352997465_  \n",
              "0                      0                    1  \n",
              "1                      0                    1  \n",
              "2                      0                    1  \n",
              "3                      0                    1  \n",
              "4                      1                    0  \n",
              "..                   ...                  ...  \n",
              "109                    0                    0  \n",
              "110                    0                    0  \n",
              "111                    0                    0  \n",
              "112                    0                    0  \n",
              "113                    0                    0  \n",
              "\n",
              "[114 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97fa66ac-3938-4032-ab68-f0780a92b414\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-1.8364285000041605_</th>\n",
              "      <th>-1.2191416092464593_</th>\n",
              "      <th>-0.6018547184887585_</th>\n",
              "      <th>0.015432172268942524_</th>\n",
              "      <th>0.6327190630266435_</th>\n",
              "      <th>1.2500059537843444_</th>\n",
              "      <th>1.8672928445420454_</th>\n",
              "      <th>2.4845797352997465_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows  8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97fa66ac-3938-4032-ab68-f0780a92b414')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97fa66ac-3938-4032-ab68-f0780a92b414 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97fa66ac-3938-4032-ab68-f0780a92b414');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-be2bb9e2-3905-407e-a1d1-7a4967476f11\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-be2bb9e2-3905-407e-a1d1-7a4967476f11')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-be2bb9e2-3905-407e-a1d1-7a4967476f11 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ec985605-4f83-4110-b258-fb8fcfda6e3d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('one_hot_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ec985605-4f83-4110-b258-fb8fcfda6e3d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('one_hot_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "one_hot_df",
              "summary": "{\n  \"name\": \"one_hot_df\",\n  \"rows\": 114,\n  \"fields\": [\n    {\n      \"column\": \"-1.8364285000041605_\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"-1.2191416092464593_\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"-0.6018547184887585_\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0.015432172268942524_\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0.6327190630266435_\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1.2500059537843444_\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1.8672928445420454_\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2.4845797352997465_\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "one_hot_df = pd.get_dummies (X [grouping_col])\n",
        "one_hot_df_rename_dict = {}\n",
        "for col in one_hot_df.columns : one_hot_df_rename_dict [col] = str (col) + \"_\"\n",
        "one_hot_df.rename (one_hot_df_rename_dict,axis =1, inplace=True)\n",
        "one_hot_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if one_hot :\n",
        "   X = X.join (one_hot_df)"
      ],
      "metadata": {
        "id": "MgXzdrYaXnN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if drop_grouping_var :  X = X.drop (grouping_col,axis =1 )"
      ],
      "metadata": {
        "id": "XdP7o0-1aWKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6moDnuwXnfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LnpX-YTAmjU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYTLWkLmUPJc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTmcUfr5Ci6t",
        "outputId": "a9bb88cc-3f6e-49b1-e6a0-2fba0ad48f65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(114, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "interaction_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3MFoNTgSrKg"
      },
      "outputs": [],
      "source": [
        "if interaction :\n",
        "   X = X.join (interaction_df)\n",
        "   X_train       = X.loc [train_indicies]\n",
        "   X_test        = X.loc [test_indicies]\n",
        "   y_train       = y.loc [train_indicies]\n",
        "   y_test        = y.loc [test_indicies]\n",
        "#X.join (one_hot_df).join (interaction_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTiWqYPcsxLI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "FI5c7WV5sgof",
        "outputId": "1230c4c9-8d5d-4cc6-e74b-15d3a82de6d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2  \\\n",
              "0    0.402015  2.297781  2.688829    -1.120221  0.282477  -0.981968 -0.036201   \n",
              "1    0.402015  2.209180  2.483232    -0.312389  0.471802  -0.944999  0.487788   \n",
              "2    0.402015  2.172224  2.195472    -0.409148  0.509785  -0.973679  0.683121   \n",
              "3   -0.603023  2.191353  2.188808    -1.239414  0.982307  -1.198642  0.178327   \n",
              "4    0.402015  2.019600  1.827317    -0.583918  0.242639  -0.062761 -0.303703   \n",
              "..        ...       ...       ...          ...       ...        ...       ...   \n",
              "109 -1.608061 -1.291558 -1.150069    -0.847848  0.824229  -0.886313  0.529760   \n",
              "110 -1.608061 -1.370919 -1.144899    -0.721838  0.446227  -0.959629  0.588296   \n",
              "111 -1.608061 -1.288478 -1.216915    -1.427868  0.664495  -1.300016  0.378991   \n",
              "112 -1.608061 -1.207636 -1.198590     0.292577 -0.025033   0.168419  0.685359   \n",
              "113 -1.608061 -1.437489 -1.174426    -1.421345  0.616264  -1.677496  0.480178   \n",
              "\n",
              "     -1.8364285000041605_  -1.2191416092464593_  -0.6018547184887585_  ...  \\\n",
              "0                       0                     0                     0  ...   \n",
              "1                       0                     0                     0  ...   \n",
              "2                       0                     0                     0  ...   \n",
              "3                       0                     0                     0  ...   \n",
              "4                       0                     0                     0  ...   \n",
              "..                    ...                   ...                   ...  ...   \n",
              "109                     0                     1                     0  ...   \n",
              "110                     0                     1                     0  ...   \n",
              "111                     0                     1                     0  ...   \n",
              "112                     0                     1                     0  ...   \n",
              "113                     1                     0                     0  ...   \n",
              "\n",
              "      10_poly   11_poly   12_poly   13_poly   14_poly   15_poly   16_poly  \\\n",
              "0    1.016719  1.039782  0.026091  0.915334  0.046034  0.919357  1.024281   \n",
              "1    1.000000  1.000000  0.202922  0.938239  0.053888  0.978101  1.000000   \n",
              "2    0.993026  0.944320  0.181742  0.942834  0.047795  1.000000  0.989872   \n",
              "3    0.996636  0.943030  0.000000  1.000000  0.000000  0.943408  0.994301   \n",
              "4    0.854438  0.773250  0.246404  0.792245  0.339378  0.758548  0.948046   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "109  0.055568  0.043637  0.737888  0.229038  0.759654  0.141830  0.039952   \n",
              "110  0.049578  0.044037  0.748921  0.210746  0.753424  0.144455  0.018225   \n",
              "111  0.055801  0.038463  0.687103  0.221308  0.724497  0.135069  0.040795   \n",
              "112  0.061903  0.039881  0.837742  0.187941  0.849288  0.148808  0.062928   \n",
              "113  0.000000  0.000000  0.808923  0.096184  0.824776  0.000000  0.000000   \n",
              "\n",
              "      17_poly   18_poly   19_poly  \n",
              "0    1.052487  0.194698  0.825415  \n",
              "1    1.000000  0.393950  0.862726  \n",
              "2    0.926537  0.370084  0.870211  \n",
              "3    0.924137  0.165954  0.962304  \n",
              "4    0.832550  0.326977  0.817564  \n",
              "..        ...       ...       ...  \n",
              "109  0.071897  0.263093  0.930156  \n",
              "110  0.073215  0.294142  0.855736  \n",
              "111  0.054848  0.120173  0.898708  \n",
              "112  0.059522  0.544099  0.762957  \n",
              "113  0.065685  0.121780  0.889212  \n",
              "\n",
              "[114 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ef1e796-ac24-4965-ac29-d91ccd6e1c94\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>LP</th>\n",
              "      <th>LTIV</th>\n",
              "      <th>Price_Decay</th>\n",
              "      <th>Price_R2</th>\n",
              "      <th>TIV_Decay</th>\n",
              "      <th>TIV_R2</th>\n",
              "      <th>-1.8364285000041605_</th>\n",
              "      <th>-1.2191416092464593_</th>\n",
              "      <th>-0.6018547184887585_</th>\n",
              "      <th>...</th>\n",
              "      <th>10_poly</th>\n",
              "      <th>11_poly</th>\n",
              "      <th>12_poly</th>\n",
              "      <th>13_poly</th>\n",
              "      <th>14_poly</th>\n",
              "      <th>15_poly</th>\n",
              "      <th>16_poly</th>\n",
              "      <th>17_poly</th>\n",
              "      <th>18_poly</th>\n",
              "      <th>19_poly</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.402015</td>\n",
              "      <td>2.297781</td>\n",
              "      <td>2.688829</td>\n",
              "      <td>-1.120221</td>\n",
              "      <td>0.282477</td>\n",
              "      <td>-0.981968</td>\n",
              "      <td>-0.036201</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.016719</td>\n",
              "      <td>1.039782</td>\n",
              "      <td>0.026091</td>\n",
              "      <td>0.915334</td>\n",
              "      <td>0.046034</td>\n",
              "      <td>0.919357</td>\n",
              "      <td>1.024281</td>\n",
              "      <td>1.052487</td>\n",
              "      <td>0.194698</td>\n",
              "      <td>0.825415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.402015</td>\n",
              "      <td>2.209180</td>\n",
              "      <td>2.483232</td>\n",
              "      <td>-0.312389</td>\n",
              "      <td>0.471802</td>\n",
              "      <td>-0.944999</td>\n",
              "      <td>0.487788</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.202922</td>\n",
              "      <td>0.938239</td>\n",
              "      <td>0.053888</td>\n",
              "      <td>0.978101</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.393950</td>\n",
              "      <td>0.862726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.402015</td>\n",
              "      <td>2.172224</td>\n",
              "      <td>2.195472</td>\n",
              "      <td>-0.409148</td>\n",
              "      <td>0.509785</td>\n",
              "      <td>-0.973679</td>\n",
              "      <td>0.683121</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.993026</td>\n",
              "      <td>0.944320</td>\n",
              "      <td>0.181742</td>\n",
              "      <td>0.942834</td>\n",
              "      <td>0.047795</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989872</td>\n",
              "      <td>0.926537</td>\n",
              "      <td>0.370084</td>\n",
              "      <td>0.870211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.603023</td>\n",
              "      <td>2.191353</td>\n",
              "      <td>2.188808</td>\n",
              "      <td>-1.239414</td>\n",
              "      <td>0.982307</td>\n",
              "      <td>-1.198642</td>\n",
              "      <td>0.178327</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.996636</td>\n",
              "      <td>0.943030</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.943408</td>\n",
              "      <td>0.994301</td>\n",
              "      <td>0.924137</td>\n",
              "      <td>0.165954</td>\n",
              "      <td>0.962304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.402015</td>\n",
              "      <td>2.019600</td>\n",
              "      <td>1.827317</td>\n",
              "      <td>-0.583918</td>\n",
              "      <td>0.242639</td>\n",
              "      <td>-0.062761</td>\n",
              "      <td>-0.303703</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.854438</td>\n",
              "      <td>0.773250</td>\n",
              "      <td>0.246404</td>\n",
              "      <td>0.792245</td>\n",
              "      <td>0.339378</td>\n",
              "      <td>0.758548</td>\n",
              "      <td>0.948046</td>\n",
              "      <td>0.832550</td>\n",
              "      <td>0.326977</td>\n",
              "      <td>0.817564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>-1.608061</td>\n",
              "      <td>-1.291558</td>\n",
              "      <td>-1.150069</td>\n",
              "      <td>-0.847848</td>\n",
              "      <td>0.824229</td>\n",
              "      <td>-0.886313</td>\n",
              "      <td>0.529760</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055568</td>\n",
              "      <td>0.043637</td>\n",
              "      <td>0.737888</td>\n",
              "      <td>0.229038</td>\n",
              "      <td>0.759654</td>\n",
              "      <td>0.141830</td>\n",
              "      <td>0.039952</td>\n",
              "      <td>0.071897</td>\n",
              "      <td>0.263093</td>\n",
              "      <td>0.930156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>-1.608061</td>\n",
              "      <td>-1.370919</td>\n",
              "      <td>-1.144899</td>\n",
              "      <td>-0.721838</td>\n",
              "      <td>0.446227</td>\n",
              "      <td>-0.959629</td>\n",
              "      <td>0.588296</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049578</td>\n",
              "      <td>0.044037</td>\n",
              "      <td>0.748921</td>\n",
              "      <td>0.210746</td>\n",
              "      <td>0.753424</td>\n",
              "      <td>0.144455</td>\n",
              "      <td>0.018225</td>\n",
              "      <td>0.073215</td>\n",
              "      <td>0.294142</td>\n",
              "      <td>0.855736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>-1.608061</td>\n",
              "      <td>-1.288478</td>\n",
              "      <td>-1.216915</td>\n",
              "      <td>-1.427868</td>\n",
              "      <td>0.664495</td>\n",
              "      <td>-1.300016</td>\n",
              "      <td>0.378991</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055801</td>\n",
              "      <td>0.038463</td>\n",
              "      <td>0.687103</td>\n",
              "      <td>0.221308</td>\n",
              "      <td>0.724497</td>\n",
              "      <td>0.135069</td>\n",
              "      <td>0.040795</td>\n",
              "      <td>0.054848</td>\n",
              "      <td>0.120173</td>\n",
              "      <td>0.898708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>-1.608061</td>\n",
              "      <td>-1.207636</td>\n",
              "      <td>-1.198590</td>\n",
              "      <td>0.292577</td>\n",
              "      <td>-0.025033</td>\n",
              "      <td>0.168419</td>\n",
              "      <td>0.685359</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.061903</td>\n",
              "      <td>0.039881</td>\n",
              "      <td>0.837742</td>\n",
              "      <td>0.187941</td>\n",
              "      <td>0.849288</td>\n",
              "      <td>0.148808</td>\n",
              "      <td>0.062928</td>\n",
              "      <td>0.059522</td>\n",
              "      <td>0.544099</td>\n",
              "      <td>0.762957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>-1.608061</td>\n",
              "      <td>-1.437489</td>\n",
              "      <td>-1.174426</td>\n",
              "      <td>-1.421345</td>\n",
              "      <td>0.616264</td>\n",
              "      <td>-1.677496</td>\n",
              "      <td>0.480178</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.808923</td>\n",
              "      <td>0.096184</td>\n",
              "      <td>0.824776</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065685</td>\n",
              "      <td>0.121780</td>\n",
              "      <td>0.889212</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows  35 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ef1e796-ac24-4965-ac29-d91ccd6e1c94')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ef1e796-ac24-4965-ac29-d91ccd6e1c94 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ef1e796-ac24-4965-ac29-d91ccd6e1c94');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d3cd454a-dfe0-468f-9b2f-cac76ef3b8c8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3cd454a-dfe0-468f-9b2f-cac76ef3b8c8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d3cd454a-dfe0-468f-9b2f-cac76ef3b8c8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2a3d6239-cade-41a9-9cdc-a9a08bd457c9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2a3d6239-cade-41a9-9cdc-a9a08bd457c9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyzsXsz9OQ21",
        "outputId": "9cfb8bea-939b-400c-cdda-3b28e62f8109"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     -0.701497\n",
              "1     -0.517761\n",
              "2      0.753245\n",
              "3     -0.617494\n",
              "4     -0.545146\n",
              "         ...   \n",
              "109   -0.732612\n",
              "110   -0.659082\n",
              "111   -0.349535\n",
              "112    0.074627\n",
              "113   -0.334164\n",
              "Length: 114, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZ4gCVa2OSf5"
      },
      "outputs": [],
      "source": [
        "reg = LinearRegression().fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TwlKq0BQCkg"
      },
      "outputs": [],
      "source": [
        "y_pred = reg.predict (X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9s1MePeO7hI",
        "outputId": "aaabbfd9-3ab8-4f15-ba4b-e75f58ae3a5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.73383674e+12, -2.88829297e+03,  1.15732361e+03,  1.32613830e+03,\n",
              "        1.18942547e+03, -1.63428872e-01,  6.54385196e-01, -2.62267323e+03,\n",
              "       -1.87358076e+03, -1.12421378e+03, -3.75528017e+02,  3.74260004e+02,\n",
              "        1.12408070e+03,  1.87357244e+03,  2.62406597e+03,  2.28881836e-05,\n",
              "        4.49696490e+03, -8.24282791e+12, -7.92043093e+02,  2.95525821e+02,\n",
              "        3.26527109e+02,  2.33796271e+02, -4.34473199e-02,  1.34718547e-01,\n",
              "       -9.75288089e+03,  7.12793248e-01, -4.91178718e+00,  1.68126213e+01,\n",
              "        1.84642934e+01, -5.96497042e-01, -5.83194044e+00,  1.13393401e+04,\n",
              "       -4.82842934e+03, -5.70895901e+03, -6.27202304e+03])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLvF-dZNO-C2",
        "outputId": "90d3dfc6-1440-4367-9fd0-c4a4cb1626e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.274201005390999"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "reg.score (X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gduFQmqlPETZ"
      },
      "outputs": [],
      "source": [
        "if scale_features :\n",
        "  data_input [pred_col_name] = scaler_dict [Target].inverse_transform (y_pred.reshape (-1,1)).reshape (-1)\n",
        "else :\n",
        "  data_input [pred_col_name] = y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "aIKFvz4vPVp2",
        "outputId": "c25ddd27-6afb-4b50-87f9-e351944e237a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      LPB                           MMC  Year       LP     LTIV  PC  \\\n",
              "0    1000   iPhone XS Max_512GB_Verizon  2018  1029.35  656.816  19   \n",
              "1    1000  iPhone XS Max_512GB_Unlocked  2018  1014.39  634.388  20   \n",
              "2    1000  iPhone XS Max_256GB_Unlocked  2018  1008.15  602.997  20   \n",
              "3    1000        iPhone X_256GB_Verizon  2017  1011.38  602.270  19   \n",
              "4     900   iPhone XS Max_256GB_Verizon  2018   982.38  562.836  20   \n",
              "..    ...                           ...   ...      ...      ...  ..   \n",
              "109   400       iPhone 7_256GB_T-Mobile  2016   423.30  238.041  17   \n",
              "110   400       iPhone 7_128GB_T-Mobile  2016   409.90  238.605  19   \n",
              "111   400            iPhone 7_32GB_AT&T  2016   423.82  230.749  20   \n",
              "112   400   iPhone 7 Plus_32GB_T-Mobile  2016   437.47  232.748  19   \n",
              "113   300        iPhone 7_32GB_T-Mobile  2016   398.66  235.384  18   \n",
              "\n",
              "     Price_Decay  Price_R2  TIV_Decay    TIV_R2   Profit   Profit_Pred  \n",
              "0      -0.001192  0.894662  -0.001335  0.879887    41381 -1.237176e+06  \n",
              "1      -0.001009  0.911918  -0.001326  0.918513   227473  7.706661e+05  \n",
              "2      -0.001031  0.915380  -0.001333  0.932912  1514777  7.988550e+05  \n",
              "3      -0.001220  0.958448  -0.001388  0.895701   126462  3.072800e+05  \n",
              "4      -0.001070  0.891031  -0.001114  0.860168   199737  9.314316e+04  \n",
              "..           ...       ...        ...       ...      ...           ...  \n",
              "109    -0.001130  0.944040  -0.001312  0.921607     9867  7.207173e+05  \n",
              "110    -0.001102  0.909587  -0.001330  0.925922    84340  4.506972e+05  \n",
              "111    -0.001262  0.929481  -0.001412  0.910493   397857 -3.158433e+05  \n",
              "112    -0.000871  0.866634  -0.001058  0.933077   827457  6.480196e+05  \n",
              "113    -0.001261  0.925085  -0.001503  0.917952   413425  4.081666e+05  \n",
              "\n",
              "[114 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f557a295-b5c3-4e3c-83ce-45066a743e95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LPB</th>\n",
              "      <th>MMC</th>\n",
              "      <th>Year</th>\n",
              "      <th>LP</th>\n",
              "      <th>LTIV</th>\n",
              "      <th>PC</th>\n",
              "      <th>Price_Decay</th>\n",
              "      <th>Price_R2</th>\n",
              "      <th>TIV_Decay</th>\n",
              "      <th>TIV_R2</th>\n",
              "      <th>Profit</th>\n",
              "      <th>Profit_Pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone XS Max_512GB_Verizon</td>\n",
              "      <td>2018</td>\n",
              "      <td>1029.35</td>\n",
              "      <td>656.816</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.001192</td>\n",
              "      <td>0.894662</td>\n",
              "      <td>-0.001335</td>\n",
              "      <td>0.879887</td>\n",
              "      <td>41381</td>\n",
              "      <td>-1.237176e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone XS Max_512GB_Unlocked</td>\n",
              "      <td>2018</td>\n",
              "      <td>1014.39</td>\n",
              "      <td>634.388</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.001009</td>\n",
              "      <td>0.911918</td>\n",
              "      <td>-0.001326</td>\n",
              "      <td>0.918513</td>\n",
              "      <td>227473</td>\n",
              "      <td>7.706661e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone XS Max_256GB_Unlocked</td>\n",
              "      <td>2018</td>\n",
              "      <td>1008.15</td>\n",
              "      <td>602.997</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.001031</td>\n",
              "      <td>0.915380</td>\n",
              "      <td>-0.001333</td>\n",
              "      <td>0.932912</td>\n",
              "      <td>1514777</td>\n",
              "      <td>7.988550e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone X_256GB_Verizon</td>\n",
              "      <td>2017</td>\n",
              "      <td>1011.38</td>\n",
              "      <td>602.270</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.001220</td>\n",
              "      <td>0.958448</td>\n",
              "      <td>-0.001388</td>\n",
              "      <td>0.895701</td>\n",
              "      <td>126462</td>\n",
              "      <td>3.072800e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>900</td>\n",
              "      <td>iPhone XS Max_256GB_Verizon</td>\n",
              "      <td>2018</td>\n",
              "      <td>982.38</td>\n",
              "      <td>562.836</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.001070</td>\n",
              "      <td>0.891031</td>\n",
              "      <td>-0.001114</td>\n",
              "      <td>0.860168</td>\n",
              "      <td>199737</td>\n",
              "      <td>9.314316e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>400</td>\n",
              "      <td>iPhone 7_256GB_T-Mobile</td>\n",
              "      <td>2016</td>\n",
              "      <td>423.30</td>\n",
              "      <td>238.041</td>\n",
              "      <td>17</td>\n",
              "      <td>-0.001130</td>\n",
              "      <td>0.944040</td>\n",
              "      <td>-0.001312</td>\n",
              "      <td>0.921607</td>\n",
              "      <td>9867</td>\n",
              "      <td>7.207173e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>400</td>\n",
              "      <td>iPhone 7_128GB_T-Mobile</td>\n",
              "      <td>2016</td>\n",
              "      <td>409.90</td>\n",
              "      <td>238.605</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.001102</td>\n",
              "      <td>0.909587</td>\n",
              "      <td>-0.001330</td>\n",
              "      <td>0.925922</td>\n",
              "      <td>84340</td>\n",
              "      <td>4.506972e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>400</td>\n",
              "      <td>iPhone 7_32GB_AT&amp;T</td>\n",
              "      <td>2016</td>\n",
              "      <td>423.82</td>\n",
              "      <td>230.749</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.001262</td>\n",
              "      <td>0.929481</td>\n",
              "      <td>-0.001412</td>\n",
              "      <td>0.910493</td>\n",
              "      <td>397857</td>\n",
              "      <td>-3.158433e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>400</td>\n",
              "      <td>iPhone 7 Plus_32GB_T-Mobile</td>\n",
              "      <td>2016</td>\n",
              "      <td>437.47</td>\n",
              "      <td>232.748</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.000871</td>\n",
              "      <td>0.866634</td>\n",
              "      <td>-0.001058</td>\n",
              "      <td>0.933077</td>\n",
              "      <td>827457</td>\n",
              "      <td>6.480196e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>300</td>\n",
              "      <td>iPhone 7_32GB_T-Mobile</td>\n",
              "      <td>2016</td>\n",
              "      <td>398.66</td>\n",
              "      <td>235.384</td>\n",
              "      <td>18</td>\n",
              "      <td>-0.001261</td>\n",
              "      <td>0.925085</td>\n",
              "      <td>-0.001503</td>\n",
              "      <td>0.917952</td>\n",
              "      <td>413425</td>\n",
              "      <td>4.081666e+05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows  12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f557a295-b5c3-4e3c-83ce-45066a743e95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f557a295-b5c3-4e3c-83ce-45066a743e95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f557a295-b5c3-4e3c-83ce-45066a743e95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-68f62927-eb7d-4b6f-95a9-a955efc703c9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68f62927-eb7d-4b6f-95a9-a955efc703c9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-68f62927-eb7d-4b6f-95a9-a955efc703c9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_dd705477-f13f-40f0-8c01-7db2a349fbbc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data_input')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dd705477-f13f-40f0-8c01-7db2a349fbbc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data_input');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_input",
              "summary": "{\n  \"name\": \"data_input\",\n  \"rows\": 114,\n  \"fields\": [\n    {\n      \"column\": \"LPB\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          900,\n          500,\n          1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MMC\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 114,\n        \"samples\": [\n          \"iPhone 11_128GB_T-Mobile\",\n          \"iPhone XS Max_256GB_Verizon\",\n          \"iPhone 8 Plus_256GB_Verizon\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2016,\n        \"max\": 2019,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2017,\n          2016,\n          2018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 159.75913399110536,\n        \"min\": 398.66,\n        \"max\": 1029.35,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          535.16,\n          982.38,\n          767.27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LTIV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105.31749580441497,\n        \"min\": 207.186,\n        \"max\": 656.816,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          239.438,\n          562.836,\n          409.377\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 16,\n        \"max\": 21,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          19,\n          20,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price_Decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00023556628349597262,\n        \"min\": -0.001411932,\n        \"max\": -0.00044894,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          -0.000637359,\n          -0.001070336,\n          -0.001031244\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price_R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08766141185476332,\n        \"min\": 0.512654,\n        \"max\": 0.980328,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          0.763261,\n          0.891031,\n          0.938773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TIV_Decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0002520634633665147,\n        \"min\": -0.00158934,\n        \"max\": -0.00050391,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          -0.00050391,\n          -0.00111357,\n          -0.00108685\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TIV_R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09797161857413617,\n        \"min\": 0.466594,\n        \"max\": 0.958327,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          0.643396,\n          0.860168,\n          0.838461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Profit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1063143,\n        \"min\": 4932,\n        \"max\": 5747639,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          276864,\n          199737,\n          110921\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Profit_Pred\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 770756.8926860166,\n        \"min\": -2016574.2790777348,\n        \"max\": 2457549.882643642,\n        \"num_unique_values\": 113,\n        \"samples\": [\n          -322766.91156411543,\n          93143.16028375446,\n          1176685.3331953867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "data_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNUyqKk5wls7",
        "outputId": "a5375b85-fc3b-4f89-905a-90892ebc6d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 114 entries, 0 to 113\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype   \n",
            "---  ------       --------------  -----   \n",
            " 0   LPB          114 non-null    category\n",
            " 1   MMC          114 non-null    object  \n",
            " 2   Year         114 non-null    int64   \n",
            " 3   LP           114 non-null    float64 \n",
            " 4   LTIV         114 non-null    float64 \n",
            " 5   PC           114 non-null    int64   \n",
            " 6   Price_Decay  114 non-null    float64 \n",
            " 7   Price_R2     114 non-null    float64 \n",
            " 8   TIV_Decay    114 non-null    float64 \n",
            " 9   TIV_R2       114 non-null    float64 \n",
            " 10  Profit       114 non-null    int64   \n",
            " 11  Profit_Pred  114 non-null    float64 \n",
            "dtypes: category(1), float64(7), int64(3), object(1)\n",
            "memory usage: 10.4+ KB\n"
          ]
        }
      ],
      "source": [
        "data_input.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JwjfcjbPWg5"
      },
      "outputs": [],
      "source": [
        "#data_input.plot.scatter (\"Profit\" , \"Profit_Pred\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "X0lMQ3KUP5t9",
        "outputId": "bb28f609-9db2-4604-b413-c8fa7df5e131"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_pred' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-4622e9112f93>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot([i for i in range (y.shape [0]) ], y)\n",
        "ax.plot([i for i in range (y.shape [0]) ], y_pred ,color =\"red\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "jbQrCDMvzac1",
        "outputId": "27645a86-bc2b-40d5-8250-8355a98076a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2  \\\n",
              "0    0.402015  2.297781  2.688829    -1.120221  0.282477  -0.981968 -0.036201   \n",
              "1    0.402015  2.209180  2.483232    -0.312389  0.471802  -0.944999  0.487788   \n",
              "2    0.402015  2.172224  2.195472    -0.409148  0.509785  -0.973679  0.683121   \n",
              "3   -0.603023  2.191353  2.188808    -1.239414  0.982307  -1.198642  0.178327   \n",
              "4    0.402015  2.019600  1.827317    -0.583918  0.242639  -0.062761 -0.303703   \n",
              "..        ...       ...       ...          ...       ...        ...       ...   \n",
              "109 -1.608061 -1.291558 -1.150069    -0.847848  0.824229  -0.886313  0.529760   \n",
              "110 -1.608061 -1.370919 -1.144899    -0.721838  0.446227  -0.959629  0.588296   \n",
              "111 -1.608061 -1.288478 -1.216915    -1.427868  0.664495  -1.300016  0.378991   \n",
              "112 -1.608061 -1.207636 -1.198590     0.292577 -0.025033   0.168419  0.685359   \n",
              "113 -1.608061 -1.437489 -1.174426    -1.421345  0.616264  -1.677496  0.480178   \n",
              "\n",
              "     -1.8364285000041605_  -1.2191416092464593_  -0.6018547184887585_  ...  \\\n",
              "0                       0                     0                     0  ...   \n",
              "1                       0                     0                     0  ...   \n",
              "2                       0                     0                     0  ...   \n",
              "3                       0                     0                     0  ...   \n",
              "4                       0                     0                     0  ...   \n",
              "..                    ...                   ...                   ...  ...   \n",
              "109                     0                     1                     0  ...   \n",
              "110                     0                     1                     0  ...   \n",
              "111                     0                     1                     0  ...   \n",
              "112                     0                     1                     0  ...   \n",
              "113                     1                     0                     0  ...   \n",
              "\n",
              "      10_poly   11_poly   12_poly   13_poly   14_poly   15_poly   16_poly  \\\n",
              "0    1.016719  1.039782  0.026091  0.915334  0.046034  0.919357  1.024281   \n",
              "1    1.000000  1.000000  0.202922  0.938239  0.053888  0.978101  1.000000   \n",
              "2    0.993026  0.944320  0.181742  0.942834  0.047795  1.000000  0.989872   \n",
              "3    0.996636  0.943030  0.000000  1.000000  0.000000  0.943408  0.994301   \n",
              "4    0.854438  0.773250  0.246404  0.792245  0.339378  0.758548  0.948046   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "109  0.055568  0.043637  0.737888  0.229038  0.759654  0.141830  0.039952   \n",
              "110  0.049578  0.044037  0.748921  0.210746  0.753424  0.144455  0.018225   \n",
              "111  0.055801  0.038463  0.687103  0.221308  0.724497  0.135069  0.040795   \n",
              "112  0.061903  0.039881  0.837742  0.187941  0.849288  0.148808  0.062928   \n",
              "113  0.000000  0.000000  0.808923  0.096184  0.824776  0.000000  0.000000   \n",
              "\n",
              "      17_poly   18_poly   19_poly  \n",
              "0    1.052487  0.194698  0.825415  \n",
              "1    1.000000  0.393950  0.862726  \n",
              "2    0.926537  0.370084  0.870211  \n",
              "3    0.924137  0.165954  0.962304  \n",
              "4    0.832550  0.326977  0.817564  \n",
              "..        ...       ...       ...  \n",
              "109  0.071897  0.263093  0.930156  \n",
              "110  0.073215  0.294142  0.855736  \n",
              "111  0.054848  0.120173  0.898708  \n",
              "112  0.059522  0.544099  0.762957  \n",
              "113  0.065685  0.121780  0.889212  \n",
              "\n",
              "[114 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c61e4a7-4709-4c2d-87b8-5410b51d4a54\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>LP</th>\n",
              "      <th>LTIV</th>\n",
              "      <th>Price_Decay</th>\n",
              "      <th>Price_R2</th>\n",
              "      <th>TIV_Decay</th>\n",
              "      <th>TIV_R2</th>\n",
              "      <th>-1.8364285000041605_</th>\n",
              "      <th>-1.2191416092464593_</th>\n",
              "      <th>-0.6018547184887585_</th>\n",
              "      <th>...</th>\n",
              "      <th>10_poly</th>\n",
              "      <th>11_poly</th>\n",
              "      <th>12_poly</th>\n",
              "      <th>13_poly</th>\n",
              "      <th>14_poly</th>\n",
              "      <th>15_poly</th>\n",
              "      <th>16_poly</th>\n",
              "      <th>17_poly</th>\n",
              "      <th>18_poly</th>\n",
              "      <th>19_poly</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.402015</td>\n",
              "      <td>2.297781</td>\n",
              "      <td>2.688829</td>\n",
              "      <td>-1.120221</td>\n",
              "      <td>0.282477</td>\n",
              "      <td>-0.981968</td>\n",
              "      <td>-0.036201</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.016719</td>\n",
              "      <td>1.039782</td>\n",
              "      <td>0.026091</td>\n",
              "      <td>0.915334</td>\n",
              "      <td>0.046034</td>\n",
              "      <td>0.919357</td>\n",
              "      <td>1.024281</td>\n",
              "      <td>1.052487</td>\n",
              "      <td>0.194698</td>\n",
              "      <td>0.825415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.402015</td>\n",
              "      <td>2.209180</td>\n",
              "      <td>2.483232</td>\n",
              "      <td>-0.312389</td>\n",
              "      <td>0.471802</td>\n",
              "      <td>-0.944999</td>\n",
              "      <td>0.487788</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.202922</td>\n",
              "      <td>0.938239</td>\n",
              "      <td>0.053888</td>\n",
              "      <td>0.978101</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.393950</td>\n",
              "      <td>0.862726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.402015</td>\n",
              "      <td>2.172224</td>\n",
              "      <td>2.195472</td>\n",
              "      <td>-0.409148</td>\n",
              "      <td>0.509785</td>\n",
              "      <td>-0.973679</td>\n",
              "      <td>0.683121</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.993026</td>\n",
              "      <td>0.944320</td>\n",
              "      <td>0.181742</td>\n",
              "      <td>0.942834</td>\n",
              "      <td>0.047795</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989872</td>\n",
              "      <td>0.926537</td>\n",
              "      <td>0.370084</td>\n",
              "      <td>0.870211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.603023</td>\n",
              "      <td>2.191353</td>\n",
              "      <td>2.188808</td>\n",
              "      <td>-1.239414</td>\n",
              "      <td>0.982307</td>\n",
              "      <td>-1.198642</td>\n",
              "      <td>0.178327</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.996636</td>\n",
              "      <td>0.943030</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.943408</td>\n",
              "      <td>0.994301</td>\n",
              "      <td>0.924137</td>\n",
              "      <td>0.165954</td>\n",
              "      <td>0.962304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.402015</td>\n",
              "      <td>2.019600</td>\n",
              "      <td>1.827317</td>\n",
              "      <td>-0.583918</td>\n",
              "      <td>0.242639</td>\n",
              "      <td>-0.062761</td>\n",
              "      <td>-0.303703</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.854438</td>\n",
              "      <td>0.773250</td>\n",
              "      <td>0.246404</td>\n",
              "      <td>0.792245</td>\n",
              "      <td>0.339378</td>\n",
              "      <td>0.758548</td>\n",
              "      <td>0.948046</td>\n",
              "      <td>0.832550</td>\n",
              "      <td>0.326977</td>\n",
              "      <td>0.817564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>-1.608061</td>\n",
              "      <td>-1.291558</td>\n",
              "      <td>-1.150069</td>\n",
              "      <td>-0.847848</td>\n",
              "      <td>0.824229</td>\n",
              "      <td>-0.886313</td>\n",
              "      <td>0.529760</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055568</td>\n",
              "      <td>0.043637</td>\n",
              "      <td>0.737888</td>\n",
              "      <td>0.229038</td>\n",
              "      <td>0.759654</td>\n",
              "      <td>0.141830</td>\n",
              "      <td>0.039952</td>\n",
              "      <td>0.071897</td>\n",
              "      <td>0.263093</td>\n",
              "      <td>0.930156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>-1.608061</td>\n",
              "      <td>-1.370919</td>\n",
              "      <td>-1.144899</td>\n",
              "      <td>-0.721838</td>\n",
              "      <td>0.446227</td>\n",
              "      <td>-0.959629</td>\n",
              "      <td>0.588296</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049578</td>\n",
              "      <td>0.044037</td>\n",
              "      <td>0.748921</td>\n",
              "      <td>0.210746</td>\n",
              "      <td>0.753424</td>\n",
              "      <td>0.144455</td>\n",
              "      <td>0.018225</td>\n",
              "      <td>0.073215</td>\n",
              "      <td>0.294142</td>\n",
              "      <td>0.855736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>-1.608061</td>\n",
              "      <td>-1.288478</td>\n",
              "      <td>-1.216915</td>\n",
              "      <td>-1.427868</td>\n",
              "      <td>0.664495</td>\n",
              "      <td>-1.300016</td>\n",
              "      <td>0.378991</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055801</td>\n",
              "      <td>0.038463</td>\n",
              "      <td>0.687103</td>\n",
              "      <td>0.221308</td>\n",
              "      <td>0.724497</td>\n",
              "      <td>0.135069</td>\n",
              "      <td>0.040795</td>\n",
              "      <td>0.054848</td>\n",
              "      <td>0.120173</td>\n",
              "      <td>0.898708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>-1.608061</td>\n",
              "      <td>-1.207636</td>\n",
              "      <td>-1.198590</td>\n",
              "      <td>0.292577</td>\n",
              "      <td>-0.025033</td>\n",
              "      <td>0.168419</td>\n",
              "      <td>0.685359</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.061903</td>\n",
              "      <td>0.039881</td>\n",
              "      <td>0.837742</td>\n",
              "      <td>0.187941</td>\n",
              "      <td>0.849288</td>\n",
              "      <td>0.148808</td>\n",
              "      <td>0.062928</td>\n",
              "      <td>0.059522</td>\n",
              "      <td>0.544099</td>\n",
              "      <td>0.762957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>-1.608061</td>\n",
              "      <td>-1.437489</td>\n",
              "      <td>-1.174426</td>\n",
              "      <td>-1.421345</td>\n",
              "      <td>0.616264</td>\n",
              "      <td>-1.677496</td>\n",
              "      <td>0.480178</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.808923</td>\n",
              "      <td>0.096184</td>\n",
              "      <td>0.824776</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065685</td>\n",
              "      <td>0.121780</td>\n",
              "      <td>0.889212</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows  35 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c61e4a7-4709-4c2d-87b8-5410b51d4a54')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8c61e4a7-4709-4c2d-87b8-5410b51d4a54 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8c61e4a7-4709-4c2d-87b8-5410b51d4a54');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bfec4540-0ec2-4873-af3c-a5e41c896d7e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bfec4540-0ec2-4873-af3c-a5e41c896d7e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bfec4540-0ec2-4873-af3c-a5e41c896d7e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_73cc125a-1469-4762-92ad-bf90e62f6768\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_73cc125a-1469-4762-92ad-bf90e62f6768 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv3amwA-yJ66",
        "outputId": "0463a4d3-6492-405a-f96f-9180b868142b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    10.49        0.0814154       39         0.348858         0.125686     17.09s\n",
            "   1    12.72          0.15788       20         0.387531         0.104589      6.37s\n",
            "   2    13.38         0.187806       33         0.447514          0.16327      5.61s\n",
            "   3    15.12         0.201719       20         0.496535         0.626991      5.82s\n",
            "   4    24.12         0.219704       20         0.534471         0.301336      4.62s\n",
            "   5    32.14         0.247597       56         0.548805         0.819797      7.13s\n",
            "   6    37.79         0.284561       69         0.616783         0.225604      4.98s\n",
            "   7    35.40         0.340355       53         0.642962        0.0231784      2.28s\n",
            "   8    41.69         0.372287       80         0.678511         0.669253      1.17s\n",
            "   9    52.74         0.415027       80         0.700155         0.220545      0.00s\n",
            "reg.score (X,y) -9.000463985718417\n",
            "reg.score (X_train,y_train) 0.9505300237791671\n",
            "reg.score (X_test,y_test) -27.16903559731706\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#population_size=4000 , generations=100 , hall_of_fame=200 , n_components=10\n",
        "gp = SymbolicTransformer(generations=generations, population_size=population_size,\n",
        "hall_of_fame=hall_of_fame, n_components=n_components,\n",
        "function_set=function_set_trans,\n",
        "parsimony_coefficient=parsimony_coefficient_trans,\n",
        "max_samples=0.9, verbose=1,\n",
        "random_state=0, n_jobs=-1)\n",
        "\n",
        "gp.fit(X_train, y_train)\n",
        "\n",
        "gp_features = gp.transform(X)\n",
        "\n",
        "gp_features_df = pd.DataFrame (gp_features)\n",
        "gp_features_rename_dict = {}\n",
        "for col in gp_features_df.columns : gp_features_rename_dict [col] = str (col) + \"_\"\n",
        "gp_features_df.rename (gp_features_rename_dict  , axis =1 ,inplace=True)\n",
        "\n",
        "X = X.join (gp_features_df)\n",
        "X_train       = X.loc [train_indicies]\n",
        "X_test        = X.loc [test_indicies]\n",
        "y_train       = y.loc [train_indicies]\n",
        "y_test        = y.loc [test_indicies]\n",
        "\n",
        "reg    = LinearRegression().fit(X_train, y_train)\n",
        "y_pred = reg.predict (X)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print ( 'reg.score (X,y)'            , reg.score (X,y))\n",
        "print ('reg.score (X_train,y_train)' , reg.score (X_train,y_train))\n",
        "print ('reg.score (X_test,y_test)'   , reg.score (X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgESbX17yqi8"
      },
      "outputs": [],
      "source": [
        "X = X.drop (gp_features_df,axis=1)\n",
        "gp_features = gp.transform(X)\n",
        "#new_diabetes = np.hstack((diabetes.data, gp_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrJyYTXsy0Rl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ef8b73-700d-4bc5-b25c-486cf24e3cf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.00000000e+00,  0.00000000e+00, -0.00000000e+00, ...,\n",
              "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00],\n",
              "       [-0.00000000e+00,  0.00000000e+00, -0.00000000e+00, ...,\n",
              "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00],\n",
              "       [-0.00000000e+00,  0.00000000e+00, -0.00000000e+00, ...,\n",
              "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00],\n",
              "       ...,\n",
              "       [ 6.33671200e-01,  3.24361579e-02, -4.63520973e-02, ...,\n",
              "         1.16854450e-01, -3.68781250e-01, -6.46539509e+09],\n",
              "       [ 1.36130263e+01, -1.90726409e-01,  1.29236043e-01, ...,\n",
              "         2.64621619e-01, -4.58797534e-01,  5.72579590e+10],\n",
              "       [-0.00000000e+00,  0.00000000e+00, -0.00000000e+00, ...,\n",
              "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "gp_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pKQ9ZYl0yIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e208d795-f49a-46e2-cae2-523c4b2ed601"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(114, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "gp_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Klo9xkBjy7ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b55e8fb5-8dc1-4306-e645-a1f9a309edf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.28564370e-01,  2.34596186e+00,  2.74680808e+00, ...,\n",
              "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00],\n",
              "       [ 3.28564370e-01,  2.25190746e+00,  2.53291180e+00, ...,\n",
              "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00],\n",
              "       [ 3.28564370e-01,  2.21267622e+00,  2.23353521e+00, ...,\n",
              "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00],\n",
              "       ...,\n",
              "       [-1.64282185e+00, -1.46104072e+00, -1.31660130e+00, ...,\n",
              "         1.16854450e-01, -3.68781250e-01, -6.46539509e+09],\n",
              "       [-1.64282185e+00, -1.37522237e+00, -1.29753680e+00, ...,\n",
              "         2.64621619e-01, -4.58797534e-01,  5.72579590e+10],\n",
              "       [-1.64282185e+00, -1.61922311e+00, -1.27239721e+00, ...,\n",
              "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "np.hstack((X.values, gp_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8k-wWL40bEJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "9799b5c6-ca70-4f7a-fe07-68cbd9d2596e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0_        1_        2_           3_         4_            5_  \\\n",
              "0    -0.000000  0.000000 -0.000000    -0.000000   0.000000      0.005451   \n",
              "1    -0.000000  0.000000 -0.000000    -0.000000   0.000000      0.001406   \n",
              "2    -0.000000  0.000000 -0.000000    -0.000000   0.000000      0.000859   \n",
              "3     0.000000  0.000000 -0.000000    -0.000000   0.000000      0.003237   \n",
              "4    -0.000000  0.000000  0.000000    -0.000000   0.000000     -0.000000   \n",
              "..         ...       ...       ...          ...        ...           ...   \n",
              "109   2.580641  0.032252 -0.048726 -3616.301567  31.170070  -5072.459452   \n",
              "110   0.731506 -0.025702  0.036232  2104.708103  54.497773   4056.056077   \n",
              "111   0.633671  0.032436 -0.046352 -3076.216264  39.019246  -6091.381937   \n",
              "112  13.613026 -0.190726  0.129236  9966.864519  73.666329  10885.320336   \n",
              "113  -0.000000  0.000000 -0.000000    -0.000000  -0.000000     -0.001286   \n",
              "\n",
              "            6_        7_            8_        9_  ...       40_       41_  \\\n",
              "0    -0.000000  0.000000     -0.000000  0.000000  ...  0.000000 -0.000000   \n",
              "1    -0.000000  0.000000     -0.000000  0.000000  ...  0.000000 -0.000000   \n",
              "2    -0.000000  0.000000     -0.000000  0.000000  ...  0.000000 -0.000000   \n",
              "3    -0.000000  0.000000     -0.000000  0.000000  ...  0.000000 -0.000000   \n",
              "4    -0.000000  0.000000      0.000000  0.000000  ...  0.000000 -0.000000   \n",
              "..         ...       ...           ...       ...  ...       ...       ...   \n",
              "109  -2.184131  0.013713 -13192.186709  0.358851  ...  0.009172 -0.048726   \n",
              "110  -0.669802 -0.010937  12119.460198 -0.168633  ... -0.007784  0.036232   \n",
              "111  -0.442521  0.009417 -11653.415635  0.526852  ...  0.007826 -0.046352   \n",
              "112 -12.780124 -0.050808  41371.048432 -1.571688  ... -0.023536  0.129236   \n",
              "113  -0.000000  0.000000     -0.000000 -0.000000  ...  0.000000 -0.000000   \n",
              "\n",
              "          42_            43_         44_         45_        46_       47_  \\\n",
              "0   -0.000000       5.450686    0.535502    0.000000   0.000000 -0.000000   \n",
              "1   -0.000000       1.405797    0.244633    0.000000   0.000000 -0.000000   \n",
              "2   -0.000000       0.859032    0.155889    0.000000   0.000000 -0.000000   \n",
              "3   -0.000000       3.237149    0.471407    0.000000   0.000000 -0.000000   \n",
              "4   -0.000000      -0.000000   -0.000000    0.000000   0.000000 -0.000000   \n",
              "..        ...            ...         ...         ...        ...       ...   \n",
              "109  0.017776  -61112.249672  192.154318  276.894949 -11.504173  0.102855   \n",
              "110  0.003260   -7107.671363  -65.800995 -206.831756 -25.250262  0.176545   \n",
              "111  0.002352   -7640.736132   66.766107  267.710815 -14.354730  0.116854   \n",
              "112  0.039029 -109015.750263 -252.652608 -713.334202 -29.277572  0.264622   \n",
              "113 -0.000000      -1.651084    0.154814    0.000000   0.000000 -0.000000   \n",
              "\n",
              "          48_           49_  \n",
              "0    0.000000 -0.000000e+00  \n",
              "1    0.000000 -0.000000e+00  \n",
              "2    0.000000 -0.000000e+00  \n",
              "3    0.000000 -0.000000e+00  \n",
              "4    0.000000 -0.000000e+00  \n",
              "..        ...           ...  \n",
              "109 -0.397141 -2.830884e+10  \n",
              "110 -0.452283  1.180708e+10  \n",
              "111 -0.368781 -6.465395e+09  \n",
              "112 -0.458798  5.725796e+10  \n",
              "113  0.000000 -0.000000e+00  \n",
              "\n",
              "[114 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2839d1ab-d922-4fb2-ba1a-ddd59477e040\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0_</th>\n",
              "      <th>1_</th>\n",
              "      <th>2_</th>\n",
              "      <th>3_</th>\n",
              "      <th>4_</th>\n",
              "      <th>5_</th>\n",
              "      <th>6_</th>\n",
              "      <th>7_</th>\n",
              "      <th>8_</th>\n",
              "      <th>9_</th>\n",
              "      <th>...</th>\n",
              "      <th>40_</th>\n",
              "      <th>41_</th>\n",
              "      <th>42_</th>\n",
              "      <th>43_</th>\n",
              "      <th>44_</th>\n",
              "      <th>45_</th>\n",
              "      <th>46_</th>\n",
              "      <th>47_</th>\n",
              "      <th>48_</th>\n",
              "      <th>49_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005451</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>5.450686</td>\n",
              "      <td>0.535502</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001406</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>1.405797</td>\n",
              "      <td>0.244633</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000859</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.859032</td>\n",
              "      <td>0.155889</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003237</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>3.237149</td>\n",
              "      <td>0.471407</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>2.580641</td>\n",
              "      <td>0.032252</td>\n",
              "      <td>-0.048726</td>\n",
              "      <td>-3616.301567</td>\n",
              "      <td>31.170070</td>\n",
              "      <td>-5072.459452</td>\n",
              "      <td>-2.184131</td>\n",
              "      <td>0.013713</td>\n",
              "      <td>-13192.186709</td>\n",
              "      <td>0.358851</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009172</td>\n",
              "      <td>-0.048726</td>\n",
              "      <td>0.017776</td>\n",
              "      <td>-61112.249672</td>\n",
              "      <td>192.154318</td>\n",
              "      <td>276.894949</td>\n",
              "      <td>-11.504173</td>\n",
              "      <td>0.102855</td>\n",
              "      <td>-0.397141</td>\n",
              "      <td>-2.830884e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>0.731506</td>\n",
              "      <td>-0.025702</td>\n",
              "      <td>0.036232</td>\n",
              "      <td>2104.708103</td>\n",
              "      <td>54.497773</td>\n",
              "      <td>4056.056077</td>\n",
              "      <td>-0.669802</td>\n",
              "      <td>-0.010937</td>\n",
              "      <td>12119.460198</td>\n",
              "      <td>-0.168633</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007784</td>\n",
              "      <td>0.036232</td>\n",
              "      <td>0.003260</td>\n",
              "      <td>-7107.671363</td>\n",
              "      <td>-65.800995</td>\n",
              "      <td>-206.831756</td>\n",
              "      <td>-25.250262</td>\n",
              "      <td>0.176545</td>\n",
              "      <td>-0.452283</td>\n",
              "      <td>1.180708e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>0.633671</td>\n",
              "      <td>0.032436</td>\n",
              "      <td>-0.046352</td>\n",
              "      <td>-3076.216264</td>\n",
              "      <td>39.019246</td>\n",
              "      <td>-6091.381937</td>\n",
              "      <td>-0.442521</td>\n",
              "      <td>0.009417</td>\n",
              "      <td>-11653.415635</td>\n",
              "      <td>0.526852</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007826</td>\n",
              "      <td>-0.046352</td>\n",
              "      <td>0.002352</td>\n",
              "      <td>-7640.736132</td>\n",
              "      <td>66.766107</td>\n",
              "      <td>267.710815</td>\n",
              "      <td>-14.354730</td>\n",
              "      <td>0.116854</td>\n",
              "      <td>-0.368781</td>\n",
              "      <td>-6.465395e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>13.613026</td>\n",
              "      <td>-0.190726</td>\n",
              "      <td>0.129236</td>\n",
              "      <td>9966.864519</td>\n",
              "      <td>73.666329</td>\n",
              "      <td>10885.320336</td>\n",
              "      <td>-12.780124</td>\n",
              "      <td>-0.050808</td>\n",
              "      <td>41371.048432</td>\n",
              "      <td>-1.571688</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023536</td>\n",
              "      <td>0.129236</td>\n",
              "      <td>0.039029</td>\n",
              "      <td>-109015.750263</td>\n",
              "      <td>-252.652608</td>\n",
              "      <td>-713.334202</td>\n",
              "      <td>-29.277572</td>\n",
              "      <td>0.264622</td>\n",
              "      <td>-0.458798</td>\n",
              "      <td>5.725796e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.001286</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-1.651084</td>\n",
              "      <td>0.154814</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows  50 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2839d1ab-d922-4fb2-ba1a-ddd59477e040')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2839d1ab-d922-4fb2-ba1a-ddd59477e040 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2839d1ab-d922-4fb2-ba1a-ddd59477e040');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-db847929-dea4-43f2-a587-12ae112f8b3e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db847929-dea4-43f2-a587-12ae112f8b3e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-db847929-dea4-43f2-a587-12ae112f8b3e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d741d4f9-cefc-445a-8740-574f0d7d1d76\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('gp_features_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d741d4f9-cefc-445a-8740-574f0d7d1d76 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('gp_features_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "gp_features_df"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "gp_features_df = pd.DataFrame (gp_features)\n",
        "gp_features_rename_dict = {}\n",
        "for col in gp_features_df.columns : gp_features_rename_dict [col] = str (col) + \"_\"\n",
        "gp_features_df.rename (gp_features_rename_dict  , axis =1 ,inplace=True)\n",
        "gp_features_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFZw89fZ0F3m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "354cac1f-9e70-47f1-87bf-9d65da108259"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2  \\\n",
              "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488   \n",
              "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486   \n",
              "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106   \n",
              "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615   \n",
              "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673   \n",
              "..        ...       ...       ...          ...       ...        ...       ...   \n",
              "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206   \n",
              "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444   \n",
              "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264   \n",
              "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798   \n",
              "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734   \n",
              "\n",
              "     -2.0235481185165343_  -1.3773730890742797_  -0.7311980596320249_  ...  \\\n",
              "0                       0                     0                     0  ...   \n",
              "1                       0                     0                     0  ...   \n",
              "2                       0                     0                     0  ...   \n",
              "3                       0                     0                     0  ...   \n",
              "4                       0                     0                     0  ...   \n",
              "..                    ...                   ...                   ...  ...   \n",
              "109                     0                     1                     0  ...   \n",
              "110                     0                     1                     0  ...   \n",
              "111                     0                     1                     0  ...   \n",
              "112                     0                     1                     0  ...   \n",
              "113                     1                     0                     0  ...   \n",
              "\n",
              "          40_       41_       42_            43_         44_         45_  \\\n",
              "0    0.000000 -0.000000 -0.000000       5.450686    0.535502    0.000000   \n",
              "1    0.000000 -0.000000 -0.000000       1.405797    0.244633    0.000000   \n",
              "2    0.000000 -0.000000 -0.000000       0.859032    0.155889    0.000000   \n",
              "3    0.000000 -0.000000 -0.000000       3.237149    0.471407    0.000000   \n",
              "4    0.000000 -0.000000 -0.000000      -0.000000   -0.000000    0.000000   \n",
              "..        ...       ...       ...            ...         ...         ...   \n",
              "109  0.009172 -0.048726  0.017776  -61112.249672  192.154318  276.894949   \n",
              "110 -0.007784  0.036232  0.003260   -7107.671363  -65.800995 -206.831756   \n",
              "111  0.007826 -0.046352  0.002352   -7640.736132   66.766107  267.710815   \n",
              "112 -0.023536  0.129236  0.039029 -109015.750263 -252.652608 -713.334202   \n",
              "113  0.000000 -0.000000 -0.000000      -1.651084    0.154814    0.000000   \n",
              "\n",
              "           46_       47_       48_           49_  \n",
              "0     0.000000 -0.000000  0.000000 -0.000000e+00  \n",
              "1     0.000000 -0.000000  0.000000 -0.000000e+00  \n",
              "2     0.000000 -0.000000  0.000000 -0.000000e+00  \n",
              "3     0.000000 -0.000000  0.000000 -0.000000e+00  \n",
              "4     0.000000 -0.000000  0.000000 -0.000000e+00  \n",
              "..         ...       ...       ...           ...  \n",
              "109 -11.504173  0.102855 -0.397141 -2.830884e+10  \n",
              "110 -25.250262  0.176545 -0.452283  1.180708e+10  \n",
              "111 -14.354730  0.116854 -0.368781 -6.465395e+09  \n",
              "112 -29.277572  0.264622 -0.458798  5.725796e+10  \n",
              "113   0.000000 -0.000000  0.000000 -0.000000e+00  \n",
              "\n",
              "[114 rows x 85 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-249d869a-0ae6-4999-9440-ea599542b4f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>LP</th>\n",
              "      <th>LTIV</th>\n",
              "      <th>Price_Decay</th>\n",
              "      <th>Price_R2</th>\n",
              "      <th>TIV_Decay</th>\n",
              "      <th>TIV_R2</th>\n",
              "      <th>-2.0235481185165343_</th>\n",
              "      <th>-1.3773730890742797_</th>\n",
              "      <th>-0.7311980596320249_</th>\n",
              "      <th>...</th>\n",
              "      <th>40_</th>\n",
              "      <th>41_</th>\n",
              "      <th>42_</th>\n",
              "      <th>43_</th>\n",
              "      <th>44_</th>\n",
              "      <th>45_</th>\n",
              "      <th>46_</th>\n",
              "      <th>47_</th>\n",
              "      <th>48_</th>\n",
              "      <th>49_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.328564</td>\n",
              "      <td>2.345962</td>\n",
              "      <td>2.746808</td>\n",
              "      <td>-1.063660</td>\n",
              "      <td>0.254197</td>\n",
              "      <td>-1.007627</td>\n",
              "      <td>0.142488</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>5.450686</td>\n",
              "      <td>0.535502</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.328564</td>\n",
              "      <td>2.251907</td>\n",
              "      <td>2.532912</td>\n",
              "      <td>-0.279537</td>\n",
              "      <td>0.451914</td>\n",
              "      <td>-0.972083</td>\n",
              "      <td>0.538486</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>1.405797</td>\n",
              "      <td>0.244633</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.328564</td>\n",
              "      <td>2.212676</td>\n",
              "      <td>2.233535</td>\n",
              "      <td>-0.373456</td>\n",
              "      <td>0.491581</td>\n",
              "      <td>-0.999657</td>\n",
              "      <td>0.686106</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.859032</td>\n",
              "      <td>0.155889</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.657129</td>\n",
              "      <td>2.232983</td>\n",
              "      <td>2.226602</td>\n",
              "      <td>-1.179355</td>\n",
              "      <td>0.985050</td>\n",
              "      <td>-1.215951</td>\n",
              "      <td>0.304615</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>3.237149</td>\n",
              "      <td>0.471407</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.328564</td>\n",
              "      <td>2.050659</td>\n",
              "      <td>1.850519</td>\n",
              "      <td>-0.543097</td>\n",
              "      <td>0.212593</td>\n",
              "      <td>-0.123845</td>\n",
              "      <td>-0.059673</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>-1.642822</td>\n",
              "      <td>-1.464310</td>\n",
              "      <td>-1.247057</td>\n",
              "      <td>-0.799281</td>\n",
              "      <td>0.819965</td>\n",
              "      <td>-0.915658</td>\n",
              "      <td>0.570206</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009172</td>\n",
              "      <td>-0.048726</td>\n",
              "      <td>0.017776</td>\n",
              "      <td>-61112.249672</td>\n",
              "      <td>192.154318</td>\n",
              "      <td>276.894949</td>\n",
              "      <td>-11.504173</td>\n",
              "      <td>0.102855</td>\n",
              "      <td>-0.397141</td>\n",
              "      <td>-2.830884e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>-1.642822</td>\n",
              "      <td>-1.548557</td>\n",
              "      <td>-1.241678</td>\n",
              "      <td>-0.676969</td>\n",
              "      <td>0.425206</td>\n",
              "      <td>-0.986149</td>\n",
              "      <td>0.614444</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007784</td>\n",
              "      <td>0.036232</td>\n",
              "      <td>0.003260</td>\n",
              "      <td>-7107.671363</td>\n",
              "      <td>-65.800995</td>\n",
              "      <td>-206.831756</td>\n",
              "      <td>-25.250262</td>\n",
              "      <td>0.176545</td>\n",
              "      <td>-0.452283</td>\n",
              "      <td>1.180708e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>-1.642822</td>\n",
              "      <td>-1.461041</td>\n",
              "      <td>-1.316601</td>\n",
              "      <td>-1.362277</td>\n",
              "      <td>0.653149</td>\n",
              "      <td>-1.313418</td>\n",
              "      <td>0.456264</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007826</td>\n",
              "      <td>-0.046352</td>\n",
              "      <td>0.002352</td>\n",
              "      <td>-7640.736132</td>\n",
              "      <td>66.766107</td>\n",
              "      <td>267.710815</td>\n",
              "      <td>-14.354730</td>\n",
              "      <td>0.116854</td>\n",
              "      <td>-0.368781</td>\n",
              "      <td>-6.465395e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>-1.642822</td>\n",
              "      <td>-1.375222</td>\n",
              "      <td>-1.297537</td>\n",
              "      <td>0.307674</td>\n",
              "      <td>-0.066945</td>\n",
              "      <td>0.098426</td>\n",
              "      <td>0.687798</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023536</td>\n",
              "      <td>0.129236</td>\n",
              "      <td>0.039029</td>\n",
              "      <td>-109015.750263</td>\n",
              "      <td>-252.652608</td>\n",
              "      <td>-713.334202</td>\n",
              "      <td>-29.277572</td>\n",
              "      <td>0.264622</td>\n",
              "      <td>-0.458798</td>\n",
              "      <td>5.725796e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>-1.642822</td>\n",
              "      <td>-1.619223</td>\n",
              "      <td>-1.272397</td>\n",
              "      <td>-1.355946</td>\n",
              "      <td>0.602780</td>\n",
              "      <td>-1.676351</td>\n",
              "      <td>0.532734</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-1.651084</td>\n",
              "      <td>0.154814</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows  85 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-249d869a-0ae6-4999-9440-ea599542b4f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-249d869a-0ae6-4999-9440-ea599542b4f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-249d869a-0ae6-4999-9440-ea599542b4f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0dc4cb04-f70e-41b2-bff0-2d247d25f737\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0dc4cb04-f70e-41b2-bff0-2d247d25f737')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0dc4cb04-f70e-41b2-bff0-2d247d25f737 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e63b6627-94c3-49eb-a761-1e462e057a8f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e63b6627-94c3-49eb-a761-1e462e057a8f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X"
            }
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "\n",
        "#X = X.drop (gp_features_df,axis=1)\n",
        "\n",
        "X = X.join (gp_features_df)\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUPhTx6yzAJA"
      },
      "outputs": [],
      "source": [
        "reg = LinearRegression().fit(X_train, y_train)\n",
        "y_pred = reg.predict (X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXbMkDQS1jAr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68083328-d163-4c08-e7a6-842954938524"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-9.000463985718417"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "reg.score (X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHpHO6k5TkVf"
      },
      "outputs": [],
      "source": [
        "X_train       = X.loc [train_indicies]\n",
        "X_test        = X.loc [test_indicies]\n",
        "y_train       = y.loc [train_indicies]\n",
        "y_test        = y.loc [test_indicies]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzPGqfChEwwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cbcae5f-e8bf-4920-e350-9917f5c0d8f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9505300237791671"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "reg.score (X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGxP9xFfEo7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b23160a-999c-49e9-d670-d363889c198d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-27.16903559731706"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "reg.score (X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzBBxkI91jHb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "82a42bae-3a01-4537-8a18-6f209874e875"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot([i for i in range (y.shape [0]) ], y)\n",
        "ax.plot([i for i in range (y.shape [0]) ], y_pred ,color =\"orange\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY4o84lKBlUn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "5b93f59e-9ed0-4bc4-98d0-0f48a2552855"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.scatter(y,y_pred)\n",
        "#ax.plot([i for i in range (y.shape [0]) ],  ,color =\"green\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoGbPGyL2ju8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "d68acbf9-5d0a-410b-e7f0-0758cc7b315e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.scatter(y.loc [test_indicies],pd.Series (y_pred).loc[test_indicies])\n",
        "#ax.plot([i for i in range (y.shape [0]) ],  ,color =\"green\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "4sEtzPCWfI-X",
        "outputId": "a762254a-3332-400d-f946-5b0495ffe0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0     8.38      1.77874e+22        4          0.53947          0.85718     25.04s\n",
            "   1     6.60      5.36263e+17       29          0.49823          1.30843     27.55s\n",
            "   2     6.94      1.54325e+12        2         0.505548          1.71147     20.42s\n",
            "   3     7.59      5.56695e+11       10         0.474133          1.35068      8.46s\n",
            "   4     8.50      1.08291e+12        4         0.454699          1.57774      0.00s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SymbolicRegressor(function_set=['add', 'sub', 'mul', 'div', 'sqrt', 'log',\n",
              "                                'abs', 'neg', 'inv'],\n",
              "                  generations=5, max_samples=0.9, n_jobs=-1, p_crossover=0.7,\n",
              "                  p_hoist_mutation=0.1, p_point_mutation=0.1,\n",
              "                  p_subtree_mutation=0.1, parsimony_coefficient=1e-14,\n",
              "                  population_size=10000, random_state=0, stopping_criteria=0.1,\n",
              "                  verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>sub(X59, abs(0.402))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SymbolicRegressor</label><div class=\"sk-toggleable__content\"><pre>sub(X59, abs(0.402))</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "# Creating and training the symbolic regressor\n",
        "#parsimony_coefficient=0.0001 ,  generations=50\n",
        "function_set = ['add', 'sub', 'mul', 'div' , 'sqrt', 'log', 'abs', 'neg', 'inv']\n",
        "est_gp = SymbolicRegressor(population_size=10000,\n",
        "                           generations=5, stopping_criteria=0.1,\n",
        "                           p_crossover=0.7, p_subtree_mutation=0.1,\n",
        "                           p_hoist_mutation=0.1, p_point_mutation=0.1,\n",
        "                           max_samples=0.9, verbose=1,\n",
        "                           function_set=function_set,\n",
        "                           parsimony_coefficient=0.00000000000001, random_state=0,n_jobs=-1)\n",
        "est_gp.fit(X, y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvMwO6CN3KK6",
        "outputId": "33f4a53b-ccfa-45d9-f747-1bc7244697ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model expression: sub(X59, abs(0.402))\n",
            "Mean Squared Error: 1.102181748859987\n"
          ]
        }
      ],
      "source": [
        "# Making predictions\n",
        "y_pred_g = est_gp.predict(X)\n",
        "\n",
        "# Evaluating the model\n",
        "print(\"Model expression:\", est_gp._program)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y, y_pred_g))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCsguna5f86A",
        "outputId": "d6771372-14eb-4260-8d29-b8741b942c26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.10218174885998699"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "est_gp.score(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "UKc7ezEEfJGr",
        "outputId": "abb4a700-4d4f-4505-8674-7771029e3646"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot([i for i in range (y.shape [0]) ], y)\n",
        "ax.plot([i for i in range (y.shape [0]) ], y_pred_g ,color =\"green\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "zVgS0TjEmmky",
        "outputId": "b6169e65-a628-40a0-e117-c695cd515c0e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.scatter(y,y_pred_g)\n",
        "#ax.plot([i for i in range (y.shape [0]) ],  ,color =\"green\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3FfIAbPmmtV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edC6RMEEmm2L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-L9wNxL7fJNz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkuXT7xsmLVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efdee8e5-3ffd-4599-ba30-e1327417a586"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "114"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "X.shape [0] // number_of_test_per_fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s_m19gh3cbH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsxFcZ3SQZzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0072d109-ccf4-49ab-cb29-355dcb25cff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[106]\n",
            "{'fold_test_index': array([106]), 'fold_y_pred': array([-7.93155962e+08]), 'fold_num': 0}\n",
            "Fold 1:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[58]\n",
            "{'fold_test_index': array([58]), 'fold_y_pred': array([842473.34130196]), 'fold_num': 1}\n",
            "Fold 2:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[71]\n",
            "{'fold_test_index': array([71]), 'fold_y_pred': array([42757.2774002]), 'fold_num': 2}\n",
            "Fold 3:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[81]\n",
            "{'fold_test_index': array([81]), 'fold_y_pred': array([-2414596.36906351]), 'fold_num': 3}\n",
            "Fold 4:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 111 112 113]\n",
            "  Test:  index=[110]\n",
            "{'fold_test_index': array([110]), 'fold_y_pred': array([-4.66681306e+09]), 'fold_num': 4}\n",
            "Fold 5:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[59]\n",
            "{'fold_test_index': array([59]), 'fold_y_pred': array([2021780.89106243]), 'fold_num': 5}\n",
            "Fold 6:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[105]\n",
            "{'fold_test_index': array([105]), 'fold_y_pred': array([1.24217068e+10]), 'fold_num': 6}\n",
            "Fold 7:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[32]\n",
            "{'fold_test_index': array([32]), 'fold_y_pred': array([2501050.78827386]), 'fold_num': 7}\n",
            "Fold 8:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[101]\n",
            "{'fold_test_index': array([101]), 'fold_y_pred': array([-8.42938895e+11]), 'fold_num': 8}\n",
            "Fold 9:\n",
            "  Train: index=[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[0]\n",
            "{'fold_test_index': array([0]), 'fold_y_pred': array([-2291341.29461261]), 'fold_num': 9}\n",
            "Fold 10:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[57]\n",
            "{'fold_test_index': array([57]), 'fold_y_pred': array([1125789.39381107]), 'fold_num': 10}\n",
            "Fold 11:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[55]\n",
            "{'fold_test_index': array([55]), 'fold_y_pred': array([612780.12143708]), 'fold_num': 11}\n",
            "Fold 12:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[8]\n",
            "{'fold_test_index': array([8]), 'fold_y_pred': array([1137126.91376121]), 'fold_num': 12}\n",
            "Fold 13:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[13]\n",
            "{'fold_test_index': array([13]), 'fold_y_pred': array([1051868.14438928]), 'fold_num': 13}\n",
            "Fold 14:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[49]\n",
            "{'fold_test_index': array([49]), 'fold_y_pred': array([1445071.01406843]), 'fold_num': 14}\n",
            "Fold 15:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[69]\n",
            "{'fold_test_index': array([69]), 'fold_y_pred': array([703808.08169123]), 'fold_num': 15}\n",
            "Fold 16:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[104]\n",
            "{'fold_test_index': array([104]), 'fold_y_pred': array([-2.7627563e+10]), 'fold_num': 16}\n",
            "Fold 17:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[23]\n",
            "{'fold_test_index': array([23]), 'fold_y_pred': array([1699805.16836812]), 'fold_num': 17}\n",
            "Fold 18:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[99]\n",
            "{'fold_test_index': array([99]), 'fold_y_pred': array([-1.07171579e+10]), 'fold_num': 18}\n",
            "Fold 19:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[70]\n",
            "{'fold_test_index': array([70]), 'fold_y_pred': array([1917262.45243587]), 'fold_num': 19}\n",
            "Fold 20:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[29]\n",
            "{'fold_test_index': array([29]), 'fold_y_pred': array([2236116.1431507]), 'fold_num': 20}\n",
            "Fold 21:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[18]\n",
            "{'fold_test_index': array([18]), 'fold_y_pred': array([1388755.23351774]), 'fold_num': 21}\n",
            "Fold 22:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[22]\n",
            "{'fold_test_index': array([22]), 'fold_y_pred': array([703431.37771634]), 'fold_num': 22}\n",
            "Fold 23:\n",
            "  Train: index=[  0   1   2   3   4   5   6   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[7]\n",
            "{'fold_test_index': array([7]), 'fold_y_pred': array([-1294410.69772549]), 'fold_num': 23}\n",
            "Fold 24:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[102]\n",
            "{'fold_test_index': array([102]), 'fold_y_pred': array([3.88782432e+10]), 'fold_num': 24}\n",
            "Fold 25:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[62]\n",
            "{'fold_test_index': array([62]), 'fold_y_pred': array([1349803.44555204]), 'fold_num': 25}\n",
            "Fold 26:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[51]\n",
            "{'fold_test_index': array([51]), 'fold_y_pred': array([-252747.42161029]), 'fold_num': 26}\n",
            "Fold 27:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[107]\n",
            "{'fold_test_index': array([107]), 'fold_y_pred': array([9.65431949e+08]), 'fold_num': 27}\n",
            "Fold 28:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[92]\n",
            "{'fold_test_index': array([92]), 'fold_y_pred': array([-929656.88612055]), 'fold_num': 28}\n",
            "Fold 29:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[65]\n",
            "{'fold_test_index': array([65]), 'fold_y_pred': array([-1602944.88289042]), 'fold_num': 29}\n",
            "Fold 30:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[48]\n",
            "{'fold_test_index': array([48]), 'fold_y_pred': array([790000.93967845]), 'fold_num': 30}\n",
            "Fold 31:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[35]\n",
            "{'fold_test_index': array([35]), 'fold_y_pred': array([-1012838.05663192]), 'fold_num': 31}\n",
            "Fold 32:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[82]\n",
            "{'fold_test_index': array([82]), 'fold_y_pred': array([-964359.35985694]), 'fold_num': 32}\n",
            "Fold 33:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[87]\n",
            "{'fold_test_index': array([87]), 'fold_y_pred': array([3293607.71389742]), 'fold_num': 33}\n",
            "Fold 34:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[40]\n",
            "{'fold_test_index': array([40]), 'fold_y_pred': array([1419876.61049849]), 'fold_num': 34}\n",
            "Fold 35:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 110 111 112 113]\n",
            "  Test:  index=[109]\n",
            "{'fold_test_index': array([109]), 'fold_y_pred': array([-9.08493394e+09]), 'fold_num': 35}\n",
            "Fold 36:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[14]\n",
            "{'fold_test_index': array([14]), 'fold_y_pred': array([1360101.27495968]), 'fold_num': 36}\n",
            "Fold 37:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[44]\n",
            "{'fold_test_index': array([44]), 'fold_y_pred': array([2355156.54138207]), 'fold_num': 37}\n",
            "Fold 38:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[50]\n",
            "{'fold_test_index': array([50]), 'fold_y_pred': array([201830.14354599]), 'fold_num': 38}\n",
            "Fold 39:\n",
            "  Train: index=[  0   1   2   3   4   5   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[6]\n",
            "{'fold_test_index': array([6]), 'fold_y_pred': array([936631.32517366]), 'fold_num': 39}\n",
            "Fold 40:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[17]\n",
            "{'fold_test_index': array([17]), 'fold_y_pred': array([1445394.76884339]), 'fold_num': 40}\n",
            "Fold 41:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[27]\n",
            "{'fold_test_index': array([27]), 'fold_y_pred': array([-47635.33638358]), 'fold_num': 41}\n",
            "Fold 42:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[12]\n",
            "{'fold_test_index': array([12]), 'fold_y_pred': array([1086269.6592748]), 'fold_num': 42}\n",
            "Fold 43:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[34]\n",
            "{'fold_test_index': array([34]), 'fold_y_pred': array([802454.48688494]), 'fold_num': 43}\n",
            "Fold 44:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[11]\n",
            "{'fold_test_index': array([11]), 'fold_y_pred': array([-1985322.20223552]), 'fold_num': 44}\n",
            "Fold 45:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[90]\n",
            "{'fold_test_index': array([90]), 'fold_y_pred': array([1442457.00144741]), 'fold_num': 45}\n",
            "Fold 46:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[85]\n",
            "{'fold_test_index': array([85]), 'fold_y_pred': array([979763.44338574]), 'fold_num': 46}\n",
            "Fold 47:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[68]\n",
            "{'fold_test_index': array([68]), 'fold_y_pred': array([477108.45097843]), 'fold_num': 47}\n",
            "Fold 48:\n",
            "  Train: index=[  0   1   2   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[3]\n",
            "{'fold_test_index': array([3]), 'fold_y_pred': array([-622120.30082421]), 'fold_num': 48}\n",
            "Fold 49:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[30]\n",
            "{'fold_test_index': array([30]), 'fold_y_pred': array([1614051.69546106]), 'fold_num': 49}\n",
            "Fold 50:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[66]\n",
            "{'fold_test_index': array([66]), 'fold_y_pred': array([525243.21509505]), 'fold_num': 50}\n",
            "Fold 51:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 113]\n",
            "  Test:  index=[112]\n",
            "{'fold_test_index': array([112]), 'fold_y_pred': array([7.0031934e+09]), 'fold_num': 51}\n",
            "Fold 52:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[15]\n",
            "{'fold_test_index': array([15]), 'fold_y_pred': array([211516.29275663]), 'fold_num': 52}\n",
            "Fold 53:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[63]\n",
            "{'fold_test_index': array([63]), 'fold_y_pred': array([1708967.77533314]), 'fold_num': 53}\n",
            "Fold 54:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[52]\n",
            "{'fold_test_index': array([52]), 'fold_y_pred': array([-760593.42571047]), 'fold_num': 54}\n",
            "Fold 55:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[64]\n",
            "{'fold_test_index': array([64]), 'fold_y_pred': array([-1883773.68904452]), 'fold_num': 55}\n",
            "Fold 56:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[38]\n",
            "{'fold_test_index': array([38]), 'fold_y_pred': array([120901.84375257]), 'fold_num': 56}\n",
            "Fold 57:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[74]\n",
            "{'fold_test_index': array([74]), 'fold_y_pred': array([-21435.62625835]), 'fold_num': 57}\n",
            "Fold 58:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[75]\n",
            "{'fold_test_index': array([75]), 'fold_y_pred': array([2054851.32716206]), 'fold_num': 58}\n",
            "Fold 59:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[9]\n",
            "{'fold_test_index': array([9]), 'fold_y_pred': array([525120.41516715]), 'fold_num': 59}\n",
            "Fold 60:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[24]\n",
            "{'fold_test_index': array([24]), 'fold_y_pred': array([-819897.94945336]), 'fold_num': 60}\n",
            "Fold 61:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[10]\n",
            "{'fold_test_index': array([10]), 'fold_y_pred': array([495604.28731463]), 'fold_num': 61}\n",
            "Fold 62:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[42]\n",
            "{'fold_test_index': array([42]), 'fold_y_pred': array([-857012.76645972]), 'fold_num': 62}\n",
            "Fold 63:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[73]\n",
            "{'fold_test_index': array([73]), 'fold_y_pred': array([-720189.56374346]), 'fold_num': 63}\n",
            "Fold 64:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[56]\n",
            "{'fold_test_index': array([56]), 'fold_y_pred': array([-147052.84374358]), 'fold_num': 64}\n",
            "Fold 65:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[95]\n",
            "{'fold_test_index': array([95]), 'fold_y_pred': array([1766091.02055475]), 'fold_num': 65}\n",
            "Fold 66:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[97]\n",
            "{'fold_test_index': array([97]), 'fold_y_pred': array([8.32582866e+10]), 'fold_num': 66}\n",
            "Fold 67:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[100]\n",
            "{'fold_test_index': array([100]), 'fold_y_pred': array([5.36540348e+10]), 'fold_num': 67}\n",
            "Fold 68:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[16]\n",
            "{'fold_test_index': array([16]), 'fold_y_pred': array([403770.1475356]), 'fold_num': 68}\n",
            "Fold 69:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[53]\n",
            "{'fold_test_index': array([53]), 'fold_y_pred': array([-451422.75451616]), 'fold_num': 69}\n",
            "Fold 70:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 112 113]\n",
            "  Test:  index=[111]\n",
            "{'fold_test_index': array([111]), 'fold_y_pred': array([9.40732552e+09]), 'fold_num': 70}\n",
            "Fold 71:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[67]\n",
            "{'fold_test_index': array([67]), 'fold_y_pred': array([436844.93202381]), 'fold_num': 71}\n",
            "Fold 72:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[21]\n",
            "{'fold_test_index': array([21]), 'fold_y_pred': array([2590316.49606683]), 'fold_num': 72}\n",
            "Fold 73:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[28]\n",
            "{'fold_test_index': array([28]), 'fold_y_pred': array([2009016.46949864]), 'fold_num': 73}\n",
            "Fold 74:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[98]\n",
            "{'fold_test_index': array([98]), 'fold_y_pred': array([-5.21447459e+10]), 'fold_num': 74}\n",
            "Fold 75:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[61]\n",
            "{'fold_test_index': array([61]), 'fold_y_pred': array([821936.16762923]), 'fold_num': 75}\n",
            "Fold 76:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[88]\n",
            "{'fold_test_index': array([88]), 'fold_y_pred': array([2598617.76708921]), 'fold_num': 76}\n",
            "Fold 77:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[37]\n",
            "{'fold_test_index': array([37]), 'fold_y_pred': array([-972343.15138025]), 'fold_num': 77}\n",
            "Fold 78:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[93]\n",
            "{'fold_test_index': array([93]), 'fold_y_pred': array([-1146073.79046398]), 'fold_num': 78}\n",
            "Fold 79:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[78]\n",
            "{'fold_test_index': array([78]), 'fold_y_pred': array([1016942.46144334]), 'fold_num': 79}\n",
            "Fold 80:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[76]\n",
            "{'fold_test_index': array([76]), 'fold_y_pred': array([883017.51393552]), 'fold_num': 80}\n",
            "Fold 81:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[19]\n",
            "{'fold_test_index': array([19]), 'fold_y_pred': array([-2340429.77448624]), 'fold_num': 81}\n",
            "Fold 82:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[60]\n",
            "{'fold_test_index': array([60]), 'fold_y_pred': array([931208.8647717]), 'fold_num': 82}\n",
            "Fold 83:\n",
            "  Train: index=[  0   1   2   3   4   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[5]\n",
            "{'fold_test_index': array([5]), 'fold_y_pred': array([-4573866.8234988]), 'fold_num': 83}\n",
            "Fold 84:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[108]\n",
            "{'fold_test_index': array([108]), 'fold_y_pred': array([3.75204092e+09]), 'fold_num': 84}\n",
            "Fold 85:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[36]\n",
            "{'fold_test_index': array([36]), 'fold_y_pred': array([-997909.64061824]), 'fold_num': 85}\n",
            "Fold 86:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[86]\n",
            "{'fold_test_index': array([86]), 'fold_y_pred': array([2516876.66257473]), 'fold_num': 86}\n",
            "Fold 87:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[26]\n",
            "{'fold_test_index': array([26]), 'fold_y_pred': array([-1261147.3502318]), 'fold_num': 87}\n",
            "Fold 88:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112]\n",
            "  Test:  index=[113]\n",
            "{'fold_test_index': array([113]), 'fold_y_pred': array([-47134729.50254445]), 'fold_num': 88}\n",
            "Fold 89:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[83]\n",
            "{'fold_test_index': array([83]), 'fold_y_pred': array([-1640728.62287921]), 'fold_num': 89}\n",
            "Fold 90:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[33]\n",
            "{'fold_test_index': array([33]), 'fold_y_pred': array([846532.27000769]), 'fold_num': 90}\n",
            "Fold 91:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[25]\n",
            "{'fold_test_index': array([25]), 'fold_y_pred': array([-439592.868433]), 'fold_num': 91}\n",
            "Fold 92:\n",
            "  Train: index=[  0   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[1]\n",
            "{'fold_test_index': array([1]), 'fold_y_pred': array([951954.10013248]), 'fold_num': 92}\n",
            "Fold 93:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[84]\n",
            "{'fold_test_index': array([84]), 'fold_y_pred': array([260714.90044765]), 'fold_num': 93}\n",
            "Fold 94:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[20]\n",
            "{'fold_test_index': array([20]), 'fold_y_pred': array([534884.63159356]), 'fold_num': 94}\n",
            "Fold 95:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[91]\n",
            "{'fold_test_index': array([91]), 'fold_y_pred': array([-704185.94362207]), 'fold_num': 95}\n",
            "Fold 96:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[77]\n",
            "{'fold_test_index': array([77]), 'fold_y_pred': array([72642.48583912]), 'fold_num': 96}\n",
            "Fold 97:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[45]\n",
            "{'fold_test_index': array([45]), 'fold_y_pred': array([3016020.95107048]), 'fold_num': 97}\n",
            "Fold 98:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[39]\n",
            "{'fold_test_index': array([39]), 'fold_y_pred': array([9834268.23132089]), 'fold_num': 98}\n",
            "Fold 99:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[103]\n",
            "{'fold_test_index': array([103]), 'fold_y_pred': array([3.80031176e+10]), 'fold_num': 99}\n",
            "Fold 100:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[54]\n",
            "{'fold_test_index': array([54]), 'fold_y_pred': array([-133072.92206898]), 'fold_num': 100}\n",
            "Fold 101:\n",
            "  Train: index=[  0   1   2   3   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[4]\n",
            "{'fold_test_index': array([4]), 'fold_y_pred': array([6485786.43098632]), 'fold_num': 101}\n",
            "Fold 102:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[96]\n",
            "{'fold_test_index': array([96]), 'fold_y_pred': array([680560.51233995]), 'fold_num': 102}\n",
            "Fold 103:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[89]\n",
            "{'fold_test_index': array([89]), 'fold_y_pred': array([229671.83518634]), 'fold_num': 103}\n",
            "Fold 104:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[79]\n",
            "{'fold_test_index': array([79]), 'fold_y_pred': array([94019.28499486]), 'fold_num': 104}\n",
            "Fold 105:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[41]\n",
            "{'fold_test_index': array([41]), 'fold_y_pred': array([2516292.4484544]), 'fold_num': 105}\n",
            "Fold 106:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[31]\n",
            "{'fold_test_index': array([31]), 'fold_y_pred': array([1051884.68734069]), 'fold_num': 106}\n",
            "Fold 107:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[47]\n",
            "{'fold_test_index': array([47]), 'fold_y_pred': array([864057.62047531]), 'fold_num': 107}\n",
            "Fold 108:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[80]\n",
            "{'fold_test_index': array([80]), 'fold_y_pred': array([1118406.58830637]), 'fold_num': 108}\n",
            "Fold 109:\n",
            "  Train: index=[  0   1   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[2]\n",
            "{'fold_test_index': array([2]), 'fold_y_pred': array([259320.53344065]), 'fold_num': 109}\n",
            "Fold 110:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[43]\n",
            "{'fold_test_index': array([43]), 'fold_y_pred': array([258303.10835063]), 'fold_num': 110}\n",
            "Fold 111:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[94]\n",
            "{'fold_test_index': array([94]), 'fold_y_pred': array([2013207.70241538]), 'fold_num': 111}\n",
            "Fold 112:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[72]\n",
            "{'fold_test_index': array([72]), 'fold_y_pred': array([1223038.08762376]), 'fold_num': 112}\n",
            "Fold 113:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[46]\n",
            "{'fold_test_index': array([46]), 'fold_y_pred': array([2004590.79341906]), 'fold_num': 113}\n"
          ]
        }
      ],
      "source": [
        "kf              = KFold(n_splits=X.shape [0] // number_of_test_per_fold , shuffle= True )\n",
        "\n",
        "fold_number     = 0\n",
        "\n",
        "kfold_pred_dict = {fold_test_index :np.array([])  ,\n",
        "                   fold_y_pred     : np.array ([]) ,\n",
        "                   }\n",
        "\n",
        "kfold_pred_list = []\n",
        "model_NN = MLPRegressor(\n",
        "    hidden_layer_sizes=(250, 200, 100, 100,100),  # More layers and different numbers of neurons\n",
        "    activation='tanh',  # Different activation function\n",
        "    solver='sgd',  # Different optimizer\n",
        "    learning_rate_init=0.01,  # Initial learning rate\n",
        "    learning_rate='adaptive',  # Adaptive learning rate\n",
        "    max_iter=1000,  # More iterations\n",
        "    batch_size=64,  # Smaller batch size\n",
        "    alpha=0.0001,  # L2 regularization\n",
        "    early_stopping=True,  # Enable early stopping\n",
        "    n_iter_no_change=20,  # Patience for early stopping\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "      print(f\"Fold {i}:\")\n",
        "      print(f\"  Train: index={train_index}\")\n",
        "      print(f\"  Test:  index={test_index}\")\n",
        "\n",
        "      X_train_fold  = X.loc [train_index]\n",
        "      X_test_fold   = X.loc [test_index]\n",
        "\n",
        "      y_train_fold  = y.loc [train_index]\n",
        "      y_test_fold   = y.loc [test_index]\n",
        "\n",
        "      reg_fold = LinearRegression().fit(X_train_fold, y_train_fold)\n",
        "      #reg_fold = model_NN.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "      fold_y_pred_value = scaler_dict [Target].inverse_transform (reg_fold.predict (X_test_fold).reshape (-1,1))\n",
        "\n",
        "      kfold_pred_dict [fold_test_index] =  test_index\n",
        "      kfold_pred_dict [fold_y_pred]     =  fold_y_pred_value.reshape (-1)\n",
        "      kfold_pred_dict [fold_num ]       =  i\n",
        "\n",
        "      kfold_pred_list.append (pd.DataFrame ( kfold_pred_dict))\n",
        "\n",
        "\n",
        "      print ( kfold_pred_dict)\n",
        "\n",
        "kfold_pred_df = pd.concat (kfold_pred_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "7OYluiFZjUts",
        "outputId": "b8e9f79a-09c2-44cd-cd91-bc5e4ac0a2ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      LPB                           MMC  Year       LP     LTIV  PC  \\\n",
              "0    1000   iPhone XS Max_512GB_Verizon  2018  1029.35  656.816  19   \n",
              "1    1000  iPhone XS Max_512GB_Unlocked  2018  1014.39  634.388  20   \n",
              "2    1000  iPhone XS Max_256GB_Unlocked  2018  1008.15  602.997  20   \n",
              "3    1000        iPhone X_256GB_Verizon  2017  1011.38  602.270  19   \n",
              "4     900   iPhone XS Max_256GB_Verizon  2018   982.38  562.836  20   \n",
              "..    ...                           ...   ...      ...      ...  ..   \n",
              "109   400       iPhone 7_256GB_T-Mobile  2016   423.30  238.041  17   \n",
              "110   400       iPhone 7_128GB_T-Mobile  2016   409.90  238.605  19   \n",
              "111   400            iPhone 7_32GB_AT&T  2016   423.82  230.749  20   \n",
              "112   400   iPhone 7 Plus_32GB_T-Mobile  2016   437.47  232.748  19   \n",
              "113   300        iPhone 7_32GB_T-Mobile  2016   398.66  235.384  18   \n",
              "\n",
              "     Price_Decay  Price_R2  TIV_Decay    TIV_R2   Profit    Profit_Pred  \\\n",
              "0      -0.001192  0.894662  -0.001335  0.879887    41381 -531899.697988   \n",
              "1      -0.001009  0.911918  -0.001326  0.918513   227473  790518.041632   \n",
              "2      -0.001031  0.915380  -0.001333  0.932912  1514777  736038.014269   \n",
              "3      -0.001220  0.958448  -0.001388  0.895701   126462  915436.593137   \n",
              "4      -0.001070  0.891031  -0.001114  0.860168   199737 -786018.700838   \n",
              "..           ...       ...        ...       ...      ...            ...   \n",
              "109    -0.001130  0.944040  -0.001312  0.921607     9867  535338.497667   \n",
              "110    -0.001102  0.909587  -0.001330  0.925922    84340  427041.757517   \n",
              "111    -0.001262  0.929481  -0.001412  0.910493   397857  481107.547500   \n",
              "112    -0.000871  0.866634  -0.001058  0.933077   827457  676207.107730   \n",
              "113    -0.001261  0.925085  -0.001503  0.917952   413425  413424.981862   \n",
              "\n",
              "      fold_y_pred  fold_num  \n",
              "0   -2.291341e+06         9  \n",
              "1    9.519541e+05        92  \n",
              "2    2.593205e+05       109  \n",
              "3   -6.221203e+05        48  \n",
              "4    6.485786e+06       101  \n",
              "..            ...       ...  \n",
              "109 -9.084934e+09        35  \n",
              "110 -4.666813e+09         4  \n",
              "111  9.407326e+09        70  \n",
              "112  7.003193e+09        51  \n",
              "113 -4.713473e+07        88  \n",
              "\n",
              "[114 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e213445-7bdd-4d1e-b084-2782efc1630e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LPB</th>\n",
              "      <th>MMC</th>\n",
              "      <th>Year</th>\n",
              "      <th>LP</th>\n",
              "      <th>LTIV</th>\n",
              "      <th>PC</th>\n",
              "      <th>Price_Decay</th>\n",
              "      <th>Price_R2</th>\n",
              "      <th>TIV_Decay</th>\n",
              "      <th>TIV_R2</th>\n",
              "      <th>Profit</th>\n",
              "      <th>Profit_Pred</th>\n",
              "      <th>fold_y_pred</th>\n",
              "      <th>fold_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone XS Max_512GB_Verizon</td>\n",
              "      <td>2018</td>\n",
              "      <td>1029.35</td>\n",
              "      <td>656.816</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.001192</td>\n",
              "      <td>0.894662</td>\n",
              "      <td>-0.001335</td>\n",
              "      <td>0.879887</td>\n",
              "      <td>41381</td>\n",
              "      <td>-531899.697988</td>\n",
              "      <td>-2.291341e+06</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone XS Max_512GB_Unlocked</td>\n",
              "      <td>2018</td>\n",
              "      <td>1014.39</td>\n",
              "      <td>634.388</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.001009</td>\n",
              "      <td>0.911918</td>\n",
              "      <td>-0.001326</td>\n",
              "      <td>0.918513</td>\n",
              "      <td>227473</td>\n",
              "      <td>790518.041632</td>\n",
              "      <td>9.519541e+05</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone XS Max_256GB_Unlocked</td>\n",
              "      <td>2018</td>\n",
              "      <td>1008.15</td>\n",
              "      <td>602.997</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.001031</td>\n",
              "      <td>0.915380</td>\n",
              "      <td>-0.001333</td>\n",
              "      <td>0.932912</td>\n",
              "      <td>1514777</td>\n",
              "      <td>736038.014269</td>\n",
              "      <td>2.593205e+05</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>iPhone X_256GB_Verizon</td>\n",
              "      <td>2017</td>\n",
              "      <td>1011.38</td>\n",
              "      <td>602.270</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.001220</td>\n",
              "      <td>0.958448</td>\n",
              "      <td>-0.001388</td>\n",
              "      <td>0.895701</td>\n",
              "      <td>126462</td>\n",
              "      <td>915436.593137</td>\n",
              "      <td>-6.221203e+05</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>900</td>\n",
              "      <td>iPhone XS Max_256GB_Verizon</td>\n",
              "      <td>2018</td>\n",
              "      <td>982.38</td>\n",
              "      <td>562.836</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.001070</td>\n",
              "      <td>0.891031</td>\n",
              "      <td>-0.001114</td>\n",
              "      <td>0.860168</td>\n",
              "      <td>199737</td>\n",
              "      <td>-786018.700838</td>\n",
              "      <td>6.485786e+06</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>400</td>\n",
              "      <td>iPhone 7_256GB_T-Mobile</td>\n",
              "      <td>2016</td>\n",
              "      <td>423.30</td>\n",
              "      <td>238.041</td>\n",
              "      <td>17</td>\n",
              "      <td>-0.001130</td>\n",
              "      <td>0.944040</td>\n",
              "      <td>-0.001312</td>\n",
              "      <td>0.921607</td>\n",
              "      <td>9867</td>\n",
              "      <td>535338.497667</td>\n",
              "      <td>-9.084934e+09</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>400</td>\n",
              "      <td>iPhone 7_128GB_T-Mobile</td>\n",
              "      <td>2016</td>\n",
              "      <td>409.90</td>\n",
              "      <td>238.605</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.001102</td>\n",
              "      <td>0.909587</td>\n",
              "      <td>-0.001330</td>\n",
              "      <td>0.925922</td>\n",
              "      <td>84340</td>\n",
              "      <td>427041.757517</td>\n",
              "      <td>-4.666813e+09</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>400</td>\n",
              "      <td>iPhone 7_32GB_AT&amp;T</td>\n",
              "      <td>2016</td>\n",
              "      <td>423.82</td>\n",
              "      <td>230.749</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.001262</td>\n",
              "      <td>0.929481</td>\n",
              "      <td>-0.001412</td>\n",
              "      <td>0.910493</td>\n",
              "      <td>397857</td>\n",
              "      <td>481107.547500</td>\n",
              "      <td>9.407326e+09</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>400</td>\n",
              "      <td>iPhone 7 Plus_32GB_T-Mobile</td>\n",
              "      <td>2016</td>\n",
              "      <td>437.47</td>\n",
              "      <td>232.748</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.000871</td>\n",
              "      <td>0.866634</td>\n",
              "      <td>-0.001058</td>\n",
              "      <td>0.933077</td>\n",
              "      <td>827457</td>\n",
              "      <td>676207.107730</td>\n",
              "      <td>7.003193e+09</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>300</td>\n",
              "      <td>iPhone 7_32GB_T-Mobile</td>\n",
              "      <td>2016</td>\n",
              "      <td>398.66</td>\n",
              "      <td>235.384</td>\n",
              "      <td>18</td>\n",
              "      <td>-0.001261</td>\n",
              "      <td>0.925085</td>\n",
              "      <td>-0.001503</td>\n",
              "      <td>0.917952</td>\n",
              "      <td>413425</td>\n",
              "      <td>413424.981862</td>\n",
              "      <td>-4.713473e+07</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows  14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e213445-7bdd-4d1e-b084-2782efc1630e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e213445-7bdd-4d1e-b084-2782efc1630e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e213445-7bdd-4d1e-b084-2782efc1630e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d4bc0998-6963-41ea-9202-c997c5ff0b3a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d4bc0998-6963-41ea-9202-c997c5ff0b3a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d4bc0998-6963-41ea-9202-c997c5ff0b3a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3cfa05e1-6832-4adf-bdc9-7d7036659cb4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data_input')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3cfa05e1-6832-4adf-bdc9-7d7036659cb4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data_input');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_input",
              "summary": "{\n  \"name\": \"data_input\",\n  \"rows\": 114,\n  \"fields\": [\n    {\n      \"column\": \"LPB\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          900,\n          500,\n          1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MMC\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 114,\n        \"samples\": [\n          \"iPhone 11_128GB_T-Mobile\",\n          \"iPhone XS Max_256GB_Verizon\",\n          \"iPhone 8 Plus_256GB_Verizon\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2016,\n        \"max\": 2019,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2017,\n          2016,\n          2018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 159.75913399110536,\n        \"min\": 398.66,\n        \"max\": 1029.35,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          535.16,\n          982.38,\n          767.27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LTIV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105.31749580441497,\n        \"min\": 207.186,\n        \"max\": 656.816,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          239.438,\n          562.836,\n          409.377\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 16,\n        \"max\": 21,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          19,\n          20,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price_Decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00023556628349597262,\n        \"min\": -0.001411932,\n        \"max\": -0.00044894,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          -0.000637359,\n          -0.001070336,\n          -0.001031244\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price_R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08766141185476332,\n        \"min\": 0.512654,\n        \"max\": 0.980328,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          0.763261,\n          0.891031,\n          0.938773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TIV_Decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0002520634633665147,\n        \"min\": -0.00158934,\n        \"max\": -0.00050391,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          -0.00050391,\n          -0.00111357,\n          -0.00108685\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TIV_R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09797161857413617,\n        \"min\": 0.466594,\n        \"max\": 0.958327,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          0.643396,\n          0.860168,\n          0.838461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Profit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1063143,\n        \"min\": 4932,\n        \"max\": 5747639,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          276864,\n          199737,\n          110921\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Profit_Pred\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 810467.5283854266,\n        \"min\": -786018.7008378336,\n        \"max\": 4995819.162842119,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          -457440.4716777005,\n          -786018.7008378336,\n          543704.6110121149\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fold_y_pred\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 79989802412.15372,\n        \"min\": -842938895185.4662,\n        \"max\": 83258286644.28091,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          1118406.588306366,\n          6485786.430986317,\n          1419876.6104984945\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fold_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33,\n        \"min\": 0,\n        \"max\": 113,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          108,\n          101,\n          34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "data_input = data_input.merge (kfold_pred_df.set_index (fold_test_index) , how = \"left\" , left_index = True , right_index = True)\n",
        "data_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk78pExbzZcv",
        "outputId": "8bbf085a-c596-415f-acdc-39c98b9a8ade"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(114, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "kfold_pred_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UqN9zbhzIre",
        "outputId": "42406d1d-7c93-4197-a7fe-0409460d2876"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "kfold_pred_df [fold_test_index].duplicated().sum ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "FQRSIZ0Ajmh4",
        "outputId": "4e37997e-1fc6-48fb-c335-5d26ef96e811"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Profit', ylabel='fold_y_pred'>"
            ]
          },
          "metadata": {},
          "execution_count": 132
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHACAYAAABeV0mSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7fklEQVR4nO3de3TU9Z3/8dcQIRAgEciFWyDBRAS5Ra4hlYuLAqVUqu3S1G642m0bbkV+VqzV4tFGVmixYMFWm5TdJVhaLiu1IlIgR0AhQLbAIiUmXFQSEiKJmdiASX5/UEYGMsnMZGa+3/nO83HOnCPf+c7knZk439d8rraGhoYGAQAAWEQrowsAAADwJcINAACwFMINAACwFMINAACwFMINAACwFMINAACwFMINAACwFMINAACwFMINAACwFMINAACwlJAON3l5eZo6daq6d+8um82mrVu3evwcDQ0NWrFihe68806Fh4erR48eev75531fLAAAcMttRhdgJLvdrsGDB2v27Nl66KGHvHqOhQsX6u2339aKFSs0cOBAVVRUqKKiwseVAgAAd9nYOPMam82mLVu2aNq0aY5jtbW1+slPfqLc3FxdvnxZAwYM0PLlyzVu3DhJ0smTJzVo0CAdP35cffv2NaZwAADgJKS7pZozb948HThwQBs3btTf/vY3fetb39KkSZN0+vRpSdIbb7yhPn36aPv27UpMTFRCQoLmzp1Lyw0AAAYi3Lhw7tw5ZWdna9OmTbr33nt1xx13aMmSJfrKV76i7OxsSVJRUZHOnj2rTZs2af369crJydHhw4f1zW9+0+DqAQAIXSE95qYpx44dU11dne68806n47W1terSpYskqb6+XrW1tVq/fr3jvNdee01Dhw7VqVOn6KoCAMAAhBsXqqurFRYWpsOHDyssLMzpvg4dOkiSunXrpttuu80pAPXr10/StZYfwg0AAIFHuHEhJSVFdXV1unjxou69995Gz0lLS9MXX3yhDz/8UHfccYck6e9//7skqXfv3gGrFQAAfCmkZ0tVV1ersLBQ0rUw84tf/ELjx49X586d1atXL333u9/Vvn37tHLlSqWkpKisrEy7du3SoEGDNGXKFNXX12v48OHq0KGDVq1apfr6emVmZioyMlJvv/22wb8dAAChKaTDzZ49ezR+/Phbjs+YMUM5OTm6evWqnnvuOa1fv14ff/yxoqOjNWrUKC1btkwDBw6UJH3yySeaP3++3n77bbVv316TJ0/WypUr1blz50D/OgAAQCEebgAAgPUwFRwAAFgK4QYAAFhKyM2Wqq+v1yeffKKOHTvKZrMZXQ4AAHBDQ0ODPvvsM3Xv3l2tWjXdNhNy4eaTTz5RfHy80WUAAAAvnD9/Xj179mzynJALNx07dpR07cWJjIw0uBoAAOCOqqoqxcfHO67jTQm5cHO9KyoyMpJwAwBAkHFnSAkDigEAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKWE3PYLRioqq9bZiholdGmvxOj2RpcDAIAlEW4C4HLNFS3ILVDe6TLHsTHJMVqdnqKoiNYGVgYAgPXQLRUAC3ILtK+w3OnYvsJyzc89alBFAABYF+HGz4rKqpV3ukx1DQ1Ox+saGpR3ukzF5XaDKgMAwJoIN352tqKmyfvPXCLcAADgS4QbP+vdOaLJ+xO6MLAYAABfItz4WZ+YDhqTHKMwm83peJjNpjHJMcyaAgDAxwg3AbA6PUVpSdFOx9KSorU6PcWgigAAsC6mggdAVERrrZ8zQsXldp25ZGedGwAA/IhwE0CJ0YQaAAD8jW4pAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKbcZXQC8U1RWrbMVNUro0l6J0e2NLgcAANMwtOVm7dq1GjRokCIjIxUZGanU1FT95S9/afIxmzZt0l133aW2bdtq4MCBevPNNwNUrTlcrrmijNcO6r6VezUr+5DGr9ijjNcOqrLmqtGlAQBgCoaGm549e+qFF17Q4cOHlZ+fr/vuu08PPvigTpw40ej5+/fvV3p6uubMmaOjR49q2rRpmjZtmo4fPx7gyo2zILdA+wrLnY7tKyzX/NyjBlUEAIC52BoaGhqMLuJGnTt31osvvqg5c+bcct/06dNlt9u1fft2x7FRo0ZpyJAhWrdunVvPX1VVpaioKFVWVioyMtJndQdCUVm17lu51+X9u5eMo4sKAGBJnly/TTOguK6uThs3bpTdbldqamqj5xw4cEATJkxwOjZx4kQdOHDA5fPW1taqqqrK6RaszlbUNHn/mUv2AFUCAIB5GR5ujh07pg4dOig8PFzf//73tWXLFvXv37/Rc0tKShQXF+d0LC4uTiUlJS6fPysrS1FRUY5bfHy8T+sPpN6dI5q8P6ELrTYAABgebvr27auCggK9//77+sEPfqAZM2bo//7v/3z2/EuXLlVlZaXjdv78eZ89d6D1iemgMckxCrPZnI6H2WwakxxDlxQAADJBuGnTpo2SkpI0dOhQZWVlafDgwXrppZcaPbdr164qLS11OlZaWqquXbu6fP7w8HDHbKzrt2C2Oj1FaUnRTsfSkqK1Oj3FoIoAADAX061zU19fr9ra2kbvS01N1a5du7Ro0SLHsZ07d7oco2NFURGttX7OCBWX23Xmkp11bgAAuImh4Wbp0qWaPHmyevXqpc8++0wbNmzQnj17tGPHDklSRkaGevTooaysLEnSwoULNXbsWK1cuVJTpkzRxo0blZ+fr9/85jdG/hqGSIwm1AAA0BhDw83FixeVkZGhCxcuKCoqSoMGDdKOHTt0//33S5LOnTunVq2+7DkbPXq0NmzYoKeeekpPPvmkkpOTtXXrVg0YMMCoXwEAAJiM6da58bdgXucGAIBQFZTr3AAAAPgC4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFjKbUYXAFhJUVm1zlbUKKFLeyVGtze6HAAISYQbE+ICGXwu11zRgtwC5Z0ucxwbkxyj1ekpiopobWBlABB6CDcmwgUyeC3ILdC+wnKnY/sKyzU/96jWzxlhUFUAEJoYc2MiTV0gYV5FZdXKO12muoYGp+N1DQ3KO12m4nK7QZUBQGgi3JgEF8jgdbaipsn7z1zivQOAQCLcmAQXyODVu3NEk/cndGHcFAAEEuHGJLhABq8+MR00JjlGYTab0/Ewm01jkmMYFA4AAUa4MQkukMFtdXqK0pKinY6lJUVrdXqKQRUBQOiyNTTcNMjD4qqqqhQVFaXKykpFRkYaXY6Typqrmp97lNlSbjDrdPnicrvOXLIbWpdZXxsAaAlPrt+GhpusrCxt3rxZH3zwgdq1a6fRo0dr+fLl6tu3r8vH5OTkaNasWU7HwsPD9Y9//MOtn2nmcHOdGS6QZsV0edd4bQBYmSfXb0O7pfbu3avMzEy999572rlzp65evaoHHnhAdnvTg2cjIyN14cIFx+3s2bMBqti3isqqtfvUxVtmQiVGt9f4vrEEm0YwXd41XhsAuMbQRfzeeustp3/n5OQoNjZWhw8f1pgxY1w+zmazqWvXrv4uz2/4hu2d69Plb3bjdPlQDYS8NgDwJVMNKK6srJQkde7cucnzqqur1bt3b8XHx+vBBx/UiRMnAlGez/AN2ztMl3eN1wYAvmSacFNfX69FixYpLS1NAwYMcHle37599bvf/U7btm3Tf/3Xf6m+vl6jR4/WRx991Oj5tbW1qqqqcroZicX6vMd0edd4bQDgS6YJN5mZmTp+/Lg2btzY5HmpqanKyMjQkCFDNHbsWG3evFkxMTF65ZVXGj0/KytLUVFRjlt8fLw/yncb37C9x3R513htAOBLpgg38+bN0/bt27V792717NnTo8e2bt1aKSkpKiwsbPT+pUuXqrKy0nE7f/68L0r2Gt+wW4b1ZFzjtQGAawwdUNzQ0KD58+dry5Yt2rNnjxITEz1+jrq6Oh07dkxf/epXG70/PDxc4eHhLS3VZ65/w95XWO7UNRVmsyktKZpv2M2Iimit9XNGMF2+Ebw2AHCNoeEmMzNTGzZs0LZt29SxY0eVlJRIkqKiotSuXTtJUkZGhnr06KGsrCxJ0rPPPqtRo0YpKSlJly9f1osvvqizZ89q7ty5hv0enlqdnnLLYn18w/ZMYjQXbld4bQCEOkPDzdq1ayVJ48aNczqenZ2tmTNnSpLOnTunVq2+7D379NNP9eijj6qkpESdOnXS0KFDtX//fvXv3z9QZbcY37ABAPAftl8AAACmFzQrFAMAAPga4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFiKoVPB8aWismqdrahhWjgAAC1EuDHY5ZorWpBb4LSg35jkGK1OT1FURGsDKwMAIDjRLWWwBbkF2ldY7nRsX2G55uceNagiAACCG+HGQEVl1co7Xea0x5Qk1TU0KO90mYrL2SEcAABPEW4MdLaipsn7z1wi3AAA4CnCjYF6d45o8v6ELgwsBgDAU4QbA/WJ6aAxyTEKs9mcjofZbBqTHMOsKQAAvEC4Mdjq9BSlJUU7HUtLitbq9BSDKgIAILgxFdxgURGttX7OCBWX23Xmkp11bgAAaCHCjUkkRhNqAADwBbqlAACApRBuAACApdAthUax1xUAIFgRbuCEva4AAMGObik4Ya8rAECwI9zAgb2uAABWQLiBA3tdAQCsgHADB/a6AgBYAeEGDux1BQCwAsINnLDXFQAg2DEVHE7Y6woAEOwIN2gUe10BAIIV3VIAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSWKEYAACDFZVV62xFDVve+AjhBgAAg1yuuaIFuQXKO13mODYmOUar01MUFdHawMqCG91SAAAYZEFugfYVljsd21dYrvm5Rw2qyBoIN0GgqKxau09dVHG53ehSAAA+UlRWrbzTZapraHA6XtfQoLzTZXzmtwDdUj7my35TmisBwLrOVtQ0ef+ZS3bG33jJ0JabrKwsDR8+XB07dlRsbKymTZumU6dONfu4TZs26a677lLbtm01cOBAvfnmmwGotmmXa64o47WDum/lXs3KPqTxK/Yo47WDqqy56vVzmrG5MhCtSLRUAQgFvTtHNHl/QheCjbcMDTd79+5VZmam3nvvPe3cuVNXr17VAw88ILvd9UVt//79Sk9P15w5c3T06FFNmzZN06ZN0/HjxwNY+a18HUTM1lzpj/BmxM8AALPoE9NBY5JjFGazOR0Ps9k0JjmGVpsWsDU03HT1dKFTp06y3fQGuFJRUeFVMWVlZYqNjdXevXs1ZsyYRs+ZPn267Ha7tm/f7jg2atQoDRkyROvWrWv2Z1RVVSkqKkqVlZWKjIz0qs6bFZVV676Ve13ev3vJOI//SHefuqhZ2Ydc3p89a7jG94316DlbIuO1g9pXWO4UtsJsNqUlRWv9nBFB8zMAwEwqa65qfu5Rhh+4wZPrt9tjblatWuX470uXLum5557TxIkTlZqaKkk6cOCAduzYoZ/+9KfeVS2psrJSktS5c2eX5xw4cECLFy92OjZx4kRt3brV65/bUv7oNzVTc+X1VqSb3diK1NJvGIH4GQBgNlERrbV+zggVl9t15pKddW58xO1wM2PGDMd/P/zww3r22Wc1b948x7EFCxZozZo1euedd/SjH/3I40Lq6+u1aNEipaWlacCAAS7PKykpUVxcnNOxuLg4lZSUNHp+bW2tamtrHf+uqqryuLbm+COIXG+udNWSEcg//kAMemNgHYBQlhhNqPElr8bc7NixQ5MmTbrl+KRJk/TOO+94VUhmZqaOHz+ujRs3evV4V7KyshQVFeW4xcfH+/T5Jf/1m65OT1FaUrTTsbSkaK1OT/G6Vm8EohXJTC1VAIDg5lW46dKli7Zt23bL8W3btqlLly4eP9+8efO0fft27d69Wz179mzy3K5du6q0tNTpWGlpqbp27dro+UuXLlVlZaXjdv78eY/rc4c/gsj15srdS8Ype9Zw7V4yTuvnjAh4P2wgBr0xsA4A4CtuDyi+UU5OjubOnavJkydr5MiRkqT3339fb731ln77299q5syZbj1PQ0OD5s+fry1btmjPnj1KTk5u9jHTp09XTU2N3njjDcex0aNHa9CgQYYNKL6RVftNAzHojYF1AABXPLl+exVupGth5le/+pVOnjwpSerXr58WLFjgCDvu+OEPf6gNGzZo27Zt6tu3r+N4VFSU2rVrJ0nKyMhQjx49lJWVJenaVPCxY8fqhRde0JQpU7Rx40b9/Oc/15EjR5ocq3Odv8ON1QUivFk1IAIAvBeQcOMLrqaWZ2dnO1p/xo0bp4SEBOXk5Dju37Rpk5566imdOXNGycnJ+o//+A999atfdetnBjLcsMsrAAC+EZBw8+GHHyo7O1tFRUVatWqVYmNj9Ze//EW9evXS3Xff7VXhgRCIcMO2CQAA+JYn12+vBhTv3btXAwcO1Pvvv68//elPqq6uliT97//+r5555hlvntJSzLhtAgAAocKrcPPEE0/oueee086dO9WmTRvH8fvuu0/vvfeez4oLRmbbNgEAgFDjVbg5duyYvvGNb9xyPDY2VuXl5Y08InS4sxgdAADwH6/Cze23364LFy7ccvzo0aPq0aNHi4sKZixGBwCAsbwKN9/+9rf14x//WCUlJbLZbKqvr9e+ffu0ZMkSZWRk+LrGoMJidAAAGMurcPPzn/9cd911l+Lj41VdXa3+/ftrzJgxGj16tJ566ilf1xh0zLJtAgAAocjjqeANDQ06f/68YmJiVF5ermPHjqm6ulopKSlurTBstECuc8NidAAA+IYn12+3dwW/rqGhQUlJSTpx4oSSk5P9shGlVbDLKwAAgedxt1SrVq2UnJysS5cu+aMeAACAFvFqzM0LL7yg//f//p+OHz/u63oAAABaxKvtFzp16qSamhp98cUXatOmjWOTy+sqKip8VqCvsXEmAADBx69jbiRp1apV3jwMAADA77wKNzNmzPB1HQAAAD7hVbiRpLq6Om3ZskUnT56UJPXv318PPvigbrvN66cEAABoMa+SyIkTJ/T1r39dJSUl6tu3ryRp+fLliomJ0RtvvKEBAwb4tMhQVlRWrbMVNayVAwCAm7wKN3PnztXdd9+t/Px8derUSZL06aefaubMmfre976n/fv3+7TIUHS55ooW5BYo73SZ49iY5BitTk9RVERrAysDAMDcvJot1a5dO+Xn5+vuu+92On78+HENHz5cn3/+uc8K9LVgmS2V8dpB7SssV90Nb0+Yzaa0pGitnzPCwMoAAAg8T67fXq1zc+edd6q0tPSW4xcvXlRSUpI3T4kbFJVVK+90mVOwkaS6hgblnS5TcbndoMoAADA/r8JNVlaWFixYoD/+8Y/66KOP9NFHH+mPf/yjFi1apOXLl6uqqspxg+fOVtQ0ef+ZS4QbAABc8WrMzde+9jVJ0r/+67/KZrNJurbnlCRNnTrV8W+bzaa6ujpf1BlSeneOaPL+hC4MLAYAwBWvws3u3bt9XQdu0Cemg8Ykx7gcc8OsKQAILsx8DSyvws3YsWPdOu+HP/yh7r77bkVHR3vzY0La6vQUzc896jRbKi0pWqvTUwysCo3hQwuAK8x8NYZXs6XcFRkZqYKCAvXp08dfP8JjwTJb6rricrvOXLJz4TQhPrQANIeZr77j99lS7vJjbgoZidHtNb5vLMHGhBbkFmhfYbnTsX2F5Zqfe9SgigCYCTNfjePXcANYFR9aAJrDzFfjEG4AL/ChBaA5zHw1DuEG8AIfWgCac33ma9g/l0y5Lsxm05jkGIYb+BHhBvACH1oA3LE6PUVpSc4zhpn56n9eTQV313e/+92gmJEEeIPp+gCaExXRWuvnjGDma4B5NRU8ISFBs2fP1syZM9WrVy9/1OU3wTYVHObHhxYA+J/fp4IvWrRImzdvVp8+fXT//fdr48aNqq2t9apYINgFy3T9orJq7T51kZlcACyvRYv4HTlyRDk5OcrNzVVdXZ2+853vaPbs2brnnnt8WaNP0XKDUMNigwCswJPrt09WKL569ap+/etf68c//rGuXr2qgQMHasGCBZo1a5ZjY02zINwg1LBCKgArCNgKxVevXtUf/vAHff3rX9djjz2mYcOG6dVXX9XDDz+sJ598Uo888khLnh5AC7HYIIBQ5NVsqSNHjig7O1u5ublq1aqVMjIy9Mtf/lJ33XWX45xvfOMbGj58uM8KBeA5dxYbNPtYIQDwlFfhZvjw4br//vu1du1aTZs2Ta1b39pvn5iYqG9/+9stLhCA91hsEEAo8ircFBUVqXfv3k2e0759ez3wwAOy2+1q354PUMAI1xcbdDXmhlYbAFbk1Zib5oLNdf/+7/+u0tJSb34EAB9hhVQAocavKxT7YCIWgBZihVQAocav4QaAeSRGE2oAhAY2zgQAAJZiaLjJy8vT1KlT1b17d9lsNm3durXJ8/fs2SObzXbLraSkJDAFAwAA0zM03Njtdg0ePFgvv/yyR487deqULly44LjFxsb6qUIAABBs/Drmpnfv3o2ugXPd5MmTNXnyZI+fNzY2VrfffnsLKgMAAFbl15ab48ePKz4+3ufPO2TIEHXr1k3333+/9u3b1+S5tbW1qqqqcroBAADrcrvlplOnTm5vgllRUeF1QU3p1q2b1q1bp2HDhqm2tlavvvqqxo0bp/fff9/lTuRZWVlatmyZX+oBAADm4/au4L///e8d/33p0iU999xzmjhxolJTUyVJBw4c0I4dO/TTn/5UP/rRjzwvxGbTli1bNG3aNI8eN3bsWPXq1Uv/+Z//2ej9tbW1qq2tdfy7qqpK8fHx7AoOAEAQ8WRXcLdbbmbMmOH474cffljPPvus5s2b5zi2YMECrVmzRu+8845X4cZbI0aM0Lvvvuvy/vDwcIWHhwesHiMUlVXrbEVNyC/OxusAX+FvCQhuXg0o3rFjh5YvX37L8UmTJumJJ55ocVGeKCgoULdu3QL6M83ics0VLcgtUN7pMsexMckxWp2eoqgI1wO5rYbXAb7C3xJgDV4NKO7SpYu2bdt2y/Ft27apS5cubj9PdXW1CgoKVFBQIEkqLi5WQUGBzp07J0launSpMjIyHOevWrVK27ZtU2FhoY4fP65Fixbpr3/9qzIzM735NYLegtwC7Sssdzq2r7Bc83OPGlSRMXgd4Cv8LQHW4FXLzbJlyzR37lzt2bNHI0eOlCS9//77euutt/Tb3/7W7efJz8/X+PHjHf9evHixpGtdYDk5Obpw4YIj6EjSlStX9Nhjj+njjz9WRESEBg0apHfeecfpOYKBL5q8i8qqnb5dXlfX0KC802UqLreHRHM6rwN8hb8lwDq8CjczZ85Uv3799Ktf/UqbN2+WJPXr10/vvvuuI+y4Y9y4cU1urpmTk+P078cff1yPP/64NyWbgi+bvM9W1DR5/5lLofFBzOsAX+FvCbAOrxfxGzlypP77v//bl7VYXlNN3uvnjPDouXp3jmjy/oQuofEhzOsAX+FvCbAOt8fc3LwQXlM33Op6k3fdTS1VNzZ5e6JPTAeNSY5R2E1rD4XZbBqTHBMy3zB5HeArVvxbKiqr1u5TFz3+fAGCndstN7fffnuzi/g1NDTIZrOprq6uxYVZjT+avFenp2h+7lGnbq60pGitTk/xqsZgxesAX7HK3xKzvhDq3F7Eb+/evW4/6dixY70uyN88WQTIl4rKqnXfStev4e4l47z+ZlhcbteZS/aQX5OD1wG+Eux/SxmvHdS+wnKnluIwm01pSdEed4EDZuGXRfzMHFiCwfUmb1cfOC35AE2MDs4PYF/jdYCvBPPfktlnfbFAIgLB6wHFly9f1muvvaaTJ09Kku6++27Nnj1bUVFRPivOaszQ5M0HC2BtZp31RVcZAsntbqkb5efna+LEiWrXrp1GjLjWxHno0CF9/vnnevvtt11uYmkGRnVL3ciIJm8+WIDQ4M8u8Jagqwwt5cn126sVin/0ox/p61//us6cOaPNmzdr8+bNKi4u1te+9jUtWrTIm6cMKYnR7TW+b2xAP2BYeRUIDWac9eXr2aJAc7wKN/n5+frxj3+s2277slfrtttu0+OPP678/HyfFQff4IMFCC2r01OUlhTtdMzIWV/udJUBvuTVmJvIyEidO3dOd911l9Px8+fPq2PHjj4pDL5j1j54AP4RFdFa6+eMMM2sLxZIRKB51XIzffp0zZkzR6+//rrOnz+v8+fPa+PGjZo7d67S09N9XSNaiA8WIDQZ0QXeGDN2lcHa3G65+dvf/qYBAwaoVatWWrFihWw2mzIyMvTFF19Iklq3bq0f/OAHeuGFF/xWLLzjz2noAOAOM8wWRehwe7ZUWFiYLly4oNjYWPXp00eHDh1Su3bt9OGHH0qS7rjjDkVENN1CYAZmmC1lhMqaq7d8sDBbCkCgmaWrDMHHL4v43X777SouLlZsbKzOnDmj+vp6RUREaODAgS0uGP5ntj54AKEpmBdIRPBwO9w8/PDDGjt2rLp16yabzaZhw4YpLCys0XOLiop8ViB8iw8WAIDVuR1ufvOb3+ihhx5SYWGhFixYoEcffZSZUQAAwHQ8mgo+adIkSdLhw4e1cOFCwg0AADAdr9a5yc7O9nUdAAAAPuH1xploOTaxBADA9wg3BmATSwAA/MerFYrRMmxiCQCA/xBuAoxNLAEA8C/CTYCxOy4AAP5FuAkwNrEEAMC/CDcBxu64AAD4F+HGAKvTU5SWFO10jN1xAQDwDaaCG4BNLAEA8B/CjYH8uYklCwQCAEIV4cZiWCDQ+giuANA0wk0Qa+wi19QCgevnjDCiTPgIwRUA3EO4CUKuLnKPPZDsdOy6GxcI5Jt+8CK4AoB7CDdByNVFrqKmtsnHnblEuAlW11e2vhnBFQBuRbgJMk1d5I5/XNXkY1kgMLjc2O3ozsrWhBsAuIZwE2Sau8gN6B6pkxc+c9q7KsxmU1pSNBe/INFYt+Ow3p2afAzBFQC+xCJ+Qaa57Rt+/o2BLBAY5Brrdjx67rI6RbRmZWsAcAMtN0Hm+vYN+wrLG22dGRR/OwsEBrGmuh0/rbmq4QmddOjMp47jBFcAuBXhJgitTk/R/NyjThfBe3rfrn8d3tMxsNSfCwTCf5rrdvzh+CQldGlPcL0Ja/8AuBHhJgjduH3DiY8r9fv9Z3TozKeOb/SsfRK83Nk1nuD6Jdb+AdAYxtwEscTo9vpD/kc6cu6y0/Hra58g+LBrvGeaWvsHQOgi3ARQUVm1dp+6qOJyu8+eL+90mdPYG8l57RMEH3aNdw9//wBcoVsqAPzVdM7aJ9bErvHu4e8fgCuGttzk5eVp6tSp6t69u2w2m7Zu3drsY/bs2aN77rlH4eHhSkpKUk5Ojt/rbCl/NZ27Mz4DwSsxur3G943lAu0Cf/8AXDE03Njtdg0ePFgvv/yyW+cXFxdrypQpGj9+vAoKCrRo0SLNnTtXO3bs8HOl3vNn0znjMxDK+PsH4Iqh3VKTJ0/W5MmT3T5/3bp1SkxM1MqVKyVJ/fr107vvvqtf/vKXmjhxor/KbBFvms49mdba2LRwxmcgVPD3D6AxQTXm5sCBA5owYYLTsYkTJ2rRokUuH1NbW6va2i83lKyqanr/JV/zpOncm7E5jM9AKOPvH0Bjgmq2VElJieLi4pyOxcXFqaqqSp9//nmjj8nKylJUVJTjFh8fH4hSHTxpOm/J2BzGZyCU8fcP4EZBFW68sXTpUlVWVjpu58+fD3gN7kztbW5sTu7Bc0xtBQDADUHVLdW1a1eVlpY6HSstLVVkZKTatWvX6GPCw8MVHh4eiPJccqfpvLmxOUs3H5PE6qsAADQnqFpuUlNTtWvXLqdjO3fuVGpqqkEVNa6orFq5B8/e0trSVNN5c2NzrmP1VQAAmmZoy011dbUKCwsd/y4uLlZBQYE6d+6sXr16aenSpfr444+1fv16SdL3v/99rVmzRo8//rhmz56tv/71r/rDH/6gP//5z0b9Ck4u11zRD//7iPZ/eMnpeGqfLlr33aFNtra42u37ZjdOIWd8AQAAtzK05SY/P18pKSlKSbk29mTx4sVKSUnR008/LUm6cOGCzp075zg/MTFRf/7zn7Vz504NHjxYK1eu1KuvvmqaaeALcgtuCTaSdKDoklutLY2NzXHlzCXG3wAA0BhbQ0MTzQQWVFVVpaioKFVWVioyMtJnz1tUVq37Vu5t8pzdS8a51dpSXG7Xe0XlWrr5eIufCwAAK/Dk+h1UY27MrLkBwZL7rS2J0e2VPqI3q68CAOAFwo2PuDMg2NO9btgdGgAAzwXVVHAz6xPTQal9uuhA0a1jbiR51drC6qsAAHiOcONDN/UgOUS1a91ka0tze0klRhNqAABwF+HGR4rKqhudKSVJlZ9fVUXNlVumgnuzlxQAAGgaY258xJ3dv2/Wkr2kmlNUVq3dpy6yZQMAIOTQcuMjnuz+LX25l9TNWrpIH61BAIBQR8uNj/SJ6aBOLsJDp4jWHu8l5e0iff5qDaIlCAAQLGi58ZGismp9WnO10fs+rbl6S0uMpy097tbg69YgWoIAAMGGlhsf8bQl5vpeUr5cpM8frUH+HBcE36OFDQBoufEZb1piVqenaH7uUadWkZYs0ufr1iB/jQuC79HCBgBfItz4iKtdvcNsNqUlRTtCwM1r2vhykT53a3CXOy1BhBtzaKqFbf2cEQZVBQDGINz4UFMtMU19s/blIn2+bA3yx7gg+B4tbADgjHDjQ01tl5Dx2sGAfLP25ZYNvm4Jgn/QwgYAzhhQ7AeJ0e01vm+sU1dU3ukyp4AgOX+z9ncN3mLzTvOjhQ0AnNFyEwDB/M2azTvNjxY2AHBGy00AWOGbta9aguAftLABwJdouQkAvlnD32hhA4Av0XITIHyzRiDQwgYAtNwEDN+sAQAIDMKND928QF9jbl7Txp3HAAAA9xFufMCbpe9ZLh8AAP9gzI0PeLO5pFk2pGSjRQCA1dBy00LeLH1vhuXyaTkCAFgVLTct5M4Cfb54jK+ZpeUIAABfI9y0kDcL9Bm9qJ8R20EAABAohJsWur5AX5jN5nQ8zGbTmOSYRruXvHmML5mh5QgAAH8h3PiANwv0Gbmon9EtRwAA+BMDin3AmwX6jFzUj+0gAABWZmtouGnghcVVVVUpKipKlZWVioyMNLocw1TWXNX83KPMlgoSLPYIINR5cv2m5SZEsR1EcGDKPgB4jjE3IY6NFs2NKfsA4DnCDWBSTNkHAO8QbgCTYso+AHiHcAOYFFP2AcA7hBvApIxe7BEAghXhBjAxIxd7BIBgxVRwg7F+CZrClH0A8BzhxgBFZdX6v0+q9Erehzr2cZXjOOuXwJXEaEINALiLcBNAjS3IdqN9hWWan3tU6+eMCHBlAABYhynG3Lz88stKSEhQ27ZtNXLkSB08eNDluTk5ObLZbE63tm3bBrBa7zW2INuN6hrE+iUAALSQ4eHm9ddf1+LFi/XMM8/oyJEjGjx4sCZOnKiLFy+6fExkZKQuXLjguJ09ezaAFXuuqKxauQfPNbogW2NYvwQAAO8Z3i31i1/8Qo8++qhmzZolSVq3bp3+/Oc/63e/+52eeOKJRh9js9nUtWvXQJbplea6oVxh/RIAALxnaMvNlStXdPjwYU2YMMFxrFWrVpowYYIOHDjg8nHV1dXq3bu34uPj9eCDD+rEiROBKNdjzXVDNWZ4QqeADxwtKqvW7lMX6Q4DAFiCoS035eXlqqurU1xcnNPxuLg4ffDBB40+pm/fvvrd736nQYMGqbKyUitWrNDo0aN14sQJ9ezZ85bza2trVVtb6/h3VVXVLef4w/V9gTzRKaK1Xs0Y7qeKbsWO0wAAKzJ8zI2nUlNTlZGRoSFDhmjs2LHavHmzYmJi9MorrzR6flZWlqKiohy3+Pj4gNTZ3L5ANxveu5P2LBkf0FDBjtMAACsytOUmOjpaYWFhKi0tdTpeWlrq9pia1q1bKyUlRYWFhY3ev3TpUi1evNjx76qqqoAEnOb2BXrhoYHq0amdvqhvMGRhNlctSzfuOM26KgCAYGRoy02bNm00dOhQ7dq1y3Gsvr5eu3btUmpqqlvPUVdXp2PHjqlbt26N3h8eHq7IyEinWyA0ty/Qt0f00r3JMRrfN9aQEBEsO04zHggA4CnDZ0stXrxYM2bM0LBhwzRixAitWrVKdrvdMXsqIyNDPXr0UFZWliTp2Wef1ahRo5SUlKTLly/rxRdf1NmzZzV37lwjf41GrU5P0fzco04tJGbZF8jsO04zHggA4C3Dw8306dNVVlamp59+WiUlJRoyZIjeeustxyDjc+fOqVWrLxuYPv30Uz366KMqKSlRp06dNHToUO3fv1/9+/c36ldwycz7Al1vWdpXWO609k6Yzaa0pGjD62xqPBArOAMAmmJraHBjVTkLqaqqUlRUlCorKwPWRWVWlTVXb2lZMkPrSFFZte5budfl/buXjDM8fAEAAsuT67fhLTcwjllbltwZD5QY3Z4d1QEAjSLcwHQ7Tjc3HqhzRGtlvHbQdC1OAABzCLp1bmB9zc00W/n2adbnAQC4RLiBKa1OT1FaUrTTsbSkaD32QHKjG5DeuD4PACC00S0FU3I1Hmj3Kde7xUtfjscBAIQuwg1M7ebxQGZfnwcAYDy6pRBUmhuPQ6sNAIBwg6DjajyOGVZ+BgAYj24pBB2zrs8DADAHwg2CltnW5wEAmAPdUgAAwFIINwAAwFIINwAAwFIINwAAwFIYUOxH7FoNAEDgEW784HLNFS3ILTDdrtWELevgvQQA1wg3frAgt8DlrtXr54wIeD1mDVvwHO8lADSPMTc+VlRWbbpdq5sKWwguvJcA0DzCjY+drahp8v4zlwIbbswYtuAd3ksAwaCorFq7T1009DOJbikfM9uu1e6ELcZsBAfeSwBmZqZuc1pufKxz+zbq1MibGGaTIbtWmy1swXu8l4D/maHVIViZqduclhsfW5BboMqaq7ccj2zX2pBdq/vEdNCY5BjtKyx36s4Is9mUlhTNN/0gwnsJ+I+ZWh2C0fVu85vd2G0eyM8oWm586PqbW9/IfZ/WXFVFzZWA1yRJq9NTlJYU7XQsLSnakLCFluG9BPzDTK0Owchs401pufEhs46JiIporfVzRqi43K4zl+ysjRLEeC8B3zNbq0MwMlu3OeHGh8z25t4sMZoLoVXwXgK+Y9YvpsHEbN3mdEv50PU3N8xmczoeZrMZMpgYANA8s38xDRZm6jan5cbHVqenaH7uUacmTsZEAIB5ma3VIViZqdvc1tBw04pgFldVVaWoqChVVlYqMjLSbz/HDG8uAMA9lTVXb/liymwpc/Hk+k24AQDgn/hial6eXL/plgoi7AQNAP7FYH1rINwEARaXAgDAfcyWCgIsLgUAgPsINwZxd/8SdoIGAMAzdEsFmKddTCwuBQCAZ2i58bHmWmQ87WJicSkAADxDy42PuNMi483+JSwuBQCAZ2i58RF3WmS83TXVTEtaAwBgdrTc+IC7LTLNJUlXXUxmWtIaAACzI9z4QHMtMic+rtQz2040GoAk97uYWFwKAIDmEW58oLlBv7/ff0ZHzl12eT9dTAAA+A7hxgeaGvR7T+/bdejMpy4f+59zRuje5JhAlAkAQEgwxYDil19+WQkJCWrbtq1GjhypgwcPNnn+pk2bdNddd6lt27YaOHCg3nzzzQBV6pqrQb8zRic0+bgv6kNq31IAAPzO8Jab119/XYsXL9a6des0cuRIrVq1ShMnTtSpU6cUGxt7y/n79+9Xenq6srKy9LWvfU0bNmzQtGnTdOTIEQ0YMMCA3+AaV4N+i8qqm3wc69QAAOBbtoaGBkObDkaOHKnhw4drzZo1kqT6+nrFx8dr/vz5euKJJ245f/r06bLb7dq+fbvj2KhRozRkyBCtW7eu2Z/nyZbpvpLx2kGX69SsnzMiIDUAABDMPLl+G9otdeXKFR0+fFgTJkxwHGvVqpUmTJigAwcONPqYAwcOOJ0vSRMnTnR5fm1traqqqpxugcY6NQAABI6h3VLl5eWqq6tTXFyc0/G4uDh98MEHjT6mpKSk0fNLSkoaPT8rK0vLli3zTcFeYp0aAAACxxQDiv1p6dKlqqysdNzOnz9vWC2J0e01vm8swQYAAD8ytOUmOjpaYWFhKi0tdTpeWlqqrl27NvqYrl27enR+eHi4wsPDfVMwAAAwPUNbbtq0aaOhQ4dq165djmP19fXatWuXUlNTG31Mamqq0/mStHPnTpfnAwCA0GL4VPDFixdrxowZGjZsmEaMGKFVq1bJbrdr1qxZkqSMjAz16NFDWVlZkqSFCxdq7NixWrlypaZMmaKNGzcqPz9fv/nNb4z8NQAAgEkYHm6mT5+usrIyPf300yopKdGQIUP01ltvOQYNnzt3Tq1afdnANHr0aG3YsEFPPfWUnnzySSUnJ2vr1q2GrnEDAADMw/B1bgLNiHVuAABAywTNOjcAAAC+RrgBAACWQrgBAACWQrgBAACWQrgBAACWYvhU8EC7PjnMiA00AQCAd65ft92Z5B1y4eazzz6TJMXHxxtcCQAA8NRnn32mqKioJs8JuXVu6uvr9cknn6hjx46y2Ww+e96qqirFx8fr/PnzrJ9jMrw35sV7Y168N+YVqu9NQ0ODPvvsM3Xv3t1pcd/GhFzLTatWrdSzZ0+/PX9kZGRI/bEFE94b8+K9MS/eG/MKxfemuRab6xhQDAAALIVwAwAALIVw4yPh4eF65plnFB4ebnQpuAnvjXnx3pgX74158d40L+QGFAMAAGuj5QYAAFgK4QYAAFgK4QYAAFgK4cZHXn75ZSUkJKht27YaOXKkDh48aHRJIS8vL09Tp05V9+7dZbPZtHXrVqNLgqSsrCwNHz5cHTt2VGxsrKZNm6ZTp04ZXRYkrV27VoMGDXKsn5Kamqq//OUvRpeFRrzwwguy2WxatGiR0aWYEuHGB15//XUtXrxYzzzzjI4cOaLBgwdr4sSJunjxotGlhTS73a7Bgwfr5ZdfNroU3GDv3r3KzMzUe++9p507d+rq1at64IEHZLfbjS4t5PXs2VMvvPCCDh8+rPz8fN1333168MEHdeLECaNLww0OHTqkV155RYMGDTK6FNNitpQPjBw5UsOHD9eaNWskXdviIT4+XvPnz9cTTzxhcHWQJJvNpi1btmjatGlGl4KblJWVKTY2Vnv37tWYMWOMLgc36dy5s1588UXNmTPH6FIgqbq6Wvfcc49+/etf67nnntOQIUO0atUqo8syHVpuWujKlSs6fPiwJkyY4DjWqlUrTZgwQQcOHDCwMiA4VFZWSrp2EYV51NXVaePGjbLb7UpNTTW6HPxTZmampkyZ4nTNwa1Cbm8pXysvL1ddXZ3i4uKcjsfFxemDDz4wqCogONTX12vRokVKS0vTgAEDjC4Hko4dO6bU1FT94x//UIcOHbRlyxb179/f6LIgaePGjTpy5IgOHTpkdCmmR7gBYJjMzEwdP35c7777rtGl4J/69u2rgoICVVZW6o9//KNmzJihvXv3EnAMdv78eS1cuFA7d+5U27ZtjS7H9Ag3LRQdHa2wsDCVlpY6HS8tLVXXrl0Nqgowv3nz5mn79u3Ky8tTz549jS4H/9SmTRslJSVJkoYOHapDhw7ppZde0iuvvGJwZaHt8OHDunjxou655x7Hsbq6OuXl5WnNmjWqra1VWFiYgRWaC2NuWqhNmzYaOnSodu3a5ThWX1+vXbt20U8NNKKhoUHz5s3Tli1b9Ne//lWJiYlGl4Qm1NfXq7a21ugyQt6//Mu/6NixYyooKHDchg0bpkceeUQFBQUEm5vQcuMDixcv1owZMzRs2DCNGDFCq1atkt1u16xZs4wuLaRVV1ersLDQ8e/i4mIVFBSoc+fO6tWrl4GVhbbMzExt2LBB27ZtU8eOHVVSUiJJioqKUrt27QyuLrQtXbpUkydPVq9evfTZZ59pw4YN2rNnj3bs2GF0aSGvY8eOt4xLa9++vbp06cJ4tUYQbnxg+vTpKisr09NPP62SkhINGTJEb7311i2DjBFY+fn5Gj9+vOPfixcvliTNmDFDOTk5BlWFtWvXSpLGjRvndDw7O1szZ84MfEFwuHjxojIyMnThwgVFRUVp0KBB2rFjh+6//36jSwM8wjo3AADAUhhzAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAyAk/OxnP1NcXJxsNpu2bt2qmTNnatq0aUaXBVhKXl6epk6dqu7duzv+X/NUQ0ODVqxYoTvvvFPh4eHq0aOHnn/+eY+eg+0XAJjKzJkz9fvf/16S1Lp1a/Xq1UsZGRl68sknddtt3n1knTx5UsuWLdOWLVs0atQoderUSePHj9eNC7SPGzdOQ4YM0apVq3zxawAhyW63a/DgwZo9e7Yeeughr55j4cKFevvtt7VixQoNHDhQFRUVqqio8Og5CDcATGfSpEnKzs5WbW2t3nzzTWVmZqp169ZaunSp03lXrlxRmzZtmn2+Dz/8UJL04IMPymazSZLCw8N9XzgQ4iZPnqzJkye7vL+2tlY/+clPlJubq8uXL2vAgAFavny5Y6+5kydPau3atTp+/Lj69u0rSUpMTPS4DrqlAJhOeHi4unbtqt69e+sHP/iBJkyYoP/5n/9xdCU9//zz6t69u+PD79ixY7rvvvvUrl07denSRd/73vdUXV0t6Vp31NSpUyVJrVq1coSbG7ulZs6cqb179+qll16SzWaTzWbTmTNnAv57A1Y3b948HThwQBs3btTf/vY3fetb39KkSZN0+vRpSdIbb7yhPn36aPv27UpMTFRCQoLmzp3rccsN4QaA6bVr105XrlyRJO3atUunTp3Szp07tX37dtntdk2cOFGdOnXSoUOHtGnTJr3zzjuaN2+eJGnJkiXKzs6WJF24cEEXLly45flfeuklpaam6tFHH3WcEx8fH7hfEAgB586dU3Z2tjZt2qR7771Xd9xxh5YsWaKvfOUrjv9Hi4qKdPbsWW3atEnr169XTk6ODh8+rG9+85se/Sy6pQCYVkNDg3bt2qUdO3Zo/vz5KisrU/v27fXqq686uqN++9vf6h//+IfWr1+v9u3bS5LWrFmjqVOnavny5YqLi9Ptt98uSeratWujPycqKkpt2rRRRESEy3MAtMyxY8dUV1enO++80+l4bW2tunTpIkmqr69XbW2t1q9f7zjvtdde09ChQ3Xq1ClHa21zCDcATGf79u3q0KGDrl69qvr6en3nO9/Rz372M2VmZmrgwIFO42xOnjypwYMHO4KNJKWlpam+vl6nTp1SXFycEb8CgJtUV1crLCxMhw8fVlhYmNN9HTp0kCR169ZNt912m1MA6tevn6RrLT+EGwBBa/z48Vq7dq3atGmj7t27O82SujHEAAgeKSkpqqur08WLF3Xvvfc2ek5aWpq++OILffjhh7rjjjskSX//+98lSb1793b7ZxFuAJhO+/btlZSU5Na5/fr1U05Ojux2uyP47Nu3T61atXL7W54ktWnTRnV1dV7VC+Ca6upqFRYWOv5dXFysgoICde7cWXfeeaceeeQRZWRkaOXKlUpJSVFZWZl27dqlQYMGacqUKZowYYLuuecezZ49W6tWrVJ9fb0yMzN1//3339Kd1RQGFAMIao888ojatm2rGTNm6Pjx49q9e7fmz5+vf/u3f/OoSyohIUHvv/++zpw5o/LyctXX1/uxasCa8vPzlZKSopSUFEnS4sWLlZKSoqefflqSlJ2drYyMDD322GPq27evpk2bpkOHDqlXr16Srs1ofOONNxQdHa0xY8ZoypQp6tevnzZu3OhRHbTcAAhqERER2rFjhxYuXKjhw4crIiJCDz/8sH7xi1949DxLlizRjBkz1L9/f33++ecqLi5WQkKCf4oGLGrcuHFOi2PerHXr1lq2bJmWLVvm8pzu3bvrT3/6U4vqsDU0VQUAAECQoVsKAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYyv8HVPo1URgM7LcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "data_input [(data_input [fold_y_pred] < data_input [Target].max() ) *\n",
        "            (data_input [fold_y_pred] > data_input [Target].min() )\n",
        "             ].plot.scatter (Target , fold_y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egF30KZEd7Zy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2881a6c5-511b-478b-998b-915928bdf077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 0:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[23]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0786787        9         0.384138         0.327777      9.73s\n",
            "   1    10.40         0.136417       10         0.434083         0.231872      6.39s\n",
            "   2    12.28         0.174279       23         0.546031         0.496764      6.04s\n",
            "   3    13.30         0.208592       21         0.547842         0.212448      5.10s\n",
            "   4    18.93         0.251372       24         0.567782         0.297578      4.78s\n",
            "   5    25.54         0.293377       58          0.61374         0.266647      4.35s\n",
            "   6    25.81         0.319344       19         0.617959        0.0480094      3.07s\n",
            "   7    28.41         0.317807       38         0.587645         0.334043      2.02s\n",
            "   8    28.89         0.320128       46         0.594371         0.112834      1.00s\n",
            "   9    31.62         0.337091       20         0.612324          0.24012      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([23]), 'fold_y_g_pred': array([7646031.06147995]), 'fold_num': 0}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 1:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[9]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0795725        9         0.397452         0.361442      6.27s\n",
            "   1    10.46         0.136594       10         0.430624         0.154102      8.02s\n",
            "   2    12.18          0.17464       41         0.522127        0.0301651      9.99s\n",
            "   3    14.24         0.208335       14         0.545562         0.305039      7.81s\n",
            "   4    24.69           0.2865       24          0.60343         0.198192      4.81s\n",
            "   5    30.11         0.331353       58         0.608317         0.248953      4.52s\n",
            "   6    33.51         0.345425       19         0.603451         0.334674      3.05s\n",
            "   7    35.98         0.338014       32         0.624575        0.0328462      2.10s\n",
            "   8    35.34         0.350968       27         0.612759         0.200553      1.03s\n",
            "   9    33.67         0.356547       33         0.647762        0.0217996      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([9]), 'fold_y_g_pred': array([-1420789.85759461]), 'fold_num': 1}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 2:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[75]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0806231       10         0.394254         0.491111      6.02s\n",
            "   1     9.47         0.138956       15         0.476484         0.170894      6.11s\n",
            "   2    10.82         0.175574       23         0.545593         0.402896      5.68s\n",
            "   3    13.90         0.200546       23         0.541453         0.141975      5.07s\n",
            "   4    17.59         0.216951       48         0.601718          0.14334      6.55s\n",
            "   5    20.91         0.261714       18         0.579891        0.0135152      7.27s\n",
            "   6    21.96         0.289959       50         0.641823         0.562457      3.16s\n",
            "   7    23.95         0.319864       50         0.635318         0.118828      2.00s\n",
            "   8    28.94         0.336247       58         0.629772         0.227294      1.04s\n",
            "   9    33.41         0.360674       49         0.648311        0.0546478      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([75]), 'fold_y_g_pred': array([645176.60301864]), 'fold_num': 2}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 3:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[84]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0798043       10         0.377888         0.491111      6.28s\n",
            "   1     9.83         0.133693       11         0.503553                0      5.97s\n",
            "   2    11.60         0.171891       11         0.529095                0      5.72s\n",
            "   3    13.36          0.20922       28         0.582646         0.101076      5.33s\n",
            "   4    17.74         0.239028       25         0.571481         0.775263      4.48s\n",
            "   5    21.43         0.284046       19         0.592444         0.543421      4.23s\n",
            "   6    22.28         0.289379       21         0.612543         0.540322      3.17s\n",
            "   7    24.93         0.327683       21         0.659357         0.209419      3.57s\n",
            "   8    29.15         0.358536       23         0.684722         0.274896      1.37s\n",
            "   9    33.39          0.39074       45         0.649198         0.362727      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([84]), 'fold_y_g_pred': array([-1212799.32905894]), 'fold_num': 3}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 4:\n",
            "  Train: index=[  0   1   2   3   4   5   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[6]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0793304        9         0.396435         0.355568      6.51s\n",
            "   1    10.39         0.135345       10         0.430386         0.154102      6.12s\n",
            "   2    11.52          0.16746       41         0.518802        0.0301651      5.89s\n",
            "   3    12.60         0.201096       31         0.537842         0.163472      5.18s\n",
            "   4    23.13         0.265833       28         0.579789         0.111476      4.63s\n",
            "   5    31.65         0.326651       15         0.588272        0.0494695      4.55s\n",
            "   6    34.23         0.344761       17         0.627209         0.182058      3.07s\n",
            "   7    36.33         0.355552       54          0.59586         0.255385      2.01s\n",
            "   8    34.81         0.363231       16         0.605418        0.0813519      1.15s\n",
            "   9    29.35         0.376571       21         0.640029         0.176379      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([6]), 'fold_y_g_pred': array([21637108.96577509]), 'fold_num': 4}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 5:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[46]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0782096        9         0.382875         0.405774      9.12s\n",
            "   1    10.41          0.13801       11         0.525541                0      6.76s\n",
            "   2    12.52         0.165824       23         0.518072         0.398747      5.83s\n",
            "   3    11.98         0.207138       12         0.546122         0.335135      4.97s\n",
            "   4    15.63         0.235447       27         0.593737         0.832523      4.37s\n",
            "   5    18.07         0.256555       46         0.601051        0.0533233      3.62s\n",
            "   6    21.49         0.310443       27         0.620367         0.066865      3.15s\n",
            "   7    24.66         0.342995       40         0.644384         0.534359      1.91s\n",
            "   8    29.84         0.376713       26         0.682129         0.192168      1.01s\n",
            "   9    34.34         0.404197       27         0.673525        0.0432625      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([46]), 'fold_y_g_pred': array([4343252.67786603]), 'fold_num': 5}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 6:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[35]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0785503        9          0.38115         0.405774      6.43s\n",
            "   1    10.40         0.136689       10         0.437427         0.231872      7.57s\n",
            "   2    12.25          0.16674       23         0.520258         0.413526      9.79s\n",
            "   3    13.38          0.20938       21         0.541866         0.212448      8.12s\n",
            "   4    17.95         0.256729       24         0.567341         0.297578      4.46s\n",
            "   5    22.12         0.299609       40         0.626929         0.198993      3.70s\n",
            "   6    23.63         0.309763       19         0.618495         0.175009      3.24s\n",
            "   7    25.01         0.318518       31         0.602065        0.0634663      1.96s\n",
            "   8    27.52         0.323012       22         0.617661         0.187573      0.98s\n",
            "   9    28.35         0.321004       27          0.58365         0.143547      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([35]), 'fold_y_g_pred': array([9316937.48240225]), 'fold_num': 6}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 7:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[82]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57         0.079072       10         0.380706         0.491111      6.26s\n",
            "   1     9.58         0.133332       11         0.504069                0      6.27s\n",
            "   2    11.57         0.170814       11         0.529583                0      5.68s\n",
            "   3    13.10         0.205121       17         0.571922        0.0507675      5.08s\n",
            "   4    17.95         0.244505       37         0.568883         0.206345      4.75s\n",
            "   5    21.33         0.273241       12         0.577549                0      6.33s\n",
            "   6    23.41         0.274133       41         0.564083         0.143399      4.77s\n",
            "   7    24.92         0.309641       41         0.599422         0.324314      1.93s\n",
            "   8    28.22         0.307557       24         0.598303         0.237716      1.02s\n",
            "   9    30.27         0.329123       33         0.620184         0.038564      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([82]), 'fold_y_g_pred': array([-9808413.62805395]), 'fold_num': 7}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 8:\n",
            "  Train: index=[  0   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[1]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0798322        9         0.395724          0.32128      6.23s\n",
            "   1    10.75         0.136743       10         0.438736          0.10173      6.18s\n",
            "   2    11.77         0.172877       41         0.521009        0.0301651      5.61s\n",
            "   3    13.46         0.205894       17         0.547804           0.2722      4.97s\n",
            "   4    22.00          0.26033       15         0.578541         0.129683      4.55s\n",
            "   5    27.70         0.291919       15         0.586793        0.0494695      3.81s\n",
            "   6    29.99         0.312155       20         0.631786         0.219573      2.92s\n",
            "   7    29.07          0.32908       26          0.64598         0.426242      2.66s\n",
            "   8    27.07         0.344593       55         0.633219         0.166055      1.70s\n",
            "   9    28.20         0.391169       27         0.662881         0.258932      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([1]), 'fold_y_g_pred': array([-1011282.07810442]), 'fold_num': 8}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 9:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[104]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0736268       10         0.379148         0.144158      6.51s\n",
            "   1     9.61         0.126147       13         0.415288         0.635612      6.19s\n",
            "   2    10.55         0.158625       41         0.450851         0.138546      5.64s\n",
            "   3    13.27          0.18105       41         0.509038         0.243588      5.06s\n",
            "   4    21.91         0.235622       46         0.560126         0.261081      4.60s\n",
            "   5    38.04          0.31155       49          0.56227         0.115208      4.09s\n",
            "   6    42.20         0.344233       56         0.559557        0.0327594      3.21s\n",
            "   7    41.29         0.343195       47         0.564747         0.315261      2.09s\n",
            "   8    38.00         0.325785       56         0.568671         0.271989      1.18s\n",
            "   9    37.24         0.332738       32         0.604868       0.00509522      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([104]), 'fold_y_g_pred': array([86537746.01487601]), 'fold_num': 9}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 10:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[96]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0799545       10         0.376119         0.505757     10.66s\n",
            "   1     9.41         0.135572       11         0.500477                0      9.70s\n",
            "   2    11.17         0.168867       11         0.528373                0      6.02s\n",
            "   3    13.33         0.204214       30         0.547866         0.376042      4.97s\n",
            "   4    17.82         0.230182       11         0.598781                0      4.53s\n",
            "   5    23.17         0.275164       24         0.582643         0.162326      3.77s\n",
            "   6    27.17         0.310745       37         0.587499         0.662012      3.08s\n",
            "   7    31.14         0.347427       39         0.595353         0.219282      2.05s\n",
            "   8    33.66         0.366559       49         0.602475         0.339181      1.06s\n",
            "   9    36.49         0.373999       49         0.603348       0.00262935      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([96]), 'fold_y_g_pred': array([786927.32288514]), 'fold_num': 10}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 11:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[101]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0819339        5         0.379364      0.000343733      6.39s\n",
            "   1     9.52         0.141752       11         0.499142                0      6.12s\n",
            "   2    10.81         0.187731       11         0.528527                0      6.24s\n",
            "   3    13.36          0.24182       26         0.549367         0.275251      8.49s\n",
            "   4    18.15         0.282548       11         0.599053                0      6.71s\n",
            "   5    24.38         0.333228       55         0.569329        0.0900864      3.57s\n",
            "   6    30.37         0.393373       35         0.617927         0.247216      2.67s\n",
            "   7    29.24         0.408702       24         0.588536         0.174297      1.77s\n",
            "   8    32.84         0.428383       61         0.613139         0.371935      0.90s\n",
            "   9    33.26         0.440886       38         0.617733        0.0818475      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([101]), 'fold_y_g_pred': array([5.92482549e+11]), 'fold_num': 11}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 12:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[30]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57         0.078667        9         0.386825         0.500021      6.25s\n",
            "   1    10.24         0.135857       10         0.437149         0.231872      6.16s\n",
            "   2    12.16         0.168078       23         0.546233         0.496764      5.83s\n",
            "   3    12.53         0.202228       21            0.542         0.212448      4.95s\n",
            "   4    16.93         0.232848       21         0.560803        0.0752557      4.66s\n",
            "   5    22.73         0.267454       19         0.575092         0.115143      3.90s\n",
            "   6    26.63         0.305173       24         0.590946        0.0216902      4.37s\n",
            "   7    29.20         0.318012       30         0.577474         0.200885      3.26s\n",
            "   8    32.10         0.325186       35         0.590125         0.301957      1.18s\n",
            "   9    32.13         0.328269       19         0.598274         0.425262      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([30]), 'fold_y_g_pred': array([-6275933.28633496]), 'fold_num': 12}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 13:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[21]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0790847        9         0.382867         0.327777      7.57s\n",
            "   1    10.34         0.136197       10         0.432594         0.231872      5.97s\n",
            "   2    11.83         0.174166       23         0.540961         0.496764      5.60s\n",
            "   3    14.32         0.212339       45         0.553347       0.00341104      5.23s\n",
            "   4    22.98         0.265899       23         0.581199         0.178533      4.72s\n",
            "   5    30.93         0.309888       51         0.576685         0.289799      3.94s\n",
            "   6    35.14          0.32783       51         0.602998         0.248527      3.03s\n",
            "   7    38.48         0.351374       46         0.589289          0.13295      2.09s\n",
            "   8    42.65         0.374915       39         0.624677         0.289971      1.31s\n",
            "   9    44.67         0.364197       74         0.649733         0.300519      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([21]), 'fold_y_g_pred': array([-17982343.94664379]), 'fold_num': 13}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 14:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[107]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0786911       10         0.429413         0.129434      6.45s\n",
            "   1     9.61         0.134369       10         0.433707         0.308052      6.16s\n",
            "   2    10.81         0.164242       24         0.512167        0.0525636      5.85s\n",
            "   3    13.04         0.199755       12         0.598552        0.0626117      4.92s\n",
            "   4    17.27         0.225808       12         0.579575         0.174202      4.45s\n",
            "   5    21.31         0.256558       12         0.603574         0.213898      3.71s\n",
            "   6    22.01         0.280981       12         0.602598         0.168629      2.72s\n",
            "   7    19.59         0.287512       17         0.626682        0.0957499      1.85s\n",
            "   8    16.66         0.274348       27         0.642657         0.110837      0.85s\n",
            "   9    16.94         0.292602       12         0.620663         0.269191      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([107]), 'fold_y_g_pred': array([1391400.11374371]), 'fold_num': 14}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 15:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[26]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0781788        9         0.382019         0.327777      6.07s\n",
            "   1    10.36         0.134583       10         0.429242         0.231872      7.20s\n",
            "   2    12.12          0.16878       23         0.540726         0.496764     11.35s\n",
            "   3    13.90         0.214628       23         0.529511        0.0165504      7.34s\n",
            "   4    22.48         0.261754       24         0.568292         0.297578      4.62s\n",
            "   5    30.02         0.314546       58         0.612032         0.266647      3.86s\n",
            "   6    33.44         0.342753       49         0.597633         0.188848      2.97s\n",
            "   7    36.45         0.334355       26         0.580412        0.0443875      2.06s\n",
            "   8    40.54          0.36308       18         0.605177          0.08071      1.03s\n",
            "   9    41.00         0.364848       23         0.615943          0.12734      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([26]), 'fold_y_g_pred': array([2293532.16725438]), 'fold_num': 15}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 16:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[51]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0784275        9          0.38381         0.405774      6.38s\n",
            "   1    10.35         0.136868       10         0.442966         0.291252      7.32s\n",
            "   2    12.26          0.16819       23          0.51906         0.398747      5.68s\n",
            "   3    13.83         0.208128       20         0.536214         0.294238      5.15s\n",
            "   4    23.38         0.272181       24         0.570084         0.296647      6.08s\n",
            "   5    30.26         0.319055       66         0.602049         0.328761      6.51s\n",
            "   6    35.02         0.353493       69         0.607532         0.189879      3.86s\n",
            "   7    34.74         0.350286       27          0.62591        0.0949781      2.02s\n",
            "   8    35.82         0.367355       41         0.613362         0.121102      1.04s\n",
            "   9    35.54         0.380727       45         0.648797        0.0510097      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([51]), 'fold_y_g_pred': array([47342357.26220743]), 'fold_num': 16}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 17:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[87]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0806747       10         0.383068         0.492919      6.34s\n",
            "   1     9.51         0.136883       11          0.50071                0      6.04s\n",
            "   2    11.23         0.173056       19         0.530265         0.262267      6.47s\n",
            "   3    14.17         0.212508       30         0.580666         0.424131      5.08s\n",
            "   4    21.60         0.241632       12          0.56912         0.164888      4.65s\n",
            "   5    25.95         0.284749       15         0.587603                0      3.86s\n",
            "   6    30.08         0.317343       53         0.595443         0.283379      3.06s\n",
            "   7    32.45         0.343944       53         0.595912         0.192296      3.50s\n",
            "   8    34.70         0.360286       37         0.625121         0.359744      1.66s\n",
            "   9    34.71         0.366646       32         0.639352         0.525131      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([87]), 'fold_y_g_pred': array([-808329.88096597]), 'fold_num': 17}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 18:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[44]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0776561        9         0.382729         0.405774      6.19s\n",
            "   1    10.36         0.136333       11         0.525633                0      6.36s\n",
            "   2    12.35         0.164787       23         0.518451         0.398747      6.64s\n",
            "   3    12.40         0.208172       12         0.544057         0.335135      4.93s\n",
            "   4    16.45         0.241236       27          0.59303         0.837707      4.36s\n",
            "   5    18.46          0.26151       23           0.5736         0.279251      3.60s\n",
            "   6    20.41         0.295785       27         0.620216         0.066865      2.90s\n",
            "   7    23.92         0.338058       21         0.645661        0.0911248      1.88s\n",
            "   8    29.98         0.379868       31          0.64571         0.140923      1.01s\n",
            "   9    32.55         0.391284       35         0.671564        0.0171857      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([44]), 'fold_y_g_pred': array([1952474.05797646]), 'fold_num': 18}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 19:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[43]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0781275        9         0.382676         0.405774     10.29s\n",
            "   1    10.36         0.138406       11         0.525478                0      9.81s\n",
            "   2    12.25         0.165014       23         0.518036         0.398747      6.90s\n",
            "   3    12.56         0.207671       12         0.546487         0.335135      5.02s\n",
            "   4    16.57         0.237566       27         0.593243         0.837707      4.32s\n",
            "   5    18.91         0.263095       29         0.589975          0.16311      3.76s\n",
            "   6    21.65         0.303485       27         0.644107         0.296802      2.76s\n",
            "   7    24.92         0.341261       21         0.646304        0.0911248      1.92s\n",
            "   8    30.51         0.384508       24         0.705946         0.234235      1.02s\n",
            "   9    32.28         0.396757       35         0.667204         0.336713      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([43]), 'fold_y_g_pred': array([633532.9764924]), 'fold_num': 19}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 20:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[27]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0783497        9         0.382019         0.500021      6.69s\n",
            "   1    10.35          0.13511       10         0.428896         0.231872      6.40s\n",
            "   2    12.07         0.169254       23         0.539581         0.496764      8.19s\n",
            "   3    12.97         0.209868       21         0.541801         0.212448      8.41s\n",
            "   4    18.43         0.245937       19         0.561784         0.197163      6.49s\n",
            "   5    25.56         0.299808       58         0.611815         0.266647      4.09s\n",
            "   6    27.12         0.329126       19         0.615584        0.0480094      2.93s\n",
            "   7    27.74         0.322936       26         0.634075         0.443641      1.95s\n",
            "   8    27.76         0.340372       27         0.605457         0.344834      0.98s\n",
            "   9    29.97         0.350658       27         0.624566         0.493941      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([27]), 'fold_y_g_pred': array([-896550.75224219]), 'fold_num': 20}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 21:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[47]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0780007        9         0.381659         0.405774      6.31s\n",
            "   1    10.29         0.138239       11         0.525636                0      6.26s\n",
            "   2    12.22         0.169315       23         0.518908         0.398747      5.69s\n",
            "   3    12.12         0.207746       18         0.548129         0.385009      5.82s\n",
            "   4    15.35         0.231721       24         0.567324         0.321831      4.57s\n",
            "   5    17.24         0.259022       20         0.551024         0.136064      4.81s\n",
            "   6    19.15         0.289779       21         0.606064         0.323233      4.73s\n",
            "   7    21.46         0.295755       52         0.601954         0.231711      2.47s\n",
            "   8    26.01         0.317531       31         0.639847         0.268196      0.96s\n",
            "   9    28.87         0.342391       21         0.613759         0.162155      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([47]), 'fold_y_g_pred': array([2265192.68062468]), 'fold_num': 21}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 22:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[29]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0798121        9         0.384535         0.500021      6.40s\n",
            "   1    10.41         0.136509       10         0.430226         0.231872      6.30s\n",
            "   2    12.13         0.172085       23           0.5405         0.496764      5.70s\n",
            "   3    13.40         0.213251       21         0.541123         0.212448      5.32s\n",
            "   4    18.21         0.250886       11         0.570164         0.253608      5.30s\n",
            "   5    23.41         0.288597       58         0.611612         0.266647      3.77s\n",
            "   6    25.47         0.322412       20         0.615803        0.0913908      2.89s\n",
            "   7    28.21         0.325937       33         0.613903         0.305693      1.98s\n",
            "   8    31.18         0.341283       33         0.620162        0.0887288      1.40s\n",
            "   9    32.39         0.355299       32         0.633075         0.279043      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([29]), 'fold_y_g_pred': array([-960379.62355754]), 'fold_num': 22}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 23:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[92]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0794741       10         0.378274         0.492919      6.26s\n",
            "   1     9.61         0.135751       11         0.500513                0      6.09s\n",
            "   2    11.61         0.171931       11         0.528779                0      5.86s\n",
            "   3    13.00         0.199942       30          0.54711         0.376042      5.00s\n",
            "   4    18.35         0.233888       11         0.598812                0      5.07s\n",
            "   5    24.79         0.286097       34         0.585904         0.152506      4.04s\n",
            "   6    27.25         0.313684       35         0.592809         0.390731      2.97s\n",
            "   7    30.97         0.329571       43         0.606594          0.42668      2.07s\n",
            "   8    32.75         0.351941       28         0.601297         0.301475      1.06s\n",
            "   9    35.19         0.366849       32         0.602208         0.112245      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([92]), 'fold_y_g_pred': array([13661512.98534874]), 'fold_num': 23}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 24:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[56]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0791461        9         0.382664         0.405774      7.18s\n",
            "   1    10.33          0.13752       10         0.439728         0.275424     10.80s\n",
            "   2    12.11         0.170239       23         0.518493         0.398747      9.26s\n",
            "   3    14.23         0.205123       19         0.551913        0.0491297      5.62s\n",
            "   4    24.40         0.270741       24          0.56933         0.296647      5.53s\n",
            "   5    31.38         0.313013       69         0.612182         0.344992      3.77s\n",
            "   6    36.98         0.334702       19          0.61782         0.300999      3.00s\n",
            "   7    36.13         0.349913       28         0.615065        0.0922359      2.03s\n",
            "   8    35.64         0.366235       36         0.649644         0.217923      1.03s\n",
            "   9    34.97         0.414863       24          0.66856                0      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([56]), 'fold_y_g_pred': array([-3338369.18081231]), 'fold_num': 24}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 25:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[63]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0810473        9         0.403487         0.405774      6.14s\n",
            "   1    10.23         0.140713       10         0.449669         0.323029      6.31s\n",
            "   2    12.06         0.170533       23         0.541941         0.398747      5.72s\n",
            "   3    13.15         0.215497       26         0.546133         0.228334      5.80s\n",
            "   4    17.65         0.243764       24          0.59139         0.296647      8.49s\n",
            "   5    21.66         0.284889       23         0.591383        0.0691624      5.52s\n",
            "   6    24.46         0.306262       29         0.652551        0.0602936      2.88s\n",
            "   7    27.39         0.333828       18           0.6467         0.381943      1.98s\n",
            "   8    28.42         0.351932       29         0.669543        0.0261862      0.99s\n",
            "   9    31.18         0.384106       27         0.689443         0.104202      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([63]), 'fold_y_g_pred': array([1102707.79847435]), 'fold_num': 25}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 26:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[94]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0803879       10         0.378231         0.505757      6.13s\n",
            "   1     9.54         0.136844       11         0.500817                0      6.10s\n",
            "   2    11.45         0.174324       11         0.528786                0      5.79s\n",
            "   3    12.50         0.197907       20         0.544851         0.238737      5.06s\n",
            "   4    16.64         0.225667       11         0.599253                0      4.49s\n",
            "   5    21.44         0.263012       30         0.575719         0.093869      4.20s\n",
            "   6    23.37         0.288769       45          0.61695        0.0573588      3.68s\n",
            "   7    29.22         0.312661       51         0.618797         0.186285      3.30s\n",
            "   8    31.87         0.354876       58         0.604835         0.287821      1.23s\n",
            "   9    34.82         0.367652       35         0.603622         0.201068      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([94]), 'fold_y_g_pred': array([6217953.70670519]), 'fold_num': 26}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 27:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[103]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0802489       10         0.379148         0.500603      6.24s\n",
            "   1     9.68         0.132972       10         0.430144         0.308052      6.15s\n",
            "   2    10.27         0.167243       11         0.484595       0.00891167      5.69s\n",
            "   3    12.37         0.190175       21         0.561361                0      5.11s\n",
            "   4    14.19         0.218675       35         0.560257         0.116503      4.51s\n",
            "   5    18.79          0.25463       25          0.56394         0.181354      4.22s\n",
            "   6    24.11         0.288778       24         0.607188         0.255261      2.85s\n",
            "   7    28.35          0.33606       25         0.645351       0.00455196      2.09s\n",
            "   8    33.30         0.376462       61          0.64321          0.20979      1.15s\n",
            "   9    37.69          0.41003       52         0.663083          0.20385      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([103]), 'fold_y_g_pred': array([121348.82911475]), 'fold_num': 27}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 28:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[81]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0798453       10         0.377834         0.491111      8.47s\n",
            "   1     9.53         0.136458       10         0.435236         0.288804      6.08s\n",
            "   2    11.96         0.176002       23         0.519647         0.402896      5.91s\n",
            "   3    15.45         0.214777       17         0.571291        0.0507675      5.24s\n",
            "   4    26.14         0.293392       19         0.559536         0.159311      4.74s\n",
            "   5    29.27         0.320261       16         0.590404        0.0727067      4.57s\n",
            "   6    29.11         0.325165       47         0.597805         0.169276      3.06s\n",
            "   7    36.10          0.35483       48          0.58757         0.293407      2.07s\n",
            "   8    37.53         0.358986       78         0.639182        0.0581907      1.04s\n",
            "   9    41.88         0.370668       98         0.656866          0.10126      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([81]), 'fold_y_g_pred': array([-33449725.83608047]), 'fold_num': 28}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 29:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[8]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0789954        9         0.397452         0.355568      6.28s\n",
            "   1    10.46         0.135557       10         0.431402         0.154102     10.56s\n",
            "   2    12.20         0.170367       41         0.528016        0.0301651      9.43s\n",
            "   3    14.25         0.206569       31         0.537792        0.0776248      6.48s\n",
            "   4    24.63         0.283194       24         0.601852         0.198192      4.82s\n",
            "   5    31.06         0.331867       29         0.613727                0      4.15s\n",
            "   6    31.64         0.339848       16         0.628741        0.0688348      3.44s\n",
            "   7    29.57         0.331328       34         0.646875        0.0493954      2.01s\n",
            "   8    28.62         0.371991       27          0.64779         0.276499      1.00s\n",
            "   9    34.38         0.422769       24         0.697271         0.272587      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([8]), 'fold_y_g_pred': array([-346940.74563616]), 'fold_num': 29}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 30:\n",
            "  Train: index=[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[0]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0797255        9           0.3915          0.32128      6.16s\n",
            "   1    10.79         0.134386       10         0.438004          0.10173      6.22s\n",
            "   2    11.62         0.169847       41         0.521009        0.0461451      5.64s\n",
            "   3    13.41         0.202602       31         0.539175         0.163472      5.08s\n",
            "   4    22.51         0.263349       23         0.552477         0.353512      7.30s\n",
            "   5    29.34         0.300688       17         0.599262          0.17521      6.63s\n",
            "   6    32.00         0.325623       51         0.619163         0.156997      3.42s\n",
            "   7    33.18         0.323253       15         0.580432        0.0510528      2.00s\n",
            "   8    33.52         0.343847       20         0.637883          0.09911      1.00s\n",
            "   9    32.35         0.357049       26          0.64669        0.0638196      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([0]), 'fold_y_g_pred': array([-137581.36937075]), 'fold_num': 30}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 31:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[73]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0796262       10         0.392158         0.491111      6.28s\n",
            "   1    10.07         0.138623       11         0.503223                0      6.18s\n",
            "   2    12.35         0.171343       11          0.52877                0      5.66s\n",
            "   3    14.36         0.218262       17         0.539211        0.0725228      5.18s\n",
            "   4    22.77         0.262728       11         0.599693                0      4.57s\n",
            "   5    27.44         0.293874       29         0.596438         0.307878      3.83s\n",
            "   6    28.51         0.319672       29          0.60163         0.110955      3.86s\n",
            "   7    34.10         0.342267       57         0.649114         0.317196      3.37s\n",
            "   8    38.01         0.355627       29         0.614602        0.0326347      1.36s\n",
            "   9    38.67         0.359581       30         0.624907        0.0939381      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([73]), 'fold_y_g_pred': array([-7684590.68574324]), 'fold_num': 31}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 32:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[20]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0788814        9         0.387959         0.327777      6.22s\n",
            "   1    10.39         0.136479       10         0.433336         0.231872      6.43s\n",
            "   2    11.76         0.174197       23         0.540961         0.495636      6.06s\n",
            "   3    13.44         0.205488       13          0.53607         0.241236      5.03s\n",
            "   4    22.62         0.261885       23         0.581521         0.178533      4.53s\n",
            "   5    31.46         0.317595       34         0.579811        0.0272594      4.58s\n",
            "   6    37.93         0.346856       50         0.597514         0.302558      3.03s\n",
            "   7    42.33         0.374854       31         0.591748         0.165788      2.13s\n",
            "   8    44.79         0.395072       54          0.61764         0.238813      1.15s\n",
            "   9    43.93         0.377307       46          0.62411         0.623332      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([20]), 'fold_y_g_pred': array([-2379180.2558087]), 'fold_num': 32}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 33:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[39]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0791961        9         0.390701         0.405774      8.50s\n",
            "   1    10.27         0.139807       11          0.45956         0.209435      6.53s\n",
            "   2    12.27         0.177263       23          0.51814         0.398747      5.81s\n",
            "   3    14.44         0.208323       45         0.548289       0.00501853      5.10s\n",
            "   4    23.11          0.26605       40         0.561647         0.125702      4.63s\n",
            "   5    31.55         0.323971       22         0.593128         0.113715      4.58s\n",
            "   6    34.12         0.347337       24         0.605905        0.0310807      2.99s\n",
            "   7    35.98         0.341908       19          0.59041          0.19196      1.99s\n",
            "   8    38.73         0.374761       52         0.607677        0.0621708      1.00s\n",
            "   9    40.62         0.374999       15         0.598018         0.226209      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([39]), 'fold_y_g_pred': array([2.21080338e+09]), 'fold_num': 33}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 34:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[102]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0729754       10         0.347602        0.0716973      6.24s\n",
            "   1     9.46         0.133866        8         0.418364         0.576736      8.52s\n",
            "   2     9.24         0.210152        8         0.484745         0.164444      9.92s\n",
            "   3    11.72         0.237731        8         0.518602         0.120443      7.10s\n",
            "   4    12.20         0.259934        6         0.529631        0.0334856      4.27s\n",
            "   5    10.60         0.272236        6         0.572633         0.453877      4.12s\n",
            "   6     9.43         0.269172       31         0.577098        0.0189186      2.60s\n",
            "   7    10.93         0.294512       34         0.566776         0.154386      1.74s\n",
            "   8    14.19         0.292585       34         0.605124        0.0350381      0.90s\n",
            "   9    21.17         0.327994       30         0.588735         0.239092      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([102]), 'fold_y_g_pred': array([1453270.8700016]), 'fold_num': 34}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 35:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[14]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0803867        9         0.398241         0.361442      6.35s\n",
            "   1    10.39         0.141869       10         0.431265         0.323886      6.21s\n",
            "   2    12.30         0.181767       23         0.528983         0.715691      5.75s\n",
            "   3    13.44         0.210737       24         0.569652         0.174375      5.12s\n",
            "   4    19.31         0.252255       49         0.597116         0.060792      4.76s\n",
            "   5    24.93         0.313626       58         0.640269         0.248953      6.73s\n",
            "   6    28.36         0.334122       25         0.615946         0.194083      4.79s\n",
            "   7    31.85          0.36999       22         0.609618         0.137831      2.00s\n",
            "   8    33.33         0.368984       20         0.629236        0.0946002      1.07s\n",
            "   9    34.85          0.37456       36         0.628463         0.100669      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([14]), 'fold_y_g_pred': array([1304474.76565086]), 'fold_num': 35}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 36:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 110 111 112 113]\n",
            "  Test:  index=[109]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57         0.079508       10         0.426542         0.154145      6.33s\n",
            "   1     9.70         0.134923       10         0.427815         0.308052      6.03s\n",
            "   2    10.68         0.165909       24          0.51067        0.0525636      5.70s\n",
            "   3    12.57         0.195738       12         0.594474        0.0626117      5.07s\n",
            "   4    16.07         0.232678       12         0.575059         0.174202      4.41s\n",
            "   5    20.96         0.256802       12         0.598701         0.213898      3.75s\n",
            "   6    21.69         0.277901       12         0.597904         0.168629      3.26s\n",
            "   7    20.45         0.290211       17         0.624429        0.0957499      2.82s\n",
            "   8    19.75         0.302169       20           0.6554         0.156152      1.50s\n",
            "   9    23.73         0.338023       12         0.669994         0.176937      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([109]), 'fold_y_g_pred': array([-1283457.72273268]), 'fold_num': 36}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 37:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[76]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0808491       10         0.388072         0.491111      6.38s\n",
            "   1     9.51         0.137517       10         0.444755         0.298982      6.30s\n",
            "   2    10.96         0.177774       23         0.520873         0.402896      5.76s\n",
            "   3    12.54         0.203747       17         0.571957        0.0507675      5.10s\n",
            "   4    17.94         0.246798       48         0.562971          0.14334      4.47s\n",
            "   5    22.10         0.290822       29         0.597651         0.307878      3.67s\n",
            "   6    24.16         0.303062       29         0.602573         0.110955      2.79s\n",
            "   7    26.02         0.309515       38         0.579886         0.082853      2.35s\n",
            "   8    28.87         0.327838       41         0.608436        0.0658238      1.02s\n",
            "   9    31.54         0.335563       48         0.629487          0.21025      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([76]), 'fold_y_g_pred': array([-9719119.42546791]), 'fold_num': 37}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 38:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[42]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0779124        9         0.382772         0.405774     10.18s\n",
            "   1    10.41         0.137443       11         0.525747                0     10.65s\n",
            "   2    12.25         0.167588       23         0.518618         0.398747      7.12s\n",
            "   3    12.37           0.2087       12         0.543748         0.335135      5.03s\n",
            "   4    16.37         0.243141       27         0.593084         0.837707      4.43s\n",
            "   5    18.84         0.260154       23         0.573837         0.279251      3.63s\n",
            "   6    21.83         0.308308       27         0.620303         0.066865      2.97s\n",
            "   7    26.20         0.338175       34         0.669795         0.046719      2.00s\n",
            "   8    34.59         0.389829       74          0.66497         0.389785      1.21s\n",
            "   9    40.65         0.425233       45         0.665714         0.197304      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([42]), 'fold_y_g_pred': array([2151611.37224301]), 'fold_num': 38}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 39:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[40]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0781595        9           0.3829         0.405774      6.56s\n",
            "   1    10.28         0.139352       11         0.525687                0      6.22s\n",
            "   2    12.24         0.166705       23         0.518899         0.398747      6.54s\n",
            "   3    12.68         0.205868       12         0.543897         0.335135      8.54s\n",
            "   4    17.09         0.242557       27         0.593261         0.837707      7.24s\n",
            "   5    20.14         0.275863       22         0.593527         0.254093      3.80s\n",
            "   6    21.62         0.304868       54         0.612812        0.0253408      2.82s\n",
            "   7    23.60         0.326505       25         0.644992        0.0648954      1.91s\n",
            "   8    27.63         0.356285       45         0.678426          0.23007      1.13s\n",
            "   9    33.30         0.403196       26         0.690493         0.250374      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([40]), 'fold_y_g_pred': array([-45181.9153831]), 'fold_num': 39}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 40:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[80]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0800597       10         0.378738         0.491111      6.30s\n",
            "   1     9.55         0.135699       10         0.435912         0.288804      6.14s\n",
            "   2    11.63         0.176044       23         0.518673         0.402896      5.64s\n",
            "   3    14.57         0.211437       17         0.571122        0.0507675      5.25s\n",
            "   4    20.87         0.258619       25         0.593025         0.453709      4.54s\n",
            "   5    24.80          0.30187       19         0.581657         0.273881      4.69s\n",
            "   6    26.20         0.312217       19         0.575184        0.0335133      5.04s\n",
            "   7    29.27         0.327668       36         0.594691         0.112212      2.60s\n",
            "   8    30.55         0.327788       32         0.629586        0.0324313      1.18s\n",
            "   9    33.38         0.358414       32          0.62665         0.247915      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([80]), 'fold_y_g_pred': array([19504414.48407456]), 'fold_num': 40}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 41:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[90]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0793739       10         0.373841         0.492919      6.15s\n",
            "   1     9.43          0.13706        7         0.446643        0.0552322      6.11s\n",
            "   2    11.05         0.176209       23         0.524601         0.402896      5.48s\n",
            "   3    12.91          0.20764       23         0.530966          0.10903      5.11s\n",
            "   4    17.90         0.238804       20          0.57906        0.0993194      4.61s\n",
            "   5    23.21         0.276537       18         0.598653         0.336968      3.65s\n",
            "   6    27.76         0.310888       32          0.61868         0.104655      2.84s\n",
            "   7    31.58         0.326042       20          0.60177         0.225942      1.90s\n",
            "   8    32.07         0.336796       33         0.638018        0.0201365      1.29s\n",
            "   9    33.95         0.347295       39         0.637073         0.232348      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([90]), 'fold_y_g_pred': array([3288082.91605143]), 'fold_num': 41}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 42:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[11]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0795988        9         0.386757         0.361442      7.26s\n",
            "   1    10.48         0.135809       10         0.430607         0.154102      6.09s\n",
            "   2    12.37         0.169701       41         0.521684        0.0301651      5.93s\n",
            "   3    14.06         0.204319       14         0.533894         0.305039      5.24s\n",
            "   4    23.35         0.275931       28         0.568294          0.13308      4.71s\n",
            "   5    30.69         0.325241       15         0.592682        0.0147075      4.03s\n",
            "   6    32.08         0.344837       16         0.627444        0.0512693      2.99s\n",
            "   7    31.05         0.342188       23          0.60839         0.816636      1.99s\n",
            "   8    27.33         0.338269       38         0.644435         0.251737      0.96s\n",
            "   9    26.60          0.35986       29          0.65074         0.132388      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([11]), 'fold_y_g_pred': array([5.17623155e+08]), 'fold_num': 42}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 43:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[24]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0780601        9         0.378097         0.327777      6.37s\n",
            "   1    10.57         0.133945       10         0.428683         0.231872      9.31s\n",
            "   2    12.36         0.167916       23          0.54093         0.496764     10.42s\n",
            "   3    13.14         0.209311       21         0.540827         0.212448      6.46s\n",
            "   4    16.97         0.240108       24         0.566407         0.297578      4.46s\n",
            "   5    20.74         0.283486       20         0.565126         0.334373      3.72s\n",
            "   6    22.15         0.305059       19         0.612561        0.0480094      2.81s\n",
            "   7    23.98         0.305528       17         0.588604         0.122321      1.93s\n",
            "   8    27.59         0.336044       34         0.606005      0.000478128      0.99s\n",
            "   9    30.07         0.331091       34         0.605886         0.122703      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([24]), 'fold_y_g_pred': array([9698359.6931107]), 'fold_num': 43}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 44:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[85]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0794626       10         0.377888         0.492919      6.39s\n",
            "   1     9.73         0.133512       11         0.503374                0      6.31s\n",
            "   2    11.81          0.17359       11         0.528872                0      6.02s\n",
            "   3    13.43         0.206505       28         0.582326         0.101076      5.08s\n",
            "   4    18.14         0.242033       25         0.593177         0.283617      5.91s\n",
            "   5    20.94         0.275624       19         0.592796         0.543421      6.17s\n",
            "   6    22.47         0.304276       22         0.668159        0.0224455      3.98s\n",
            "   7    26.07          0.34291       27         0.642161         0.269757      1.99s\n",
            "   8    27.87           0.3651       24         0.664868         0.249555      1.04s\n",
            "   9    29.72         0.387668       23         0.705443         0.030615      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([85]), 'fold_y_g_pred': array([-355166.64525808]), 'fold_num': 44}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 45:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 112 113]\n",
            "  Test:  index=[111]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0792668       10         0.427863         0.154145      6.55s\n",
            "   1     9.73         0.133837       10         0.428762         0.278642      7.44s\n",
            "   2    10.82         0.165566       24         0.510672        0.0525636      5.70s\n",
            "   3    12.87          0.19619       12         0.596659        0.0626117      5.04s\n",
            "   4    16.14         0.226695       12         0.577406         0.174202      4.39s\n",
            "   5    20.76         0.257187       12         0.601275         0.213898      3.73s\n",
            "   6    22.03         0.275341       12         0.600347         0.168629      2.78s\n",
            "   7    19.81         0.285755       17         0.624176        0.0844586      2.32s\n",
            "   8    17.22         0.289286       14         0.627578        0.0142887      1.53s\n",
            "   9    19.97         0.317946       26         0.660491         0.368607      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([111]), 'fold_y_g_pred': array([-375648.06486244]), 'fold_num': 45}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 46:\n",
            "  Train: index=[  0   1   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[2]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0796402        9         0.395724         0.355568      6.49s\n",
            "   1    10.46         0.138318       10         0.438736         0.154102      7.59s\n",
            "   2    11.57         0.175469       41         0.527357        0.0301651      5.59s\n",
            "   3    12.73         0.209261       18         0.547091         0.131649      5.12s\n",
            "   4    22.32         0.269277       24         0.601407           0.2081      4.59s\n",
            "   5    28.30          0.31535       23         0.586311         0.308248      3.78s\n",
            "   6    31.02         0.349053       55         0.596893          0.32969      2.95s\n",
            "   7    36.42         0.367372       53         0.612685        0.0177398      2.01s\n",
            "   8    39.08         0.389062       36         0.645908         0.147059      1.06s\n",
            "   9    41.95         0.410073       44         0.613746         0.188491      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([2]), 'fold_y_g_pred': array([25106482.90982959]), 'fold_num': 46}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 47:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[45]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0778816        9         0.382898         0.405774     10.35s\n",
            "   1    10.30         0.137587       11         0.525522                0     11.93s\n",
            "   2    12.26          0.16747       23         0.517386         0.398747      6.92s\n",
            "   3    12.36         0.205149       12         0.544566         0.335135      5.01s\n",
            "   4    16.37         0.248114       27          0.59303         0.832523      4.43s\n",
            "   5    17.76          0.25722       23         0.573817         0.279251      3.62s\n",
            "   6    19.82         0.288187       40         0.614034          0.15543      2.77s\n",
            "   7    22.64         0.327073       21         0.645293        0.0911248      2.03s\n",
            "   8    31.10         0.383932       46         0.659449         0.128252      1.08s\n",
            "   9    37.47         0.418974       54         0.689945          0.10029      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([45]), 'fold_y_g_pred': array([-10459.16024012]), 'fold_num': 47}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 48:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[89]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0789449       10         0.381113         0.492919      6.39s\n",
            "   1     9.30         0.139653       13         0.480751         0.671254      6.00s\n",
            "   2    11.30         0.188307       23         0.552096         0.402896      6.59s\n",
            "   3    14.50          0.21753       36         0.581255         0.192497      7.76s\n",
            "   4    22.99         0.279643       21         0.600113          0.12474      7.43s\n",
            "   5    32.22         0.335614       12         0.645353         0.112225      4.73s\n",
            "   6    34.31          0.34598       48         0.628836         0.148487      3.00s\n",
            "   7    35.36         0.355922       35         0.626308          0.23558      2.09s\n",
            "   8    36.90         0.385056       35         0.650558        0.0635924      1.03s\n",
            "   9    34.17         0.366739       40         0.662057         0.109877      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([89]), 'fold_y_g_pred': array([1644593.97884479]), 'fold_num': 48}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 49:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[13]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0797443        9         0.390337         0.361442      6.34s\n",
            "   1    10.44         0.136226       10         0.431265         0.154102      6.35s\n",
            "   2    12.19         0.168663       41         0.520939        0.0301651      6.58s\n",
            "   3    13.70         0.208244       31         0.534599        0.0688175      4.92s\n",
            "   4    24.24         0.279718       50         0.571997         0.328976      4.68s\n",
            "   5    31.02         0.331763       15         0.589006         0.101614      4.25s\n",
            "   6    31.68         0.345587       22         0.620868        0.0701169      5.36s\n",
            "   7    29.55         0.345361       32         0.632999        0.0448254      2.77s\n",
            "   8    26.37         0.367105       28         0.672222         0.146158      0.96s\n",
            "   9    28.29         0.403618       28         0.685605         0.197929      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([13]), 'fold_y_g_pred': array([49943549.59433363]), 'fold_num': 49}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 50:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[78]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0803413       10          0.37803         0.491111      6.36s\n",
            "   1     9.55         0.136363       10         0.435377         0.288804      6.16s\n",
            "   2    11.53         0.170698       23         0.517899         0.402896      6.60s\n",
            "   3    13.15          0.21146       17         0.571245        0.0507675      4.98s\n",
            "   4    23.45         0.276214       19         0.560065         0.159311      4.62s\n",
            "   5    27.12         0.311512      103         0.573068         0.205485      3.96s\n",
            "   6    29.38         0.326531       51         0.596894         0.408328      2.90s\n",
            "   7    35.35         0.357119       33          0.59497         0.294456      2.01s\n",
            "   8    37.57         0.375467       54         0.613835         0.139387      1.35s\n",
            "   9    36.98         0.370856       42          0.61149         0.140249      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([78]), 'fold_y_g_pred': array([-51820462.16272081]), 'fold_num': 50}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 51:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[70]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0802615        9         0.382761         0.406133      7.71s\n",
            "   1    10.00         0.139058       11         0.503398                0      6.52s\n",
            "   2    12.36         0.171741       11         0.529083                0      6.51s\n",
            "   3    13.82         0.212062       17         0.539534        0.0725228      5.12s\n",
            "   4    18.45         0.246513       11         0.599944                0      4.73s\n",
            "   5    21.79         0.280429       34         0.595772        0.0163703      3.73s\n",
            "   6    24.18         0.301985       19         0.612434         0.540322      2.89s\n",
            "   7    24.39         0.323709       19          0.64211         0.254562      1.98s\n",
            "   8    27.61         0.346414       23         0.671767         0.280726      1.01s\n",
            "   9    30.47         0.368053       34         0.678439         0.405516      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([70]), 'fold_y_g_pred': array([217394.57533318]), 'fold_num': 51}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 52:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[38]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0784321        9         0.381063         0.405774      6.39s\n",
            "   1    10.30         0.136782       10         0.443201         0.263755      8.58s\n",
            "   2    12.19         0.168614       23          0.51814         0.413526     11.27s\n",
            "   3    12.60         0.209276       21         0.540533         0.212448      6.66s\n",
            "   4    17.69         0.240161       24         0.571034         0.317088      4.76s\n",
            "   5    23.16         0.283271       39          0.62649         0.269894      3.93s\n",
            "   6    25.11          0.29916       28         0.593006         0.347912      2.93s\n",
            "   7    25.94         0.313125       31         0.603183        0.0634663      1.99s\n",
            "   8    27.54         0.320678       22         0.609815        0.0296537      0.99s\n",
            "   9    28.59         0.318657       28         0.625614         0.367735      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([38]), 'fold_y_g_pred': array([-85359393.46841861]), 'fold_num': 52}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 53:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[68]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57         0.079712        9         0.382803         0.406133      6.41s\n",
            "   1    10.15         0.138046       11         0.503398                0      6.40s\n",
            "   2    12.50         0.169596       11         0.528729                0      5.97s\n",
            "   3    14.51         0.222492       17         0.539971         0.181579      6.31s\n",
            "   4    23.47         0.266925       11           0.5996                0      7.35s\n",
            "   5    27.11         0.305695       29         0.575112         0.318165      6.19s\n",
            "   6    28.54         0.323939       47         0.592091         0.217443      3.29s\n",
            "   7    33.94         0.353835       68         0.598757         0.366884      2.02s\n",
            "   8    35.99         0.360038       28         0.621705         0.236846      1.03s\n",
            "   9    37.69         0.358936       22         0.630586         0.141268      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([68]), 'fold_y_g_pred': array([-1106329.07805552]), 'fold_num': 53}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 54:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[57]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0788925        9         0.385144         0.405774      6.55s\n",
            "   1    10.47         0.138518       11         0.505986                0      6.55s\n",
            "   2    12.24         0.169724       23         0.523964         0.398747      5.93s\n",
            "   3    13.58         0.207233       17         0.538696          0.34551      6.12s\n",
            "   4    22.75         0.255531       32         0.590889         0.336419      4.61s\n",
            "   5    30.79         0.311731       21         0.612508         0.338398      4.05s\n",
            "   6    34.58         0.336902       24         0.588695         0.167851      3.89s\n",
            "   7    38.09         0.360786       47         0.607834         0.336924      3.43s\n",
            "   8    39.17          0.36869       36         0.604255         0.275871      1.27s\n",
            "   9    40.11         0.394313       58         0.631924        0.0148059      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([57]), 'fold_y_g_pred': array([105033.59766563]), 'fold_num': 54}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 55:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112]\n",
            "  Test:  index=[113]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0792988       10         0.427928         0.154145      6.34s\n",
            "   1     9.70          0.13426       10         0.428818         0.278642      6.26s\n",
            "   2    10.73         0.165972       24         0.510648        0.0247435      5.60s\n",
            "   3    12.63         0.194887       12         0.597106        0.0412783      5.68s\n",
            "   4    15.88         0.231928       12         0.577592         0.174202      4.54s\n",
            "   5    20.62         0.253919       12         0.601478         0.213898      3.69s\n",
            "   6    21.30         0.280266       12         0.600541         0.168629      2.73s\n",
            "   7    20.33         0.285892       17         0.624203        0.0844586      1.78s\n",
            "   8    18.46         0.294727       16          0.63499         0.026171      0.86s\n",
            "   9    21.38          0.31603       29         0.640715         0.225025      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([113]), 'fold_y_g_pred': array([-2565596.94184175]), 'fold_num': 55}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 56:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[54]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0789255        9         0.383758         0.405774     10.50s\n",
            "   1    10.41         0.137084       10         0.441107         0.275424      9.38s\n",
            "   2    12.36         0.168106       23         0.518731         0.398747      5.85s\n",
            "   3    13.74         0.209885       20         0.535544         0.263659      6.02s\n",
            "   4    24.00         0.268721       24         0.572218         0.296647      4.66s\n",
            "   5    30.73         0.312135       27         0.580698         0.149321      3.92s\n",
            "   6    33.38         0.335686       48         0.593688         0.152793      3.07s\n",
            "   7    35.66         0.344167       37         0.620568         0.179796      2.03s\n",
            "   8    35.63          0.36039       24         0.618579         0.219272      1.04s\n",
            "   9    35.46         0.375856       41         0.612905         0.138642      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([54]), 'fold_y_g_pred': array([10552788.8293064]), 'fold_num': 56}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 57:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[41]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0781358        9         0.383269         0.405774      6.37s\n",
            "   1    10.30         0.137985       11         0.526051                0      6.12s\n",
            "   2    12.41         0.166348       23         0.518112         0.398747      7.58s\n",
            "   3    12.57         0.204683       18         0.542765         0.385009      8.76s\n",
            "   4    15.39         0.231066       11         0.563756                0      6.95s\n",
            "   5    17.22         0.246075       24         0.565657       3.8987e-17      3.55s\n",
            "   6    18.43         0.282441       18          0.59998                0      2.67s\n",
            "   7    19.46         0.273672       43         0.606247        0.0510701      1.91s\n",
            "   8    22.40         0.287293       23         0.612636         0.414057      0.93s\n",
            "   9    22.72         0.303946       21         0.600691         0.216897      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([41]), 'fold_y_g_pred': array([7377855.3559651]), 'fold_num': 57}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 58:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 113]\n",
            "  Test:  index=[112]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0794178       10         0.428787         0.154145      6.13s\n",
            "   1     9.70          0.13417       10         0.430146         0.278642      6.26s\n",
            "   2    10.84         0.165424       24         0.510672        0.0247435      5.68s\n",
            "   3    12.98         0.199678       12         0.596659        0.0412783      5.14s\n",
            "   4    16.77         0.233639       12         0.577123         0.174202      5.18s\n",
            "   5    23.20           0.2662       12         0.600761         0.213898      4.34s\n",
            "   6    22.59         0.289206       12          0.59983         0.168629      4.54s\n",
            "   7    21.98         0.303362       12          0.63056         0.241991      2.82s\n",
            "   8    20.15         0.311399       16         0.633753         0.026171      0.86s\n",
            "   9    23.88          0.35044       27         0.639279        0.0274796      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([112]), 'fold_y_g_pred': array([-4164743.49103805]), 'fold_num': 58}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 59:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[15]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0792091        9         0.387667         0.361442      6.39s\n",
            "   1    10.28         0.136876       15         0.444083        0.0690877      6.31s\n",
            "   2    12.14         0.171649       23         0.528983         0.608685      5.81s\n",
            "   3    13.73         0.203558       21         0.526083         0.319112      5.05s\n",
            "   4    17.50         0.233196       23         0.568894         0.157378      5.59s\n",
            "   5    21.09         0.257778       17         0.605373         0.156621      3.72s\n",
            "   6    24.71         0.286866       35         0.591885         0.278759      3.51s\n",
            "   7    26.52         0.312694       16         0.614069        0.0889093      1.95s\n",
            "   8    28.95          0.35267       23         0.667444         0.259661      1.29s\n",
            "   9    35.90         0.401225       73         0.673937         0.295004      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([15]), 'fold_y_g_pred': array([2076632.74913651]), 'fold_num': 59}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 60:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[67]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0792166        9         0.383031         0.406133      7.04s\n",
            "   1    10.13         0.137958       11         0.503778                0      6.32s\n",
            "   2    12.58         0.170567       11         0.529132                0      6.06s\n",
            "   3    14.41         0.219999       17         0.540379         0.181579      5.27s\n",
            "   4    23.43         0.266086       11         0.600291                0      4.66s\n",
            "   5    27.15         0.305024       29         0.575484         0.318165      3.95s\n",
            "   6    28.57         0.321923       47         0.592759         0.217443      3.29s\n",
            "   7    33.94          0.35241       68         0.599413         0.366884      2.03s\n",
            "   8    35.75         0.356198       28         0.622289         0.236846      1.00s\n",
            "   9    35.65         0.359957       22         0.630815         0.141268      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([67]), 'fold_y_g_pred': array([-658613.08856439]), 'fold_num': 60}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 61:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[58]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0777035        9         0.382733         0.405774      6.38s\n",
            "   1    10.39         0.135124       11         0.503701                0     10.67s\n",
            "   2    11.94         0.168847       23          0.51699         0.398747      9.35s\n",
            "   3    12.43         0.198732       12         0.546628         0.324554      6.21s\n",
            "   4    17.29         0.233531       25         0.592537         0.832523      4.68s\n",
            "   5    18.40         0.259009       48         0.604269         0.119513      3.59s\n",
            "   6    19.10         0.289565       22         0.672423         0.114011      3.19s\n",
            "   7    20.84         0.339797       27         0.656417         0.103998      1.86s\n",
            "   8    24.31         0.367146       25         0.676228         0.106579      0.96s\n",
            "   9    26.55         0.387451       42         0.683801         0.175544      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([58]), 'fold_y_g_pred': array([3147781.20203319]), 'fold_num': 61}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 62:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[55]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0786837        9         0.384637         0.405774      6.18s\n",
            "   1    10.44          0.13978       11         0.505811                0      6.36s\n",
            "   2    12.33         0.170293       23         0.524167         0.398747      5.77s\n",
            "   3    12.64         0.202014       21         0.549032          0.20447      5.00s\n",
            "   4    17.99         0.234079       11         0.566643                0      6.70s\n",
            "   5    22.68         0.270967       48         0.611605         0.119513      6.28s\n",
            "   6    25.43         0.311235       23         0.596885         0.264331      3.57s\n",
            "   7    26.10         0.317437       35         0.612855         0.593381      1.99s\n",
            "   8    30.35          0.34192       28         0.622746         0.148833      1.17s\n",
            "   9    35.12         0.355785       43         0.624127        0.0761985      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([55]), 'fold_y_g_pred': array([-9317298.02619527]), 'fold_num': 62}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 63:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[106]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0795854       10         0.429413         0.144158      6.18s\n",
            "   1     9.80         0.134773       10         0.429819         0.308052      6.21s\n",
            "   2    10.75         0.165468       24         0.509569        0.0525636      5.57s\n",
            "   3    12.79         0.199054       12         0.596351        0.0626117      5.35s\n",
            "   4    16.41         0.227485       12         0.577082         0.174202      4.49s\n",
            "   5    21.65         0.262209       12         0.600735         0.213898      3.75s\n",
            "   6    22.52         0.282305       12         0.602598         0.148589      2.80s\n",
            "   7    24.41         0.310365       17         0.626682         0.084177      2.95s\n",
            "   8    23.06         0.310422       14         0.626706         0.343421      1.67s\n",
            "   9    23.54         0.332082       43         0.640272         0.178412      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([106]), 'fold_y_g_pred': array([-241502.26167296]), 'fold_num': 63}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 64:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[66]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0789748        9         0.383031         0.405774      6.33s\n",
            "   1    10.12         0.136744       11         0.503599                0      6.27s\n",
            "   2    12.21         0.172811       11         0.528995                0      5.97s\n",
            "   3    14.47         0.219536       20         0.535356         0.286353      5.18s\n",
            "   4    23.68         0.259894       11          0.59984                0      4.65s\n",
            "   5    27.74         0.306435       12         0.577193                0      3.82s\n",
            "   6    29.61         0.310568       47         0.592325         0.217443      2.92s\n",
            "   7    34.77         0.336888       49         0.598686         0.713398      2.03s\n",
            "   8    40.57         0.361318       58         0.630577        0.0315219      1.19s\n",
            "   9    44.82         0.384368       54         0.639163         0.226394      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([66]), 'fold_y_g_pred': array([2534861.07909441]), 'fold_num': 64}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 65:\n",
            "  Train: index=[  0   1   2   3   4   5   6   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[7]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0792668        9         0.425902         0.355568     10.85s\n",
            "   1    10.46          0.13479       10         0.430423         0.154102      9.76s\n",
            "   2    11.44          0.16648       41         0.519814        0.0301651      5.75s\n",
            "   3    12.95         0.206536       16         0.541902         0.117774      5.10s\n",
            "   4    22.72         0.259387       26         0.574772         0.176789      4.69s\n",
            "   5    31.23         0.318687       64         0.592943         0.178563      3.98s\n",
            "   6    36.02         0.356072       42         0.628618         0.488442      2.99s\n",
            "   7    35.74         0.357616       29         0.608197      0.000119688      1.97s\n",
            "   8    35.55         0.375169       33         0.637759        0.0391971      1.11s\n",
            "   9    33.53         0.357323       36         0.618721         0.113347      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([7]), 'fold_y_g_pred': array([1557028.87421578]), 'fold_num': 65}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 66:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[33]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0785361        9         0.383438         0.405774      6.20s\n",
            "   1    10.31         0.135821       10         0.429666         0.231872      6.08s\n",
            "   2    11.95         0.167883       23         0.518535         0.413526      6.73s\n",
            "   3    13.07         0.210487       21          0.54121         0.212448      8.78s\n",
            "   4    18.58         0.249624       19         0.560007         0.197163      6.56s\n",
            "   5    24.36         0.289972       35         0.619758         0.234968      3.72s\n",
            "   6    26.91          0.32417       67         0.591778         0.131097      2.86s\n",
            "   7    27.89         0.311332       42         0.566619        0.0335723      1.95s\n",
            "   8    30.47         0.323854       42         0.624914         0.101738      1.04s\n",
            "   9    32.41         0.348004       22         0.629411         0.233116      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([33]), 'fold_y_g_pred': array([227169.20127342]), 'fold_num': 66}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 67:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[17]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0790212        9         0.387446         0.361442      6.37s\n",
            "   1    10.26          0.13599        8         0.410859         0.125587      6.05s\n",
            "   2    12.00         0.168289       23         0.527874         0.608685      6.00s\n",
            "   3    13.20         0.211749       21         0.543894        0.0121031      5.21s\n",
            "   4    19.46         0.257151       21         0.570902         0.190267      4.58s\n",
            "   5    24.40         0.303328       18         0.598854         0.241792      4.80s\n",
            "   6    25.47         0.325056       19         0.631789         0.295647      5.00s\n",
            "   7    25.84         0.347828       58         0.664534         0.230529      2.48s\n",
            "   8    27.75         0.387573       23         0.709073         0.252836      0.99s\n",
            "   9    30.32         0.409752       41         0.710681         0.168134      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([17]), 'fold_y_g_pred': array([-3459416.51090221]), 'fold_num': 67}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 68:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[60]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57         0.079801        9         0.380639         0.405774      6.50s\n",
            "   1    10.38         0.138989       11         0.503708                0      6.38s\n",
            "   2    12.36         0.171986       23         0.519128         0.398747      5.62s\n",
            "   3    13.91         0.210299       17         0.540904         0.344601      5.10s\n",
            "   4    22.54         0.254054       32         0.581231         0.336419      4.80s\n",
            "   5    29.13         0.296163       39         0.575527         0.478632      3.89s\n",
            "   6    33.43         0.325164       76         0.606438       0.00378182      3.00s\n",
            "   7    36.43         0.347795       52         0.606248         0.182225      2.09s\n",
            "   8    38.53         0.357223       35         0.594309      0.000582798      1.67s\n",
            "   9    40.35         0.360681       75         0.619576        0.0145164      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([60]), 'fold_y_g_pred': array([2055972.99341309]), 'fold_num': 68}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 69:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[49]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0782262        9         0.383866         0.405774      7.75s\n",
            "   1    10.40         0.137935       11         0.526176                0      6.33s\n",
            "   2    12.64         0.165606       23         0.518216         0.398747      5.82s\n",
            "   3    13.53         0.206967       18         0.541838         0.385009      5.05s\n",
            "   4    20.70         0.250684       11         0.563812                0      4.41s\n",
            "   5    24.61         0.275305       60          0.57864         0.208145      3.70s\n",
            "   6    27.91         0.316456       66          0.60546        0.0402748      2.95s\n",
            "   7    29.03         0.316772       41         0.583872         0.119676      1.97s\n",
            "   8    31.30         0.332945       40         0.617507         0.196958      1.02s\n",
            "   9    35.23         0.357452       52         0.606692         0.171148      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([49]), 'fold_y_g_pred': array([2316630.37973136]), 'fold_num': 69}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 70:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[61]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0791491        9          0.38397         0.405774      9.14s\n",
            "   1    10.22          0.13735       11          0.50343                0     11.23s\n",
            "   2    12.47         0.170627       23         0.518163         0.398747      8.41s\n",
            "   3    13.92         0.211762       23         0.538536         0.125041      5.00s\n",
            "   4    22.77         0.257569       24          0.56806         0.296647      4.50s\n",
            "   5    28.71         0.300481       27         0.577562         0.149321      3.99s\n",
            "   6    31.68         0.326212       24          0.58626         0.167851      3.00s\n",
            "   7    33.67         0.327885       64         0.595075         0.446809      2.01s\n",
            "   8    34.25         0.356441       28         0.619748         0.170575      1.01s\n",
            "   9    33.34         0.362326       35         0.665231         0.113545      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([61]), 'fold_y_g_pred': array([1813366.99745381]), 'fold_num': 70}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 71:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[64]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0775858        9           0.3829         0.405774      6.20s\n",
            "   1    10.28         0.135933       11         0.503708                0      7.40s\n",
            "   2    12.01         0.167124       11         0.529128                0      5.76s\n",
            "   3    13.14         0.213638       17         0.540325         0.181579      6.33s\n",
            "   4    18.90         0.240261       11         0.599997                0      7.85s\n",
            "   5    22.00         0.281144       41          0.58848        0.0269294      5.35s\n",
            "   6    24.34         0.321784       20         0.622739         0.316459      2.80s\n",
            "   7    24.74         0.343129       21         0.644883         0.184607      1.93s\n",
            "   8    26.66         0.371214       35         0.660515         0.168253      0.98s\n",
            "   9    27.84         0.395558       36         0.678031         0.305086      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([64]), 'fold_y_g_pred': array([-6284297.39459997]), 'fold_num': 71}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 72:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[22]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0788161        9         0.383004         0.327777      7.82s\n",
            "   1    10.38         0.136378       10         0.432817         0.231872      6.26s\n",
            "   2    12.05         0.173858       23          0.54105         0.496764      5.75s\n",
            "   3    13.52         0.209272       45         0.553518       0.00341104      5.43s\n",
            "   4    20.32         0.254161       23          0.58135         0.178533      4.70s\n",
            "   5    27.92         0.289758       39         0.627021         0.269894      3.99s\n",
            "   6    37.28         0.340286      118         0.584803        0.0293128      4.41s\n",
            "   7    39.30         0.333218       43         0.604653         0.240838      3.46s\n",
            "   8    36.59         0.324629       17         0.572419          0.16279      1.31s\n",
            "   9    38.60         0.337507       78         0.621237         0.344501      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([22]), 'fold_y_g_pred': array([89982.72360389]), 'fold_num': 72}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 73:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[32]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0788129        9         0.383438         0.500021      6.40s\n",
            "   1    10.40         0.137037       10         0.429073         0.231872      6.54s\n",
            "   2    11.93         0.169343       23         0.518747         0.413526      5.72s\n",
            "   3    12.89          0.20726       21         0.541162         0.212448      4.91s\n",
            "   4    18.55         0.252216       15         0.590224          0.19661      4.58s\n",
            "   5    23.93         0.287372       28         0.555913         0.429381      3.80s\n",
            "   6    26.32         0.291075       20         0.622785          0.15692      2.88s\n",
            "   7    28.53         0.331381       48         0.607575         0.254743      1.99s\n",
            "   8    34.34         0.359335       26          0.64195         0.199768      1.22s\n",
            "   9    46.61         0.419009       73         0.642788         0.283473      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([32]), 'fold_y_g_pred': array([-35464.42523145]), 'fold_num': 73}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 74:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[18]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0790971        9         0.398546         0.361442      8.43s\n",
            "   1    10.25         0.138169       10         0.425901         0.323886      6.16s\n",
            "   2    12.21         0.170639       23         0.540961         0.608685      5.89s\n",
            "   3    14.72         0.210049       45         0.573976       0.00341104      5.14s\n",
            "   4    23.11         0.272141       47          0.57937         0.258176      4.73s\n",
            "   5    31.71         0.335948       46         0.594804         0.382343      4.02s\n",
            "   6    36.12         0.351812       48         0.635997         0.148528      3.02s\n",
            "   7    40.59         0.384056       39         0.618433         0.289697      2.14s\n",
            "   8    44.60         0.403703       30         0.646746        0.0671055      1.09s\n",
            "   9    45.04         0.379898       38         0.653826        0.0528177      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([18]), 'fold_y_g_pred': array([1068146.85014349]), 'fold_num': 74}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 75:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[93]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0796012       10         0.378231         0.492919      8.91s\n",
            "   1     9.71         0.134564       11         0.500519                0     10.90s\n",
            "   2    11.17         0.167981       11         0.528786                0      8.50s\n",
            "   3    12.11         0.195634        9         0.515628                0      4.99s\n",
            "   4    15.73         0.214176       11          0.59882                0      4.33s\n",
            "   5    21.16         0.238872       17         0.589353         0.336968      3.72s\n",
            "   6    22.55         0.250132       22         0.576537         0.176734      2.85s\n",
            "   7    22.19          0.25072       21         0.601235         0.220073      1.88s\n",
            "   8    22.77         0.257185       37         0.614231         0.271352      0.94s\n",
            "   9    25.09         0.264686       20         0.632659         0.213016      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([93]), 'fold_y_g_pred': array([2083312.54132947]), 'fold_num': 75}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 76:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[79]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0807357       10         0.418441         0.491111      6.41s\n",
            "   1     9.42         0.137418       10         0.472667         0.288804      7.48s\n",
            "   2    10.99         0.183048       23         0.528323         0.402896      5.72s\n",
            "   3    12.47          0.21878       28         0.588028         0.101076      5.07s\n",
            "   4    17.19         0.259741       30         0.579634         0.105286      7.66s\n",
            "   5    23.38         0.295195       28         0.587807          0.23529      6.26s\n",
            "   6    25.79         0.301542       41         0.604377         0.229429      3.07s\n",
            "   7    28.40         0.317267       39         0.595642         0.174572      2.20s\n",
            "   8    34.63         0.344401       37         0.613676         0.256113      1.09s\n",
            "   9    37.50         0.373677       37         0.640822         0.332999      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([79]), 'fold_y_g_pred': array([7.28227902e+08]), 'fold_num': 76}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 77:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[108]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0791032       10         0.426542         0.129434      6.42s\n",
            "   1     9.68         0.134312       10         0.431122         0.308052      6.20s\n",
            "   2    10.81         0.164675       24         0.510352        0.0525636      6.57s\n",
            "   3    13.46         0.201387       12         0.597173        0.0626117      5.15s\n",
            "   4    16.50         0.227337       12         0.578031         0.174202      4.42s\n",
            "   5    20.62         0.256751       12         0.601812         0.213898      3.68s\n",
            "   6    21.31         0.273917       12         0.600871         0.168629      3.67s\n",
            "   7    19.18         0.281175       17         0.624675        0.0957499      3.12s\n",
            "   8    16.92         0.283862       12         0.627913        0.0142887      1.16s\n",
            "   9    18.25         0.306694       17         0.630739         0.114481      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([108]), 'fold_y_g_pred': array([735280.79673913]), 'fold_num': 77}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 78:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[97]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57         0.081034       10         0.376119         0.500603      6.08s\n",
            "   1     9.40         0.137155       10         0.427812         0.308052      7.37s\n",
            "   2    11.27         0.173362       23         0.518599         0.381947      5.61s\n",
            "   3    13.44         0.203703       20         0.544675         0.243488      5.27s\n",
            "   4    19.32         0.239444       12         0.560642         0.214746      4.52s\n",
            "   5    24.28         0.279891       56         0.607908         0.266035      3.85s\n",
            "   6    29.38         0.328142       31         0.593792         0.282219      3.14s\n",
            "   7    31.85         0.330981       19         0.582716        0.0842963      2.09s\n",
            "   8    30.34         0.330447       29         0.612676        0.0672225      1.05s\n",
            "   9    30.94         0.344626       30         0.648709         0.372978      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([97]), 'fold_y_g_pred': array([-4728723.71369144]), 'fold_num': 78}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 79:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[74]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0796242       10         0.390296         0.491111     10.45s\n",
            "   1    10.11         0.138473       11         0.503179                0      8.65s\n",
            "   2    12.33         0.171995       11          0.52873                0      6.68s\n",
            "   3    14.43         0.219684       17         0.539039        0.0725228      5.06s\n",
            "   4    22.89         0.264305       11         0.599604                0      4.77s\n",
            "   5    27.78          0.29785       29         0.596657         0.307878      3.83s\n",
            "   6    29.90         0.325044       29         0.601825         0.110955      2.94s\n",
            "   7    37.40         0.345912       57         0.649114          0.33005      2.06s\n",
            "   8    39.76         0.367056       28         0.621521         0.236846      1.03s\n",
            "   9    42.03         0.365326       35         0.635529         0.131823      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([74]), 'fold_y_g_pred': array([-2502574.33827949]), 'fold_num': 79}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 80:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[48]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0786712        9         0.381775         0.405774      6.35s\n",
            "   1    10.30         0.141237       11         0.525705                0      6.18s\n",
            "   2    13.02         0.170547       23         0.519042         0.398747     10.31s\n",
            "   3    12.43         0.204569       21         0.541363          0.20447      8.38s\n",
            "   4    16.05         0.240648       15         0.590092         0.186013      5.35s\n",
            "   5    18.68         0.269505       29         0.600773         0.535431      3.61s\n",
            "   6    22.29         0.308786       34         0.654849        0.0544025      2.80s\n",
            "   7    27.61           0.3558       31          0.65424        0.0484789      2.00s\n",
            "   8    34.32         0.418697       23         0.674841         0.494374      1.10s\n",
            "   9    39.65         0.440803       59         0.682086          0.28069      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([48]), 'fold_y_g_pred': array([-1.76071737e+08]), 'fold_num': 80}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 81:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[19]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0791037        9         0.387959         0.361442      6.35s\n",
            "   1    10.33         0.136029       10         0.435139         0.323886      6.31s\n",
            "   2    11.99          0.17344       23         0.540961         0.494553      6.59s\n",
            "   3    13.04          0.20471       21         0.541143         0.123776      5.15s\n",
            "   4    17.20         0.250271       23         0.581521        0.0995416      4.97s\n",
            "   5    22.11         0.287737       29          0.57816         0.138707      6.48s\n",
            "   6    23.16         0.307961       30         0.636578         0.203175      4.29s\n",
            "   7    25.48         0.316509       55         0.577845         0.480866      1.99s\n",
            "   8    29.11         0.337571       29         0.597094          0.19358      1.02s\n",
            "   9    31.39         0.339083       47         0.637961         0.224745      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([19]), 'fold_y_g_pred': array([8902581.6559194]), 'fold_num': 81}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 82:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[62]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0790591        9         0.382187         0.405774      6.32s\n",
            "   1    10.27         0.137847       11         0.503393                0      6.23s\n",
            "   2    12.36          0.17074       23         0.518469         0.398747      7.08s\n",
            "   3    13.79         0.208029       23         0.538893         0.125041      5.09s\n",
            "   4    22.77         0.255951       32         0.580706         0.336419      4.58s\n",
            "   5    30.91         0.300658       24         0.595781        0.0692503      3.94s\n",
            "   6    35.30         0.334639       24         0.586037         0.167851      3.07s\n",
            "   7    37.82         0.347071       51         0.584231         0.389196      3.01s\n",
            "   8    40.38          0.36625       93         0.587727         0.221478      1.80s\n",
            "   9    40.42         0.375313       45         0.637308        0.0427676      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([62]), 'fold_y_g_pred': array([3341367.30551678]), 'fold_num': 82}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 83:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[95]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0812818       10          0.37526         0.505757      6.13s\n",
            "   1     9.42         0.139976       11         0.500567                0      6.43s\n",
            "   2    11.35         0.172684       11         0.528487                0      5.73s\n",
            "   3    13.19         0.206403       20         0.544851         0.243488      5.77s\n",
            "   4    16.92         0.227848       11         0.598884                0      4.61s\n",
            "   5    20.34         0.254932       28         0.599901         0.218239      3.71s\n",
            "   6    22.27         0.275435       48         0.612587         0.150805      2.81s\n",
            "   7    26.34         0.296202       48         0.616475         0.102401      1.95s\n",
            "   8    31.89         0.329078       46          0.64286                0      1.02s\n",
            "   9    39.18         0.392913       42         0.693724         0.116014      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([95]), 'fold_y_g_pred': array([4.66785261e+08]), 'fold_num': 83}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 84:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[91]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0792767       10         0.377365         0.492919     11.01s\n",
            "   1     9.57         0.135025       11         0.500782                0      9.54s\n",
            "   2    11.49         0.170693       11         0.529107                0      6.78s\n",
            "   3    13.10         0.203533       36         0.538005         0.192497      5.03s\n",
            "   4    18.02         0.232238       11         0.599201                0      4.50s\n",
            "   5    23.62         0.273139       29         0.584769        0.0554154      3.91s\n",
            "   6    25.78         0.301023       38         0.605565         0.184148      2.91s\n",
            "   7    31.20         0.318746       26         0.590752        0.0946129      2.02s\n",
            "   8    32.99         0.332469       30         0.603898        0.0635576      1.07s\n",
            "   9    32.80         0.349385       27         0.624476         0.296322      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([91]), 'fold_y_g_pred': array([2337723.8383]), 'fold_num': 84}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 85:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[69]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0803947        9         0.384152         0.406133      6.28s\n",
            "   1    10.04         0.140471       11         0.503398                0      6.13s\n",
            "   2    12.41         0.171051       11         0.529169                0      7.00s\n",
            "   3    14.70         0.221737       17         0.539971        0.0725228     10.44s\n",
            "   4    24.18         0.267769       11         0.600046                0      6.03s\n",
            "   5    29.47         0.309775       29          0.59549         0.299135      3.96s\n",
            "   6    32.70         0.327876       29         0.600666         0.084335      3.06s\n",
            "   7    37.83         0.361401       41         0.603754         0.275901      2.04s\n",
            "   8    39.20         0.367137       37          0.63616         0.290698      1.08s\n",
            "   9    36.32         0.354472       29         0.618611        0.0724659      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([69]), 'fold_y_g_pred': array([44346712.95020059]), 'fold_num': 85}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 86:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[83]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0798776       10         0.377757         0.491111      6.30s\n",
            "   1     9.82         0.134814       11          0.50362                0      6.22s\n",
            "   2    11.66         0.172072       11         0.529177                0      5.63s\n",
            "   3    12.90          0.21146        9         0.621121                0      5.99s\n",
            "   4    17.34         0.242036       25          0.57059         0.775263      4.56s\n",
            "   5    20.03         0.282688        9         0.628181                0      6.26s\n",
            "   6    20.28         0.283077       22         0.613649          0.43823      4.41s\n",
            "   7    21.66         0.315786       21         0.658352         0.209419      2.17s\n",
            "   8    23.50         0.341807       27         0.655419       0.00488673      0.97s\n",
            "   9    25.18         0.366926       22          0.67325         0.212424      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([83]), 'fold_y_g_pred': array([44942084.61427853]), 'fold_num': 86}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 87:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[98]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57         0.077452        9         0.365789         0.311033      6.30s\n",
            "   1     9.95          0.13223       11         0.508705                0      6.09s\n",
            "   2    12.15         0.158927       11         0.537891                0      5.81s\n",
            "   3    14.75          0.20599       45         0.546057         0.448877      6.04s\n",
            "   4    20.67         0.227608       11          0.61258                0      4.63s\n",
            "   5    27.39         0.287133       45         0.599867        0.0527301      3.87s\n",
            "   6    38.35         0.349942       45         0.616782         0.344257      3.21s\n",
            "   7    47.77         0.390642       45         0.617566        0.0189088      2.55s\n",
            "   8    51.14         0.407569       75         0.622685        0.0616281      1.86s\n",
            "   9    53.60         0.412266       50         0.619702        0.0666667      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([98]), 'fold_y_g_pred': array([13768531.91654375]), 'fold_num': 87}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 88:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[50]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0809915        9         0.397638         0.405774      6.24s\n",
            "   1    10.01          0.14139       10         0.469971         0.291252      6.23s\n",
            "   2    11.72         0.169905       23         0.540457         0.398747      5.79s\n",
            "   3    13.37         0.218421       23         0.555969        0.0195899      5.05s\n",
            "   4    24.32         0.284072       40         0.591325        0.0214234      5.51s\n",
            "   5    34.41         0.349388       41         0.628618          0.20509      4.10s\n",
            "   6    41.19         0.386489       52         0.621957         0.119258      3.22s\n",
            "   7    43.00         0.386511       57         0.631687       0.00299945      2.11s\n",
            "   8    42.16         0.391285       61         0.642729        0.0492914      1.04s\n",
            "   9    39.33         0.375519       34         0.645754        0.0879708      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([50]), 'fold_y_g_pred': array([348361.24586438]), 'fold_num': 88}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 89:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[71]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0802648       10         0.384778         0.529978     10.32s\n",
            "   1    10.00         0.139571       11         0.503347                0      9.72s\n",
            "   2    12.39         0.172945       11         0.529019                0      5.78s\n",
            "   3    14.35         0.221313       17         0.539134        0.0725228      5.09s\n",
            "   4    23.15         0.268777       11         0.599868                0      4.75s\n",
            "   5    27.92         0.298164       29         0.597674         0.307878      4.41s\n",
            "   6    28.82         0.321957       29         0.602614         0.110955      2.94s\n",
            "   7    34.14         0.341547       49         0.634601         0.192354      1.99s\n",
            "   8    35.78         0.362154       29         0.615536        0.0326347      1.01s\n",
            "   9    37.43         0.355246       24         0.642493          0.41108      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([71]), 'fold_y_g_pred': array([2426905.55038781]), 'fold_num': 89}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 90:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[12]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0811877        9         0.407972         0.361442      6.41s\n",
            "   1    10.32         0.143199       10         0.438199         0.154102      6.14s\n",
            "   2    11.26         0.183832       23         0.505751         0.715691      6.87s\n",
            "   3    12.57         0.217023       12         0.553114         0.335135      9.33s\n",
            "   4    21.39         0.253744       36         0.600477         0.157777      6.58s\n",
            "   5    31.15         0.321209       37         0.587803         0.356278      3.96s\n",
            "   6    34.29          0.34829       30         0.612306          0.23505      3.43s\n",
            "   7    35.50         0.380319       38         0.601434         0.167471      2.09s\n",
            "   8    37.98         0.389127       47         0.620626         0.182818      1.08s\n",
            "   9    38.00         0.398264       39         0.645683         0.174612      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([12]), 'fold_y_g_pred': array([-22849981.02836216]), 'fold_num': 90}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 91:\n",
            "  Train: index=[  0   1   2   3   4   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[5]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0792669        9         0.398066         0.355568      6.24s\n",
            "   1    10.41         0.137135       10         0.438808         0.154102      6.33s\n",
            "   2    11.86         0.174974       41         0.533317        0.0301651      5.64s\n",
            "   3    13.20         0.207886       33          0.55799          0.13265      5.16s\n",
            "   4    23.35          0.28086       24         0.602916           0.2081      4.63s\n",
            "   5    28.79         0.318355       62         0.587951         0.178563      5.56s\n",
            "   6    32.66         0.338212       43         0.609792         0.386632      5.17s\n",
            "   7    34.26         0.355082       36         0.630665          0.29508      2.30s\n",
            "   8    34.09         0.359435       64         0.595945        0.0147677      1.00s\n",
            "   9    37.05         0.365061       60         0.602355        0.0452283      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([5]), 'fold_y_g_pred': array([-3794949.34646556]), 'fold_num': 91}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 92:\n",
            "  Train: index=[  0   1   2   3   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[4]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0796365        9         0.394369         0.355568      6.25s\n",
            "   1    10.78         0.136796       10         0.430863         0.154102      6.23s\n",
            "   2    12.48         0.174454       41         0.522306        0.0301651      6.27s\n",
            "   3    14.14         0.203463       31         0.538878         0.163472      4.98s\n",
            "   4    23.50           0.2642       51         0.565544         0.182944      4.74s\n",
            "   5    31.93         0.314518       53         0.596004         0.400161      3.92s\n",
            "   6    38.50         0.341273       50         0.638606                0      3.47s\n",
            "   7    38.88         0.337997       45         0.603837                0      2.44s\n",
            "   8    37.16         0.341218       49         0.644259          0.24155      1.75s\n",
            "   9    41.75          0.36582       43         0.608084         0.116322      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([4]), 'fold_y_g_pred': array([3910295.23946912]), 'fold_num': 92}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 93:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[16]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0789485        9         0.387716         0.361442      6.36s\n",
            "   1    10.32         0.135845        8         0.411529         0.125587      6.13s\n",
            "   2    12.15         0.166272       23         0.528708         0.608685      5.70s\n",
            "   3    13.74         0.208069       23         0.531141         0.208479      5.22s\n",
            "   4    22.48          0.27504       11         0.569908         0.232396      4.62s\n",
            "   5    28.88         0.317447       25         0.598909        0.0170218      3.88s\n",
            "   6    31.04         0.332519       29         0.641464         0.162284      3.45s\n",
            "   7    29.03         0.332594       57         0.661636         0.274607      2.01s\n",
            "   8    33.91         0.380887       38         0.688354         0.078893      1.04s\n",
            "   9    41.15         0.409766       28         0.669155         0.111845      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([16]), 'fold_y_g_pred': array([256135.7915891]), 'fold_num': 93}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 94:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[72]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0803901        9          0.39124         0.406133     10.68s\n",
            "   1    10.20         0.140911       11         0.503347                0      9.57s\n",
            "   2    12.58         0.172782       11         0.528965                0      6.73s\n",
            "   3    12.97         0.210881       17         0.539273        0.0725228      5.11s\n",
            "   4    18.43         0.239686       11         0.599805                0      4.65s\n",
            "   5    20.51         0.283733       29         0.597001         0.307878      3.73s\n",
            "   6    21.64         0.296595       16         0.621422        0.0773945      2.83s\n",
            "   7    23.19         0.319988       19         0.652585         0.189595      2.24s\n",
            "   8    23.50         0.328832       27         0.638156         0.133317      1.01s\n",
            "   9    26.72         0.365372       18           0.6763        0.0793641      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([72]), 'fold_y_g_pred': array([224708.74704086]), 'fold_num': 94}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 95:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[37]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57         0.078015        9         0.382026         0.405774      6.43s\n",
            "   1    10.31         0.135468       10         0.445901         0.263755      6.34s\n",
            "   2    12.19         0.167822       23         0.519544         0.413526      5.79s\n",
            "   3    12.60         0.207976       17         0.542896         0.366321      8.33s\n",
            "   4    17.74         0.253578       18         0.559034         0.161976      7.22s\n",
            "   5    20.42         0.274544       20         0.551409         0.206254      4.16s\n",
            "   6    23.10         0.316602       29         0.611751         0.572643      2.89s\n",
            "   7    25.87         0.337171       34          0.59046         0.210443      2.28s\n",
            "   8    32.82         0.367046       38         0.629572         0.238198      1.06s\n",
            "   9    36.07         0.381057       27         0.618187         0.190692      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([37]), 'fold_y_g_pred': array([-1883562.43225995]), 'fold_num': 95}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 96:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[77]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0805734       10          0.37781         0.491111      6.52s\n",
            "   1     9.50         0.136313       10         0.435377         0.298982      6.20s\n",
            "   2    12.30         0.176165       23         0.518951         0.402896      5.98s\n",
            "   3    15.73          0.21502       17         0.571117        0.0507675      5.27s\n",
            "   4    26.35         0.299983       25         0.593077         0.453709      4.89s\n",
            "   5    31.36         0.323033       57         0.592946        0.0778765      5.02s\n",
            "   6    34.04         0.350499       35         0.577466         0.165765      5.16s\n",
            "   7    38.53         0.360211       37         0.612265        0.0116261      3.03s\n",
            "   8    39.90         0.363208       81          0.61643        0.0795096      1.04s\n",
            "   9    40.38         0.375792       23         0.600531        0.0228593      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([77]), 'fold_y_g_pred': array([1.34670876e+08]), 'fold_num': 96}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 97:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[100]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0785257       10         0.365117         0.500603      6.45s\n",
            "   1     9.88         0.130679       11         0.504371                0      6.35s\n",
            "   2    11.77          0.16818       11         0.534617                0      5.98s\n",
            "   3    13.99         0.200964        9         0.524499                0      5.27s\n",
            "   4    16.02         0.209513       11         0.607883                0      4.52s\n",
            "   5    18.83         0.228375       14         0.601929                0      3.86s\n",
            "   6    19.25         0.237224       32         0.603631        0.0893101      2.78s\n",
            "   7    20.11         0.236908       62         0.588616         0.270857      1.87s\n",
            "   8    23.36         0.266052       31         0.626841                0      1.71s\n",
            "   9    27.06         0.280304       31         0.616101                0      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([100]), 'fold_y_g_pred': array([1998887.28651079]), 'fold_num': 97}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 98:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[65]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0782754        9          0.38272         0.405774      6.58s\n",
            "   1    10.32         0.136475       11           0.5035                0      6.09s\n",
            "   2    12.12         0.167011       11         0.528872                0      5.81s\n",
            "   3    13.93         0.217406       17         0.540107         0.181579      5.13s\n",
            "   4    22.76         0.260851       11         0.599701                0      4.66s\n",
            "   5    26.44         0.304918       23         0.588575        0.0118955      3.94s\n",
            "   6    28.26         0.327136       76         0.606349       0.00679985      2.89s\n",
            "   7    30.45         0.339433       27         0.598892         0.135159      1.98s\n",
            "   8    33.43         0.363271       21         0.644027       0.00202173      1.02s\n",
            "   9    32.20         0.365695       24         0.645699        0.0525716      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([65]), 'fold_y_g_pred': array([-6069975.54712676]), 'fold_num': 98}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 99:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[28]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0789733        9         0.384755         0.500021      8.17s\n",
            "   1    10.37         0.136407       10         0.431597         0.231872     10.99s\n",
            "   2    12.12         0.172782       23         0.540716         0.496764      9.21s\n",
            "   3    13.21         0.205662       21         0.541444         0.212448      5.09s\n",
            "   4    17.65         0.248867       11         0.570164         0.232396      4.66s\n",
            "   5    23.92         0.295325       58         0.612137         0.266647      3.79s\n",
            "   6    25.73         0.322908       21         0.602582        0.0851129      2.93s\n",
            "   7    26.04         0.312929       24         0.590779        0.0391051      1.95s\n",
            "   8    26.47         0.319894       31         0.613595         0.646841      0.97s\n",
            "   9    29.72         0.351047       52          0.68156         0.310519      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([28]), 'fold_y_g_pred': array([-2133446.49613208]), 'fold_num': 99}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 100:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[25]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0781449        9          0.38389         0.327777      6.41s\n",
            "   1    10.53         0.134803       10         0.428686         0.231872      6.12s\n",
            "   2    12.65         0.170224       23         0.540224         0.496764      5.74s\n",
            "   3    14.97         0.213604       45          0.55174       0.00341104      6.42s\n",
            "   4    23.65         0.276443       11         0.568497         0.232396      7.94s\n",
            "   5    31.19         0.327514       58         0.606602         0.248953      5.29s\n",
            "   6    33.79         0.348988       76         0.639562         0.208882      3.03s\n",
            "   7    41.95         0.366419       59         0.595779         0.173077      2.18s\n",
            "   8    47.27         0.389353       49         0.624239         0.163322      1.11s\n",
            "   9    49.50          0.38601       51         0.609537         0.268506      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([25]), 'fold_y_g_pred': array([-17424014.29281341]), 'fold_num': 100}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 101:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[99]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0795178       10         0.375545         0.500603      6.14s\n",
            "   1     9.61         0.132444       11         0.508705                0      6.34s\n",
            "   2    10.56         0.169086       11         0.539701                0      5.93s\n",
            "   3    11.61         0.196029        9         0.533173         0.149738      5.04s\n",
            "   4    13.19         0.209632       11          0.61518                0      4.25s\n",
            "   5    16.87         0.234474       11         0.575664                0      3.65s\n",
            "   6    19.60         0.277876       18         0.627228          0.60327      4.42s\n",
            "   7    19.94         0.251955       18         0.620066         0.118195      2.98s\n",
            "   8    25.09          0.30479       18         0.648559         0.355069      1.05s\n",
            "   9    27.98         0.334993       18         0.674978         0.726822      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([99]), 'fold_y_g_pred': array([3451482.41514093]), 'fold_num': 101}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 102:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[105]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0800548       10         0.427354         0.144158      6.46s\n",
            "   1     9.88         0.135748       10         0.428042         0.308052      7.39s\n",
            "   2    11.26         0.166993       24         0.509018        0.0525636      5.90s\n",
            "   3    12.37         0.190862       24         0.553344         0.306663      4.94s\n",
            "   4    16.77         0.235506       28         0.568377        0.0407599      4.60s\n",
            "   5    23.35         0.260649       22         0.575286         0.269307      3.78s\n",
            "   6    25.03         0.282665       37         0.586096         0.364116      2.89s\n",
            "   7    25.76         0.306055       20          0.59438        0.0554122      1.94s\n",
            "   8    27.11         0.305326       21         0.596663          0.19744      1.06s\n",
            "   9    27.99         0.307448       29         0.605413         0.359555      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([105]), 'fold_y_g_pred': array([462900.27813372]), 'fold_num': 102}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 103:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[34]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0785427        9         0.384818         0.405774      9.59s\n",
            "   1    10.30         0.136048       10          0.43662         0.231872      6.44s\n",
            "   2    12.29         0.166304       23         0.520731         0.413526      6.40s\n",
            "   3    13.87          0.20551       20         0.539727         0.294238      4.94s\n",
            "   4    22.78          0.26604       48         0.571057        0.0318232      4.61s\n",
            "   5    30.00         0.319732       22         0.614829         0.029557      3.87s\n",
            "   6    31.58         0.334314       28         0.593459         0.308786      2.97s\n",
            "   7    31.36         0.334667       90         0.601383          0.13002      2.01s\n",
            "   8    34.78         0.355064       85         0.591234          0.12783      1.04s\n",
            "   9    36.83          0.35779       37         0.609058        0.0067022      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([34]), 'fold_y_g_pred': array([3321762.32578145]), 'fold_num': 103}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 104:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[59]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0791118        9         0.382585         0.405774      6.36s\n",
            "   1    10.34         0.136052       11         0.503469                0      7.75s\n",
            "   2    12.05          0.17226       23         0.518074         0.398747     11.31s\n",
            "   3    13.88         0.209528       23         0.538517         0.125041      6.96s\n",
            "   4    23.07         0.263255       24         0.569687         0.296647      4.60s\n",
            "   5    29.77         0.306839       24         0.595152        0.0692503      3.82s\n",
            "   6    32.75         0.324981       32         0.585424         0.198971      2.97s\n",
            "   7    32.55         0.329938       43         0.614498        0.0390794      1.99s\n",
            "   8    34.71          0.34861       21         0.645081       0.00940183      1.05s\n",
            "   9    35.60         0.367392       22         0.633931         0.100701      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([59]), 'fold_y_g_pred': array([3497827.85143833]), 'fold_num': 104}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 105:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[53]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0789994        9         0.388537         0.405774      6.31s\n",
            "   1    10.41         0.138475       10         0.442222         0.275424      6.36s\n",
            "   2    12.24         0.170665       23         0.519311         0.398747      6.52s\n",
            "   3    13.98         0.210643       20         0.536018         0.263659      5.07s\n",
            "   4    23.10         0.267765       24         0.571148         0.296647      6.35s\n",
            "   5    30.82         0.320617       32         0.572613         0.304088      6.33s\n",
            "   6    31.91         0.337957       15         0.592591       0.00522154      3.78s\n",
            "   7    34.28         0.346974       62         0.609425         0.347462      1.97s\n",
            "   8    35.17         0.358896       45         0.607654         0.121222      1.05s\n",
            "   9    36.71         0.373652       26         0.636234        0.0702545      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([53]), 'fold_y_g_pred': array([-1810761.83855193]), 'fold_num': 105}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 106:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[36]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0783148        9         0.384257         0.405774      6.26s\n",
            "   1    10.35         0.135699       10         0.445901         0.231872      7.21s\n",
            "   2    12.18         0.168863       23         0.520358         0.413526      5.74s\n",
            "   3    13.45         0.211007       21         0.541969         0.212448      5.02s\n",
            "   4    17.64         0.253793       24         0.567341         0.317088      4.43s\n",
            "   5    21.01         0.288797       40         0.626898         0.198993      3.72s\n",
            "   6    22.53         0.305849       19         0.619094         0.175009      2.88s\n",
            "   7    24.98         0.310934       25         0.595243         0.235802      2.91s\n",
            "   8    26.66           0.3328       35         0.593645         0.425076      1.66s\n",
            "   9    31.31          0.35169       62         0.628421         0.275824      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([36]), 'fold_y_g_pred': array([-10264432.55939514]), 'fold_num': 106}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 107:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[52]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0789324        9         0.382978         0.405774      6.43s\n",
            "   1    10.44         0.137404       10         0.442222         0.291252      6.28s\n",
            "   2    12.21          0.16827       23         0.518543         0.398747      6.83s\n",
            "   3    13.91         0.211346       20         0.536018         0.294238      5.10s\n",
            "   4    24.23         0.268553       24         0.569191         0.296647      4.69s\n",
            "   5    31.50         0.316973       27         0.577515         0.149321      3.89s\n",
            "   6    34.26         0.337732       78         0.600084         0.321246      3.19s\n",
            "   7    37.07         0.348815       30         0.584538         0.243733      2.07s\n",
            "   8    36.29          0.36976       31         0.605734         0.239484      1.02s\n",
            "   9    34.89          0.37693       35         0.650436         0.277713      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([52]), 'fold_y_g_pred': array([-46119.58171446]), 'fold_num': 107}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 108:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[88]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0798624       10         0.378296         0.492919     10.76s\n",
            "   1     9.35         0.131494       11         0.501968                0      8.83s\n",
            "   2    11.69         0.168505       11         0.530424                0      6.57s\n",
            "   3    13.09         0.208544       23         0.539351         0.165573      5.04s\n",
            "   4    18.92         0.236587       11         0.563581                0      4.53s\n",
            "   5    24.08         0.267214       34         0.568121          0.29467      3.95s\n",
            "   6    26.33         0.284239       19         0.593293         0.136519      2.97s\n",
            "   7    28.87         0.297311       43         0.594001        0.0842969      2.01s\n",
            "   8    34.32         0.323658       40         0.617394       0.00537769      1.09s\n",
            "   9    40.21         0.340956       40         0.630188        0.0464444      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([88]), 'fold_y_g_pred': array([763340.86511898]), 'fold_num': 108}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 109:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[86]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0792325       10         0.386599         0.492919      6.30s\n",
            "   1     9.66         0.134954       11         0.503374                0      7.15s\n",
            "   2    11.60         0.175187       11         0.532049                0      9.15s\n",
            "   3    13.36          0.21244       17         0.575346        0.0507675      8.14s\n",
            "   4    17.03         0.241404       11         0.565549                0      5.51s\n",
            "   5    20.27         0.269019       29         0.600056         0.307878      3.82s\n",
            "   6    23.00         0.289529       29         0.602373         0.230697      2.84s\n",
            "   7    25.75         0.309422       24         0.593488         0.212137      1.96s\n",
            "   8    31.18         0.331374       34         0.616246         0.116304      1.07s\n",
            "   9    34.01         0.350066       38         0.624088         0.189309      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([86]), 'fold_y_g_pred': array([-2387225.05902046]), 'fold_num': 109}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 110:\n",
            "  Train: index=[  0   1   2   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[3]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0798605        9         0.395494         0.355568      6.24s\n",
            "   1    10.82         0.136492       10         0.430636         0.154102      6.14s\n",
            "   2    12.11         0.174329       41         0.520115        0.0301651      6.86s\n",
            "   3    13.54         0.200565       31         0.539828         0.163472      5.18s\n",
            "   4    23.60         0.268752       51         0.564668         0.182944      4.74s\n",
            "   5    32.32         0.324492       58         0.583881        0.0132893      6.26s\n",
            "   6    37.42         0.351219       74         0.636863         0.315891      5.00s\n",
            "   7    36.65         0.355743       23         0.609919        0.0734578      2.02s\n",
            "   8    32.40         0.347179       75         0.638357         0.130587      0.97s\n",
            "   9    29.38         0.341147       38         0.647401         0.065817      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([3]), 'fold_y_g_pred': array([7581945.38621387]), 'fold_num': 110}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 111:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 111 112 113]\n",
            "  Test:  index=[110]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0795483       10         0.426752         0.154145      6.25s\n",
            "   1     9.76         0.134822       10         0.427815         0.278642      6.15s\n",
            "   2    10.68          0.16867       45         0.524221         0.432909      6.70s\n",
            "   3    13.26         0.198678       12         0.594839        0.0626117      5.27s\n",
            "   4    18.98         0.237118       12         0.575444         0.174202      4.51s\n",
            "   5    25.43         0.274512       12         0.599081         0.213898      3.83s\n",
            "   6    25.23         0.285094       12         0.598264         0.168629      2.83s\n",
            "   7    22.65         0.304446       17         0.624176        0.0957499      2.12s\n",
            "   8    20.92         0.304518       18         0.634771        0.0110474      1.50s\n",
            "   9    21.69         0.299695       25         0.621654         0.188838      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([110]), 'fold_y_g_pred': array([-649644.24339746]), 'fold_num': 111}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 112:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[10]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0797274        9         0.389199         0.361442      6.34s\n",
            "   1    10.48         0.135946       10         0.430469         0.154102      6.24s\n",
            "   2    12.13         0.172898       41         0.520429        0.0301651      6.84s\n",
            "   3    14.26         0.208611       28          0.58265         0.302002      5.23s\n",
            "   4    24.37         0.280833       50         0.570738         0.328976      4.64s\n",
            "   5    29.21         0.319129       15         0.594591        0.0147075      3.81s\n",
            "   6    31.98         0.331265       24         0.629925         0.232323      2.97s\n",
            "   7    34.18         0.359302       42         0.615128        0.0762488      2.00s\n",
            "   8    35.01         0.380313       40         0.609651         0.362412      1.00s\n",
            "   9    36.21         0.383594       36         0.635127         0.293868      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([10]), 'fold_y_g_pred': array([24777416.93757141]), 'fold_num': 112}\n",
            "         Year        LP      LTIV  Price_Decay  Price_R2  TIV_Decay    TIV_R2\n",
            "0    0.328564  2.345962  2.746808    -1.063660  0.254197  -1.007627  0.142488\n",
            "1    0.328564  2.251907  2.532912    -0.279537  0.451914  -0.972083  0.538486\n",
            "2    0.328564  2.212676  2.233535    -0.373456  0.491581  -0.999657  0.686106\n",
            "3   -0.657129  2.232983  2.226602    -1.179355  0.985050  -1.215951  0.304615\n",
            "4    0.328564  2.050659  1.850519    -0.543097  0.212593  -0.123845 -0.059673\n",
            "..        ...       ...       ...          ...       ...        ...       ...\n",
            "109 -1.642822 -1.464310 -1.247057    -0.799281  0.819965  -0.915658  0.570206\n",
            "110 -1.642822 -1.548557 -1.241678    -0.676969  0.425206  -0.986149  0.614444\n",
            "111 -1.642822 -1.461041 -1.316601    -1.362277  0.653149  -1.313418  0.456264\n",
            "112 -1.642822 -1.375222 -1.297537     0.307674 -0.066945   0.098426  0.687798\n",
            "113 -1.642822 -1.619223 -1.272397    -1.355946  0.602780  -1.676351  0.532734\n",
            "\n",
            "[114 rows x 7 columns]\n",
            "Fold 113:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113]\n",
            "  Test:  index=[31]\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    12.57        0.0788008        9         0.388683         0.500021      7.75s\n",
            "   1    10.38         0.136178       10         0.438099         0.231872      9.89s\n",
            "   2    12.27         0.173925       23         0.546233         0.413526     10.56s\n",
            "   3    13.34         0.204164       24         0.559847         0.176017      5.09s\n",
            "   4    18.71          0.24837       27         0.559883         0.101476      4.69s\n",
            "   5    23.91         0.299849       31         0.575409        0.0440822      3.79s\n",
            "   6    26.68          0.31083       60         0.606872         0.193251      2.99s\n",
            "   7    30.38         0.338745       47         0.627865         0.324963      2.02s\n",
            "   8    31.98         0.360986       47         0.631723       0.00897699      1.10s\n",
            "   9    36.73         0.378825       54         0.640773         0.200813      0.00s\n",
            "(114, 1711)\n",
            "{'fold_test_index': array([31]), 'fold_y_g_pred': array([-13430712.76984005]), 'fold_num': 113}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "if Kfold_symbolic :\n",
        "    kf              = KFold(n_splits=X.shape [0] // number_of_test_per_fold , shuffle= True )\n",
        "\n",
        "    fold_number     = 0\n",
        "\n",
        "    kfold_pred_dict = {fold_test_index :np.array([])  ,\n",
        "                      fold_y_g_pred      : np.array ([]) ,\n",
        "                      }\n",
        "\n",
        "    kfold_pred_list = []\n",
        "\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "          if gp_features_df.columns [0] in X.columns :\n",
        "            X = X.drop (gp_features_df,axis =1)\n",
        "          if interaction_df.columns [0] in X.columns :\n",
        "            X = X.drop (interaction_df,axis =1)\n",
        "          print (X)\n",
        "          print(f\"Fold {i}:\")\n",
        "          print(f\"  Train: index={train_index}\")\n",
        "          print(f\"  Test:  index={test_index}\")\n",
        "\n",
        "          X_train_fold  = X.loc [train_index]\n",
        "          X_test_fold   = X.loc [test_index]\n",
        "\n",
        "          y_train_fold  = y.loc [train_index]\n",
        "          y_test_fold   = y.loc [test_index]\n",
        "\n",
        "          gp = SymbolicTransformer(generations=generations, population_size=population_size,\n",
        "          hall_of_fame=hall_of_fame, n_components=n_components,\n",
        "          function_set=function_set_trans,\n",
        "          parsimony_coefficient=parsimony_coefficient_trans,\n",
        "          max_samples=0.9, verbose=1,\n",
        "          random_state=0, n_jobs=-1)\n",
        "\n",
        "          gp.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "          gp_features = gp.transform(X)\n",
        "\n",
        "          gp_features_df = pd.DataFrame (gp_features)\n",
        "          gp_features_rename_dict = {}\n",
        "          for col in gp_features_df.columns : gp_features_rename_dict [col] = str (col) + \"_\"\n",
        "          gp_features_df.rename (gp_features_rename_dict  , axis =1 ,inplace=True)\n",
        "\n",
        "          X = X.join (gp_features_df)\n",
        "\n",
        "          poly           = PolynomialFeatures(2,interaction_only=False)\n",
        "          interaction_df = pd.DataFrame ( poly.fit_transform(X) )\n",
        "          interaction_df_rename_dict = {}\n",
        "          for col in interaction_df.columns : interaction_df_rename_dict [col] = str (col) + \"_poly\"\n",
        "          interaction_df.rename (interaction_df_rename_dict,axis =1, inplace=True)\n",
        "          sel_col_indicies        = [ random.randint (0, interaction_df.shape [1]-X.shape [1] -1) for _ in range (int (interaction_df.shape [1] * 0.01))]\n",
        "          print (interaction_df.shape)\n",
        "          interaction_df  = interaction_df.T.drop_duplicates().T\n",
        "          interaction_df  = interaction_df.iloc [:,sel_col_indicies]\n",
        "\n",
        "          X = X.join (interaction_df)\n",
        "\n",
        "          X_train_fold  = X.loc [train_index]\n",
        "          X_test_fold   = X.loc [test_index]\n",
        "\n",
        "          y_train_fold  = y.loc [train_index]\n",
        "          y_test_fold   = y.loc [test_index]\n",
        "\n",
        "          reg_fold = LinearRegression().fit(X_train_fold, y_train_fold)\n",
        "          #reg_fold = est_gp.fit(X_train_fold, y_train_fold)\n",
        "          #reg_fold = model_NN.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "          fold_y_pred_value = scaler_dict [Target].inverse_transform (reg_fold.predict (X_test_fold).reshape (-1,1))\n",
        "\n",
        "          kfold_pred_dict [fold_test_index]   =  test_index\n",
        "          kfold_pred_dict [fold_y_g_pred]     =  fold_y_pred_value.reshape (-1)\n",
        "          kfold_pred_dict [fold_num ]         =  i\n",
        "\n",
        "          kfold_pred_list.append (pd.DataFrame ( kfold_pred_dict))\n",
        "\n",
        "\n",
        "\n",
        "          print ( kfold_pred_dict)\n",
        "\n",
        "    kfold_pred_df = pd.concat (kfold_pred_list)\n",
        "\n",
        "    data_input = data_input.merge (kfold_pred_df.set_index (fold_test_index) , how = \"left\" , left_index = True , right_index = True)\n",
        "\n",
        "    data_input [(data_input [fold_y_g_pred ] < data_input [Target].max() ) *\n",
        "            (data_input [fold_y_g_pred ] > data_input [Target].min() )\n",
        "             ].plot.scatter (Target , fold_y_g_pred )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOn0kv1+NZMYoKttNeeZ14x",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}